[{"title":"Linux 系统运维基础指南","url":"/2026/02/28/01-Linux%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4%E5%9F%BA%E7%A1%80%E6%8C%87%E5%8D%97/","content":"Linux 系统运维基础指南目录\n系统信息查看\n用户与权限管理\n进程管理\n磁盘管理\n网络配置\n系统日志\n常用运维命令\n\n\n1. 系统信息查看1.1 查看系统版本# 查看操作系统版本cat /etc/os-releasecat /etc/redhat-release    # CentOS/RHELcat /etc/debian_version    # Debian/Ubuntu# 查看内核版本uname -runame -a\n\n1.2 查看硬件信息# CPU 信息lscpucat /proc/cpuinfo# 内存信息free -hcat /proc/meminfo# 磁盘信息lsblkdf -h# PCI 设备lspci# USB 设备lsusb\n\n1.3 查看系统运行状态# 系统运行时间uptime# 系统负载tophtop# 查看系统服务systemctl list-units --type=servicesystemctl list-unit-files --state=enabled\n\n\n2. 用户与权限管理2.1 用户管理# 创建用户useradd -m -s /bin/bash usernamepasswd username# 修改用户信息usermod -aG sudo username    # 添加用户到 sudo 组usermod -L username          # 锁定用户usermod -U username          # 解锁用户# 删除用户userdel -r username          # -r 同时删除家目录# 查看用户信息id usernamecat /etc/passwdcat /etc/shadow\n\n2.2 组管理# 创建组groupadd groupname# 添加用户到组usermod -aG groupname username# 查看组信息getent group groupnamecat /etc/group\n\n2.3 权限管理# 修改文件权限chmod 755 filenamechmod u+x filenamechmod -R 755 directory/# 修改文件所有者chown user:group filenamechown -R user:group directory/# 查看权限ls -lstat filename\n\n2.4 Sudo 配置# 编辑 sudo 配置visudo# 添加用户 sudo 权限username ALL=(ALL:ALL) ALL# 免密码 sudousername ALL=(ALL) NOPASSWD: ALL\n\n\n3. 进程管理3.1 查看进程# 查看所有进程ps auxps -ef# 查看特定进程ps aux | grep nginxpgrep nginx# 实时查看进程tophtop\n\n3.2 进程控制# 终止进程kill PIDkill -9 PID          # 强制终止killall processnamepkill processname# 调整进程优先级nice -n 10 commandrenice -n 10 -p PID\n\n3.3 后台任务管理# 后台运行command &amp;# 查看后台任务jobs# 切换到后台/前台Ctrl+Z              # 挂起bg                  # 后台运行fg                  # 前台运行# nohup 运行nohup command &amp;\n\n\n4. 磁盘管理4.1 磁盘分区# 查看磁盘分区fdisk -llsblk# 分区操作fdisk /dev/sdbparted /dev/sdb# 格式化分区mkfs.ext4 /dev/sdb1mkfs.xfs /dev/sdb1\n\n4.2 挂载管理# 挂载mount /dev/sdb1 /mnt/data# 卸载umount /mnt/data# 查看挂载df -hmount | grep sdb1# 永久挂载（/etc/fstab）echo &quot;/dev/sdb1 /mnt/data ext4 defaults 0 0&quot; &gt;&gt; /etc/fstab\n\n4.3 LVM 管理# 创建物理卷pvcreate /dev/sdb1# 创建卷组vgcreate vg_data /dev/sdb1# 创建逻辑卷lvcreate -L 100G -n lv_data vg_data# 扩展逻辑卷lvextend -L +50G /dev/vg_data/lv_dataresize2fs /dev/vg_data/lv_data\n\n4.4 磁盘空间分析# 查看磁盘使用df -hdf -i               # inode 使用# 查看目录大小du -sh /pathdu -h --max-depth=1 /path# 查找大文件find / -type f -size +100M\n\n\n5. 网络配置5.1 网络接口配置# 查看网络接口ip addrifconfig# 配置 IP 地址ip addr add 192.168.1.100/24 dev eth0ip link set eth0 up# 永久配置（CentOS/RHEL）vi /etc/sysconfig/network-scripts/ifcfg-eth0# 永久配置（Ubuntu/Debian）vi /etc/netplan/01-netcfg.yaml\n\n5.2 路由配置# 查看路由表ip routeroute -n# 添加默认网关ip route add default via 192.168.1.1# 添加静态路由ip route add 10.0.0.0/8 via 192.168.1.254\n\n5.3 DNS 配置# 查看 DNScat /etc/resolv.conf# 配置 DNSecho &quot;nameserver 8.8.8.8&quot; &gt;&gt; /etc/resolv.confecho &quot;nameserver 8.8.4.4&quot; &gt;&gt; /etc/resolv.conf\n\n5.4 防火墙配置# firewalld（CentOS/RHEL）systemctl start firewalldfirewall-cmd --add-port=80/tcp --permanentfirewall-cmd --reload# ufw（Ubuntu/Debian）ufw enableufw allow 80/tcpufw status# iptablesiptables -A INPUT -p tcp --dport 80 -j ACCEPTiptables-save &gt; /etc/iptables/rules.v4\n\n\n6. 系统日志6.1 日志文件位置# 系统日志/var/log/messages          # CentOS/RHEL/var/log/syslog            # Ubuntu/Debian# 安全日志/var/log/secure            # CentOS/RHEL/var/log/auth.log          # Ubuntu/Debian# 应用日志/var/log/nginx//var/log/apache2//var/log/mysql/\n\n6.2 日志查看命令# 查看日志tail -f /var/log/messagestail -100 /var/log/messages# 搜索日志grep &quot;error&quot; /var/log/messagesjournalctl -u nginx -f# 日志轮转logrotate -f /etc/logrotate.conf\n\n6.3 systemd 日志# 查看系统日志journalctljournalctl -f              # 实时查看journalctl -xe             # 查看详细错误# 按服务查看journalctl -u nginxjournalctl -u sshd# 按时间查看journalctl --since &quot;2024-01-01&quot;journalctl --since &quot;1 hour ago&quot;\n\n\n7. 常用运维命令7.1 系统维护# 更新系统yum update -y              # CentOS/RHELapt update &amp;&amp; apt upgrade -y   # Ubuntu/Debian# 清理缓存yum clean allapt clean# 重启服务systemctl restart servicesystemctl reload service# 查看服务状态systemctl status service\n\n7.2 性能监控# CPU 监控topmpstat 1 5# 内存监控free -hvmstat 1 5# 磁盘 I/Oiostat -x 1 5iotop# 网络监控iftopnethogs\n\n7.3 故障排查# 网络连接测试ping hosttraceroute hosttelnet host portnc -zv host port# 端口占用netstat -tulpnss -tulpnlsof -i :80# 系统调用追踪strace -p PID\n\n\n附录：常用快捷键\n\n\n快捷键\n功能\n\n\n\nCtrl+C\n终止当前命令\n\n\nCtrl+Z\n挂起当前命令\n\n\nCtrl+D\n退出终端\n\n\nCtrl+L\n清屏\n\n\nCtrl+R\n搜索历史命令\n\n\nTab\n自动补全\n\n\nCtrl+A\n移动到行首\n\n\nCtrl+E\n移动到行尾\n\n\n\n文档版本: 1.0最后更新: 2026-02-27适用系统: CentOS&#x2F;RHEL, Ubuntu&#x2F;Debian\n","categories":["系统部署与运维管理"]},{"title":"Nginx 服务器配置与运维手册","url":"/2026/02/28/02-Nginx%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%E4%B8%8E%E8%BF%90%E7%BB%B4%E6%89%8B%E5%86%8C/","content":"Nginx 服务器配置与运维手册目录\nNginx 安装与部署\n核心配置详解\n虚拟主机配置\n反向代理配置\n负载均衡配置\nSSL&#x2F;HTTPS配置\n性能优化\n日常运维\n故障排查\n\n\n1. Nginx 安装与部署1.1 CentOS&#x2F;RHEL 安装# 添加 Nginx 仓库yum install -y yum-utilscat &gt; /etc/yum.repos.d/nginx.repo &lt;&lt; EOF[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/\\$releasever/\\$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keyEOF# 安装 Nginxyum install -y nginx# 启动并设置开机自启systemctl start nginxsystemctl enable nginx\n\n1.2 Ubuntu&#x2F;Debian 安装# 添加 Nginx 仓库apt install -y curl gnupg2 ca-certificates lsb-releasecurl -fsSL https://nginx.org/keys/nginx_signing.key | gpg --dearmor -o /usr/share/keyrings/nginx-archive-keyring.gpgecho &quot;deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] http://nginx.org/packages/debian `lsb_release -cs` nginx&quot; | tee /etc/apt/sources.list.d/nginx.list# 安装 Nginxapt updateapt install -y nginx# 启动并设置开机自启systemctl start nginxsystemctl enable nginx\n\n1.3 验证安装# 查看版本nginx -v# 测试配置文件nginx -t# 检查运行状态systemctl status nginx# 查看监听端口ss -tulpn | grep nginx\n\n\n2. 核心配置详解2.1 配置文件结构# 主配置文件/etc/nginx/nginx.conf# 配置目录/etc/nginx/conf.d/# 日志目录/var/log/nginx/# 网站根目录/usr/share/nginx/html/\n\n2.2 nginx.conf 核心配置# 运行用户和组user nginx;worker_processes auto;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;# 事件模块events &#123;    worker_connections 10240;    use epoll;    multi_accept on;&#125;# HTTP 模块http &#123;    include /etc/nginx/mime.types;    default_type application/octet-stream;    # 日志格式    log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;                    &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;                    &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    access_log /var/log/nginx/access.log main;    # 性能优化    sendfile on;    tcp_nopush on;    tcp_nodelay on;    keepalive_timeout 65;    types_hash_max_size 2048;    # Gzip 压缩    gzip on;    gzip_vary on;    gzip_proxied any;    gzip_comp_level 6;    gzip_types text/plain text/css text/xml application/json application/javascript application/xml;    # 包含其他配置    include /etc/nginx/conf.d/*.conf;&#125;\n\n\n3. 虚拟主机配置3.1 基于域名的虚拟主机server &#123;    listen 80;    server_name example.com www.example.com;    root /var/www/example;    index index.html index.htm;    location / &#123;        try_files $uri $uri/ =404;    &#125;    # 错误页面    error_page 404 /404.html;    error_page 500 502 503 504 /50x.html;&#125;\n\n3.2 基于端口的虚拟主机server &#123;    listen 8080;    server_name _;    root /var/www/app1;&#125;server &#123;    listen 8081;    server_name _;    root /var/www/app2;&#125;\n\n3.3 基于 IP 的虚拟主机server &#123;    listen 192.168.1.10:80;    server_name _;    root /var/www/site1;&#125;server &#123;    listen 192.168.1.11:80;    server_name _;    root /var/www/site2;&#125;\n\n\n4. 反向代理配置4.1 基础反向代理server &#123;    listen 80;    server_name proxy.example.com;    location / &#123;        proxy_pass http://127.0.0.1:8080;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        proxy_set_header X-Forwarded-Proto $scheme;    &#125;&#125;\n\n4.2 带缓存的反向代理proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:100m max_size=10g inactive=60m;server &#123;    location / &#123;        proxy_pass http://backend;        proxy_cache my_cache;        proxy_cache_valid 200 302 10m;        proxy_cache_valid 404 1m;        proxy_cache_key $scheme$request_method$host$request_uri;        add_header X-Cache-Status $upstream_cache_status;    &#125;&#125;\n\n4.3 WebSocket 代理location /ws/ &#123;    proxy_pass http://backend;    proxy_http_version 1.1;    proxy_set_header Upgrade $http_upgrade;    proxy_set_header Connection &quot;upgrade&quot;;    proxy_set_header Host $host;    proxy_read_timeout 86400;&#125;\n\n\n5. 负载均衡配置5.1 轮询（默认）upstream backend &#123;    server 192.168.1.10:8080;    server 192.168.1.11:8080;    server 192.168.1.12:8080;&#125;server &#123;    location / &#123;        proxy_pass http://backend;    &#125;&#125;\n\n5.2 权重分配upstream backend &#123;    server 192.168.1.10:8080 weight=3;    server 192.168.1.11:8080 weight=2;    server 192.168.1.12:8080 weight=1;&#125;\n\n5.3 IP Hashupstream backend &#123;    ip_hash;    server 192.168.1.10:8080;    server 192.168.1.11:8080;    server 192.168.1.12:8080;&#125;\n\n5.4 最少连接upstream backend &#123;    least_conn;    server 192.168.1.10:8080;    server 192.168.1.11:8080;    server 192.168.1.12:8080;&#125;\n\n5.5 健康检查upstream backend &#123;    server 192.168.1.10:8080 max_fails=3 fail_timeout=30s;    server 192.168.1.11:8080 max_fails=3 fail_timeout=30s;    server 192.168.1.12:8080 backup;&#125;\n\n\n6. SSL&#x2F;HTTPS 配置6.1 自签名证书# 生成私钥openssl genrsa -out server.key 2048# 生成 CSRopenssl req -new -key server.key -out server.csr# 生成证书openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt\n\n6.2 HTTPS 配置server &#123;    listen 443 ssl http2;    server_name example.com;    ssl_certificate /etc/nginx/ssl/server.crt;    ssl_certificate_key /etc/nginx/ssl/server.key;    ssl_protocols TLSv1.2 TLSv1.3;    ssl_ciphers HIGH:!aNULL:!MD5;    ssl_prefer_server_ciphers on;    ssl_session_cache shared:SSL:10m;    ssl_session_timeout 10m;    location / &#123;        root /var/www/example;        index index.html;    &#125;&#125;# HTTP 重定向到 HTTPSserver &#123;    listen 80;    server_name example.com;    return 301 https://$server_name$request_uri;&#125;\n\n6.3 Let’s Encrypt 证书# 安装 certbotyum install -y certbot python3-certbot-nginx# 获取证书certbot --nginx -d example.com -d www.example.com# 自动续期certbot renew --dry-run\n\n\n7. 性能优化7.1 Worker 进程优化worker_processes auto;worker_rlimit_nofile 65535;events &#123;    worker_connections 65535;    multi_accept on;    use epoll;&#125;\n\n7.2 缓存优化# 静态文件缓存location ~* \\.(jpg|jpeg|png|gif|ico|css|js)$ &#123;    expires 30d;    add_header Cache-Control &quot;public, immutable&quot;;&#125;# 开启缓存proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=STATIC:100m max_size=10g;\n\n7.3 Gzip 压缩gzip on;gzip_vary on;gzip_min_length 1024;gzip_proxied expired no-cache no-store private auth;gzip_comp_level 6;gzip_types text/plain text/css text/xml application/json application/javascript application/xml+rss application/atom+xml image/svg+xml;\n\n7.4 连接优化keepalive_timeout 65;keepalive_requests 100;tcp_nopush on;tcp_nodelay on;\n\n\n8. 日常运维8.1 服务管理# 启动/停止/重启systemctl start nginxsystemctl stop nginxsystemctl restart nginx# 重载配置（不中断服务）systemctl reload nginxnginx -s reload# 查看状态systemctl status nginx\n\n8.2 配置测试# 测试配置文件语法nginx -t# 显示配置信息nginx -T\n\n8.3 日志管理# 查看访问日志tail -f /var/log/nginx/access.log# 查看错误日志tail -f /var/log/nginx/error.log# 日志轮转logrotate -f /etc/logrotate.d/nginx\n\n8.4 性能监控# 查看连接数ss -s | grep nginx# 查看活动连接curl http://localhost/nginx_status# 监控请求数awk &#x27;&#123;print $7&#125;&#x27; /var/log/nginx/access.log | sort | uniq -c | sort -rn\n\n\n9. 故障排查9.1 常见问题Nginx 无法启动\n# 检查端口占用ss -tulpn | grep :80# 检查配置文件nginx -t# 查看错误日志tail -50 /var/log/nginx/error.log\n\n502 Bad Gateway\n# 检查后端服务systemctl status backend-service# 检查 upstream 配置# 确认后端服务器可访问curl -I http://backend-server:port\n\n403 Forbidden\n# 检查文件权限ls -la /var/www/html# 检查 SELinuxgetenforcesetenforce 0  # 临时禁用测试\n\n404 Not Found\n# 检查 root 路径配置# 检查文件是否存在ls -la /var/www/html/filename# 检查 try_files 配置\n\n9.2 调试模式# 增加日志详细程度error_log /var/log/nginx/error.log debug;# 开启调试日志后重启systemctl restart nginx\n\n\n文档版本: 1.0最后更新: 2026-02-27适用版本: Nginx 1.20+\n","categories":["软件部署与运维管理"]},{"title":"Kubernetes 集群运维指南","url":"/2026/02/28/04-Kubernetes%E9%9B%86%E7%BE%A4%E8%BF%90%E7%BB%B4%E6%8C%87%E5%8D%97/","content":"Kubernetes 集群运维指南目录\nKubernetes 架构概述\n集群部署\nkubectl 使用指南\n工作负载管理\n服务与网络\n存储管理\n配置管理\n集群监控\n故障排查\n备份与恢复\n\n\n1. Kubernetes 架构概述1.1 核心组件控制平面（Control Plane）\n\nkube-apiserver: API 服务器，集群的统一入口\netcd: 分布式键值存储，保存集群状态\nkube-scheduler: 负责 Pod 调度\nkube-controller-manager: 运行各种控制器\ncloud-controller-manager: 与云提供商交互\n\n节点组件（Node Components）\n\nkubelet: 节点代理，管理 Pod 生命周期\nkube-proxy: 网络代理，维护网络规则\n容器运行时: Docker, containerd, CRI-O\n\n1.2 核心概念Cluster（集群）├── Node（节点）│   ├── Pod（最小调度单元）│   │   └── Container（容器）├── Namespace（命名空间）└── Resource（资源）    ├── Deployment    ├── StatefulSet    ├── DaemonSet    ├── Service    ├── ConfigMap    └── Secret\n\n\n2. 集群部署2.1 kubeadm 部署Master 节点配置\n# 禁用 swapswapoff -ased -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab# 配置内核参数cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1EOFsysctl --system# 安装 containerdapt-get updateapt-get install -y containerdcontainerd config default &gt; /etc/containerd/config.tomlsed -i &#x27;s/SystemdCgroup = false/SystemdCgroup = true/&#x27; /etc/containerd/config.tomlsystemctl restart containerd# 安装 kubeadm, kubelet, kubectlapt-get updateapt-get install -y apt-transport-https ca-certificates curlcurl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpgecho &quot;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main&quot; | tee /etc/apt/sources.list.d/kubernetes.listapt-get updateapt-get install -y kubelet kubeadm kubectlapt-mark hold kubelet kubeadm kubectl\n\n初始化集群\n# 初始化 master 节点kubeadm init --pod-network-cidr=10.244.0.0/16# 配置 kubectlmkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/config# 安装网络插件（Flannel）kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml# 获取 join 命令kubeadm token create --print-join-command\n\nWorker 节点加入\n# 在 worker 节点执行 join 命令kubeadm join &lt;master-ip&gt;:&lt;master-port&gt; --token &lt;token&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;\n\n2.2 验证集群# 查看节点kubectl get nodes# 查看组件状态kubectl get componentstatuses# 查看系统 Podkubectl get pods -n kube-system\n\n\n3. kubectl 使用指南3.1 基本命令# 配置kubectl config viewkubectl config get-contextskubectl config use-context &lt;context-name&gt;# 查看资源kubectl get podskubectl get pods -n &lt;namespace&gt;kubectl get pods -o widekubectl get pods -o yamlkubectl get pods -o json# 详细描述kubectl describe pod &lt;pod-name&gt;kubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;# 日志kubectl logs &lt;pod-name&gt;kubectl logs -f &lt;pod-name&gt;kubectl logs &lt;pod-name&gt; -c &lt;container-name&gt;\n\n3.2 资源操作# 创建资源kubectl create -f manifest.yamlkubectl apply -f manifest.yamlkubectl apply -f ./directory/# 删除资源kubectl delete -f manifest.yamlkubectl delete pod &lt;pod-name&gt;kubectl delete namespace &lt;namespace&gt;# 编辑资源kubectl edit pod &lt;pod-name&gt;kubectl edit deployment &lt;deployment-name&gt;# 扩缩容kubectl scale deployment &lt;deployment-name&gt; --replicas=3\n\n3.3 进入容器# 进入 Podkubectl exec -it &lt;pod-name&gt; -- /bin/bashkubectl exec -it &lt;pod-name&gt; -c &lt;container-name&gt; -- /bin/sh# 在容器中执行命令kubectl exec &lt;pod-name&gt; -- ls -lakubectl exec &lt;pod-name&gt; -- cat /etc/hosts\n\n3.4 端口转发# 本地端口转发kubectl port-forward &lt;pod-name&gt; 8080:80kubectl port-forward deployment/&lt;deployment-name&gt; 8080:80# 服务端口转发kubectl port-forward svc/&lt;service-name&gt; 8080:80\n\n3.5 常用别名# 添加别名alias k=kubectlcomplete -o default -F __start_kubectl k# 常用别名alias kgp=&#x27;kubectl get pods&#x27;alias kgd=&#x27;kubectl get deployments&#x27;alias kgs=&#x27;kubectl get services&#x27;alias kgn=&#x27;kubectl get nodes&#x27;alias kgl=&#x27;kubectl get pods -o wide&#x27;alias kdp=&#x27;kubectl describe pod&#x27;alias kdd=&#x27;kubectl describe deployment&#x27;alias kaf=&#x27;kubectl apply -f&#x27;alias kdf=&#x27;kubectl delete -f&#x27;alias kl=&#x27;kubectl logs&#x27;alias klf=&#x27;kubectl logs -f&#x27;alias ke=&#x27;kubectl edit&#x27;alias kx=&#x27;kubectl delete pod&#x27;\n\n\n4. 工作负载管理4.1 DeploymentapiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deployment  namespace: defaultspec:  replicas: 3  selector:    matchLabels:      app: nginx  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.21        ports:        - containerPort: 80        resources:          requests:            memory: &quot;64Mi&quot;            cpu: &quot;250m&quot;          limits:            memory: &quot;128Mi&quot;            cpu: &quot;500m&quot;        readinessProbe:          httpGet:            path: /            port: 80          initialDelaySeconds: 5          periodSeconds: 10        livenessProbe:          httpGet:            path: /            port: 80          initialDelaySeconds: 15          periodSeconds: 20\n\n4.2 StatefulSetapiVersion: apps/v1kind: StatefulSetmetadata:  name: mysqlspec:  serviceName: &quot;mysql&quot;  replicas: 3  selector:    matchLabels:      app: mysql  template:    metadata:      labels:        app: mysql    spec:      containers:      - name: mysql        image: mysql:5.7        ports:        - containerPort: 3306        volumeMounts:        - name: data          mountPath: /var/lib/mysql        env:        - name: MYSQL_ROOT_PASSWORD          valueFrom:            secretKeyRef:              name: mysql-secret              key: password  volumeClaimTemplates:  - metadata:      name: data    spec:      accessModes: [&quot;ReadWriteOnce&quot;]      resources:        requests:          storage: 10Gi\n\n4.3 DaemonSetapiVersion: apps/v1kind: DaemonSetmetadata:  name: node-exporter  namespace: monitoringspec:  selector:    matchLabels:      app: node-exporter  template:    metadata:      labels:        app: node-exporter    spec:      hostNetwork: true      hostPID: true      containers:      - name: node-exporter        image: prom/node-exporter:latest        ports:        - containerPort: 9100          hostPort: 9100\n\n4.4 Job &amp; CronJob# JobapiVersion: batch/v1kind: Jobmetadata:  name: backup-jobspec:  template:    spec:      containers:      - name: backup        image: backup-tool:latest        command: [&quot;./backup.sh&quot;]      restartPolicy: OnFailure  backoffLimit: 3---# CronJobapiVersion: batch/v1kind: CronJobmetadata:  name: backup-cronjobspec:  schedule: &quot;0 2 * * *&quot;  # 每天凌晨 2 点  jobTemplate:    spec:      template:        spec:          containers:          - name: backup            image: backup-tool:latest          restartPolicy: OnFailure\n\n\n5. 服务与网络5.1 Service 类型# ClusterIP（默认）apiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app: myapp  ports:  - port: 80    targetPort: 8080  type: ClusterIP---# NodePortapiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app: myapp  ports:  - port: 80    targetPort: 8080    nodePort: 30080  type: NodePort---# LoadBalancerapiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app: myapp  ports:  - port: 80    targetPort: 8080  type: LoadBalancer---# Headless ServiceapiVersion: v1kind: Servicemetadata:  name: headless-servicespec:  clusterIP: None  selector:    app: myapp  ports:  - port: 80\n\n5.2 IngressapiVersion: networking.k8s.io/v1kind: Ingressmetadata:  name: my-ingress  annotations:    nginx.ingress.kubernetes.io/rewrite-target: /spec:  rules:  - host: example.com    http:      paths:      - path: /        pathType: Prefix        backend:          service:            name: web-service            port:              number: 80      - path: /api        pathType: Prefix        backend:          service:            name: api-service            port:              number: 8080  tls:  - hosts:    - example.com    secretName: tls-secret\n\n5.3 Network PolicyapiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata:  name: deny-all  namespace: defaultspec:  podSelector: &#123;&#125;  policyTypes:  - Ingress  - Egress---apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata:  name: allow-web  namespace: defaultspec:  podSelector:    matchLabels:      app: web  policyTypes:  - Ingress  ingress:  - from:    - namespaceSelector:        matchLabels:          name: ingress-nginx    ports:    - protocol: TCP      port: 80\n\n\n6. 存储管理6.1 Volume 类型# emptyDirvolumes:- name: cache  emptyDir: &#123;&#125;# hostPathvolumes:- name: log-volume  hostPath:    path: /var/log    type: Directory# PersistentVolumeClaimvolumes:- name: data-volume  persistentVolumeClaim:    claimName: my-pvc# ConfigMapvolumes:- name: config  configMap:    name: my-config# Secretvolumes:- name: secret  secret:    secretName: my-secret\n\n6.2 PersistentVolumeapiVersion: v1kind: PersistentVolumemetadata:  name: pv-dataspec:  capacity:    storage: 10Gi  accessModes:  - ReadWriteOnce  persistentVolumeReclaimPolicy: Retain  storageClassName: manual  hostPath:    path: /mnt/data---apiVersion: v1kind: PersistentVolumeClaimmetadata:  name: pvc-dataspec:  accessModes:  - ReadWriteOnce  resources:    requests:      storage: 10Gi  storageClassName: manual\n\n6.3 StorageClassapiVersion: storage.k8s.io/v1kind: StorageClassmetadata:  name: fastprovisioner: kubernetes.io/aws-ebsparameters:  type: gp2  fsType: ext4reclaimPolicy: RetainallowVolumeExpansion: truevolumeBindingMode: WaitForFirstConsumer\n\n\n7. 配置管理7.1 ConfigMapapiVersion: v1kind: ConfigMapmetadata:  name: app-configdata:  app.properties: |    server.port=8080    database.host=mysql  LOG_LEVEL: INFO  ENVIRONMENT: production---# 使用 ConfigMapapiVersion: v1kind: Podmetadata:  name: my-podspec:  containers:  - name: my-container    image: myapp    envFrom:    - configMapRef:        name: app-config    volumeMounts:    - name: config      mountPath: /etc/config  volumes:  - name: config    configMap:      name: app-config\n\n7.2 SecretapiVersion: v1kind: Secretmetadata:  name: db-secrettype: Opaquedata:  username: YWRtaW4=  # base64 encoded  password: cGFzc3dvcmQxMjM=---# 使用 SecretapiVersion: v1kind: Podmetadata:  name: my-podspec:  containers:  - name: my-container    image: myapp    env:    - name: DB_USERNAME      valueFrom:        secretKeyRef:          name: db-secret          key: username    - name: DB_PASSWORD      valueFrom:        secretKeyRef:          name: db-secret          key: password\n\n\n8. 集群监控8.1 Metrics Server# 安装 Metrics Serverkubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml# 查看资源使用kubectl top nodeskubectl top pods\n\n8.2 Prometheus + Grafana# 使用 Helm 安装helm repo add prometheus-community https://prometheus-community.github.io/helm-chartshelm install monitoring prometheus-community/kube-prometheus-stack -n monitoring --create-namespace# 访问 Grafanakubectl port-forward svc/monitoring-grafana -n monitoring 3000:80\n\n8.3 日志收集# 使用 EFK Stack# Elasticsearch + Fluentd + Kibana# 或使用 Loki + Promtailhelm repo add grafana https://grafana.github.io/helm-chartshelm install loki grafana/loki-stack -n logging --create-namespace\n\n\n9. 故障排查9.1 常见问题Pod 无法启动\n# 查看 Pod 状态kubectl get pods -o widekubectl describe pod &lt;pod-name&gt;# 查看日志kubectl logs &lt;pod-name&gt;kubectl logs &lt;pod-name&gt; --previous# 检查事件kubectl get events --sort-by=&#x27;.lastTimestamp&#x27;\n\nPod 处于 Pending 状态\n# 检查资源kubectl describe pod &lt;pod-name&gt;kubectl top nodes# 检查调度kubectl get events | grep &lt;pod-name&gt;\n\n节点 NotReady\n# 检查节点状态kubectl describe node &lt;node-name&gt;# 检查 kubeletsystemctl status kubeletjournalctl -u kubelet -f# 检查网络kubectl get pods -n kube-system -o wide\n\n9.2 调试工具# 临时调试容器kubectl debug -it &lt;pod-name&gt; --image=busybox# 创建调试 Podkubectl run -it --rm debug --image=busybox --restart=Never# 网络调试kubectl run -it --rm netshoot --image=nicolaka/netshoot --restart=Never\n\n\n10. 备份与恢复10.1 etcd 备份# 备份 etcdETCDCTL_API=3 etcdctl snapshot save snapshot.db \\  --endpoints=https://127.0.0.1:2379 \\  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\  --cert=/etc/kubernetes/pki/etcd/server.crt \\  --key=/etc/kubernetes/pki/etcd/server.key# 恢复 etcdETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\  --data-dir=/var/lib/etcd-restore\n\n10.2 资源备份# 备份所有资源kubectl get all --all-namespaces -o yaml &gt; all-resources.yaml# 备份特定命名空间kubectl get all -n &lt;namespace&gt; -o yaml &gt; namespace-resources.yaml# 使用 velerovelero backup create daily-backup --include-namespaces default,productionvelero backup getvelero restore create --from-backup daily-backup\n\n\n文档版本: 1.0最后更新: 2026-02-27适用版本: Kubernetes 1.23+\n","categories":["软件部署与运维管理"]},{"title":"Docker 容器化运维实践","url":"/2026/02/28/03-Docker%E5%AE%B9%E5%99%A8%E5%8C%96%E8%BF%90%E7%BB%B4%E5%AE%9E%E8%B7%B5/","content":"Docker 容器化运维实践目录\nDocker 安装与配置\n镜像管理\n容器管理\nDockerfile 编写\n数据卷管理\n网络管理\nDocker Compose\n容器监控与日志\n安全最佳实践\n\n\n1. Docker 安装与配置1.1 CentOS&#x2F;RHEL 安装# 卸载旧版本yum remove -y docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine# 安装 yum 工具包yum install -y yum-utils# 添加 Docker 仓库yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo# 安装 Dockeryum install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin# 启动 Dockersystemctl start dockersystemctl enable docker# 验证安装docker --versiondocker run hello-world\n\n1.2 Ubuntu&#x2F;Debian 安装# 卸载旧版本apt-get remove -y docker docker-engine docker.io containerd runc# 安装依赖apt-get updateapt-get install -y ca-certificates curl gnupg lsb-release# 添加 GPG 密钥curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg# 添加仓库echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | tee /etc/apt/sources.list.d/docker.list &gt; /dev/null# 安装 Dockerapt-get updateapt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin# 启动 Dockersystemctl start dockersystemctl enable docker\n\n1.3 配置镜像加速器# 创建/编辑配置文件cat &gt; /etc/docker/daemon.json &lt;&lt; EOF&#123;  &quot;registry-mirrors&quot;: [    &quot;https://docker.mirrors.ustc.edu.cn&quot;,    &quot;https://registry.docker-cn.com&quot;  ],  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],  &quot;log-driver&quot;: &quot;json-file&quot;,  &quot;log-opts&quot;: &#123;    &quot;max-size&quot;: &quot;100m&quot;,    &quot;max-file&quot;: &quot;3&quot;  &#125;&#125;EOF# 重启 Dockersystemctl daemon-reloadsystemctl restart docker\n\n1.4 配置非 root 用户使用 Docker# 创建 docker 组groupadd docker# 添加用户到 docker 组usermod -aG docker $USER# 应用组变更newgrp docker# 验证docker run hello-world\n\n\n2. 镜像管理2.1 镜像操作# 搜索镜像docker search nginxdocker search --filter is-official=true nginx# 拉取镜像docker pull nginx:latestdocker pull nginx:1.21# 查看本地镜像docker imagesdocker image ls# 查看镜像详情docker inspect nginx# 查看镜像历史docker history nginx\n\n2.2 镜像管理# 删除镜像docker rmi nginx:latestdocker image rm nginx:latest# 删除所有悬空镜像docker image prune# 删除所有未使用镜像docker image prune -a# 镜像标签docker tag nginx:latest myrepo/nginx:v1.0# 保存镜像docker save -o nginx.tar nginx:latestdocker save nginx:latest | gzip &gt; nginx.tar.gz# 加载镜像docker load -i nginx.tardocker load &lt; nginx.tar.gz\n\n2.3 构建镜像# 基于 Dockerfile 构建docker build -t myapp:v1.0 .# 指定 Dockerfiledocker build -f Dockerfile.prod -t myapp:prod .# 构建参数docker build --build-arg VERSION=1.0 -t myapp:v1.0 .# 无缓存构建docker build --no-cache -t myapp:v1.0 .\n\n2.4 推送镜像# 登录 Docker Hubdocker login# 推送镜像docker push myrepo/myapp:v1.0# 推送所有标签docker push myrepo/myapp --all-tags\n\n\n3. 容器管理3.1 创建与启动# 运行容器docker run -d --name my-nginx -p 80:80 nginx# 交互式运行docker run -it --name my-container ubuntu:20.04 /bin/bash# 指定资源限制docker run -d --name myapp --memory=&quot;512m&quot; --cpus=&quot;1.0&quot; myapp:v1.0# 环境变量docker run -d --name myapp -e ENV=production -e DB_HOST=localhost myapp:v1.0# 挂载卷docker run -d --name myapp -v /host/data:/container/data myapp:v1.0\n\n3.2 容器操作# 查看运行中的容器docker ps# 查看所有容器docker ps -a# 查看容器详情docker inspect container_name# 进入容器docker exec -it container_name /bin/bashdocker exec -it container_name /bin/sh# 查看容器日志docker logs container_namedocker logs -f container_namedocker logs --tail 100 container_name# 查看容器资源使用docker statsdocker stats container_name\n\n3.3 容器控制# 停止容器docker stop container_namedocker stop $(docker ps -q)# 启动容器docker start container_name# 重启容器docker restart container_name# 暂停/恢复容器docker pause container_namedocker unpause container_name# 删除容器docker rm container_namedocker rm -f container_name  # 强制删除运行中的容器docker rm $(docker ps -a -q)  # 删除所有容器\n\n3.4 容器文件操作# 从容器复制文件到主机docker cp container_name:/path/to/file /host/path/# 从主机复制文件到容器docker cp /host/path/file container_name:/container/path/# 查看容器文件系统变更docker diff container_name\n\n\n4. Dockerfile 编写4.1 基础结构# 基础镜像FROM ubuntu:20.04# 维护者信息LABEL maintainer=&quot;your@email.com&quot;# 环境变量ENV APP_HOME=/appENV NODE_ENV=production# 工作目录WORKDIR $APP_HOME# 复制文件COPY package*.json ./COPY . .# 安装依赖RUN apt-get update &amp;&amp; apt-get install -y \\    curl \\    &amp;&amp; rm -rf /var/lib/apt/lists/*# 暴露端口EXPOSE 8080# 启动命令CMD [&quot;node&quot;, &quot;server.js&quot;]# 或者使用 ENTRYPOINTENTRYPOINT [&quot;node&quot;]CMD [&quot;server.js&quot;]\n\n4.2 多阶段构建# 构建阶段FROM node:16 AS builderWORKDIR /appCOPY package*.json ./RUN npm ciCOPY . .RUN npm run build# 生产阶段FROM node:16-alpineWORKDIR /appCOPY --from=builder /app/dist ./distCOPY --from=builder /app/node_modules ./node_modulesCOPY package*.json ./EXPOSE 8080CMD [&quot;node&quot;, &quot;dist/server.js&quot;]\n\n4.3 最佳实践# 使用具体版本的基础镜像FROM node:16.13.0-alpine# 合并 RUN 指令减少层数RUN apk add --no-cache \\    curl \\    git \\    &amp;&amp; rm -rf /var/cache/apk/*# 使用 .dockerignore# .git# node_modules# *.log# .env# 非 root 用户运行RUN addgroup -g 1001 -S nodejs &amp;&amp; \\    adduser -S nodejs -u 1001USER nodejs# 健康检查HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\    CMD curl -f http://localhost:8080/health || exit 1\n\n\n5. 数据卷管理5.1 数据卷类型# 绑定挂载docker run -v /host/path:/container/path nginx# 命名卷docker volume create mydatadocker run -v mydata:/container/data nginx# 只读挂载docker run -v /host/path:/container/path:ro nginx\n\n5.2 卷操作# 创建卷docker volume create myvolume# 查看卷docker volume lsdocker volume inspect myvolume# 删除卷docker volume rm myvolume# 删除未使用卷docker volume prune# 备份卷docker run --rm -v myvolume:/data -v $(pwd):/backup alpine tar cvf /backup/backup.tar /data# 恢复卷docker run --rm -v myvolume:/data -v $(pwd):/backup alpine tar xvf /backup/backup.tar -C /\n\n\n6. 网络管理6.1 网络类型# 查看网络docker network ls# 创建网络docker network create mynetworkdocker network create --driver bridge --subnet 172.20.0.0/16 mynetwork# 查看网络详情docker network inspect mynetwork\n\n6.2 容器网络连接# 运行时连接网络docker run -d --network mynetwork --name web nginx# 运行中连接网络docker network connect mynetwork container_name# 断开网络docker network disconnect mynetwork container_name\n\n6.3 容器间通信# 同一网络内的容器可以通过名称通信docker run -d --network mynetwork --name db postgresdocker run -d --network mynetwork --name web -e DB_HOST=db myapp# 使用 link（已废弃，不推荐）docker run -d --name web --link db:database myapp\n\n\n7. Docker Compose7.1 安装# Docker Compose V2（作为 Docker 插件）# 已随 Docker 一起安装# 验证docker compose version\n\n7.2 docker-compose.yml 示例version: &#x27;3.8&#x27;services:  web:    build: .    ports:      - &quot;8080:8080&quot;    environment:      - NODE_ENV=production      - DB_HOST=db    depends_on:      - db    networks:      - app-network    restart: unless-stopped    volumes:      - ./logs:/app/logs  db:    image: postgres:13    environment:      - POSTGRES_USER=myuser      - POSTGRES_PASSWORD=mypassword      - POSTGRES_DB=mydb    volumes:      - postgres-data:/var/lib/postgresql/data    networks:      - app-network    restart: unless-stopped  redis:    image: redis:6-alpine    networks:      - app-network    restart: unless-stoppednetworks:  app-network:    driver: bridgevolumes:  postgres-data:\n\n7.3 Compose 常用命令# 启动服务docker compose up -d# 停止服务docker compose down# 查看日志docker compose logs -fdocker compose logs -f web# 查看状态docker compose ps# 重启服务docker compose restart# 重建服务docker compose up -d --build# 执行命令docker compose exec web /bin/bash# 查看资源使用docker compose top\n\n\n8. 容器监控与日志8.1 资源监控# 实时资源使用docker stats# 一次性快照docker stats --no-stream# 查看容器进程docker top container_name\n\n8.2 日志管理# 查看日志docker logs container_namedocker logs -f container_namedocker logs --tail 100 container_namedocker logs --since 1h container_namedocker logs --until 10m container_name# 日志驱动配置# 在 daemon.json 中配置&#123;  &quot;log-driver&quot;: &quot;json-file&quot;,  &quot;log-opts&quot;: &#123;    &quot;max-size&quot;: &quot;10m&quot;,    &quot;max-file&quot;: &quot;3&quot;  &#125;&#125;\n\n8.3 监控方案# 使用 cAdvisordocker run -d \\  --name=cadvisor \\  --volume=/:/rootfs:ro \\  --volume=/var/run:/var/run:ro \\  --volume=/sys:/sys:ro \\  --volume=/var/lib/docker/:/var/lib/docker:ro \\  --publish=8080:8080 \\  google/cadvisor:latest# 使用 Prometheus + Grafana# 参考 Prometheus 官方文档配置\n\n\n9. 安全最佳实践9.1 镜像安全# 使用官方镜像FROM node:16-alpine# 扫描镜像漏洞docker scan myapp:v1.0# 使用固定版本FROM node:16.13.0-alpine\n\n9.2 容器安全# 非 root 用户运行docker run -u 1000:1000 myapp# 只读文件系统docker run --read-only myapp# 限制能力docker run --cap-drop=ALL --cap-add=NET_BIND_SERVICE myapp# 禁用网络docker run --network none myapp\n\n9.3 网络安全# 仅暴露必要端口docker run -p 127.0.0.1:8080:8080 myapp# 使用内部网络docker network create --internal internal-net\n\n9.4 密钥管理# 使用 Docker Secrets（Swarm 模式）echo &quot;mypassword&quot; | docker secret create db_password -# 使用环境变量（不推荐敏感信息）docker run -e DB_PASSWORD=mypassword myapp# 使用密钥管理工具# Docker Secrets, HashiCorp Vault 等\n\n\n文档版本: 1.0最后更新: 2026-02-27适用版本: Docker 20.10+, Docker Compose V2\n","categories":["软件部署与运维管理"]},{"title":"MySQL 数据库运维手册","url":"/2026/02/28/05-MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%90%E7%BB%B4%E6%89%8B%E5%86%8C/","content":"MySQL 数据库运维手册目录\nMySQL 安装与配置\n用户与权限管理\n数据库操作\n备份与恢复\n性能优化\n主从复制\n监控与诊断\n安全加固\n日常维护\n\n\n1. MySQL 安装与配置1.1 CentOS&#x2F;RHEL 安装# 下载 MySQL YUM 仓库wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpmyum localinstall -y mysql80-community-release-el7-3.noarch.rpm# 安装 MySQLyum install -y mysql-community-server# 启动 MySQLsystemctl start mysqldsystemctl enable mysqld# 查看临时密码grep &#x27;temporary password&#x27; /var/log/mysqld.log# 安全初始化mysql_secure_installation\n\n1.2 Ubuntu&#x2F;Debian 安装# 下载 MySQL APT 仓库wget https://dev.mysql.com/get/mysql-apt-config_0.8.22-1_all.debdpkg -i mysql-apt-config_0.8.22-1_all.debapt-get update# 安装 MySQLapt-get install -y mysql-server# 启动 MySQLsystemctl start mysqlsystemctl enable mysql# 安全初始化mysql_secure_installation\n\n1.3 配置文件# /etc/my.cnf 或 /etc/mysql/mysql.conf.d/mysqld.cnf[mysqld]# 基础配置port = 3306socket = /var/lib/mysql/mysql.sockdatadir = /var/lib/mysqlpid-file = /var/run/mysqld/mysqld.pid# 字符集character-set-server = utf8mb4collation-server = utf8mb4_unicode_ci# 连接配置max_connections = 500max_connect_errors = 10000wait_timeout = 28800interactive_timeout = 28800# InnoDB 配置innodb_buffer_pool_size = 1Ginnodb_log_file_size = 256Minnodb_log_buffer_size = 16Minnodb_flush_log_at_trx_commit = 1innodb_flush_method = O_DIRECT# 日志配置log_error = /var/log/mysql/error.logslow_query_log = 1slow_query_log_file = /var/log/mysql/slow.loglong_query_time = 2log_queries_not_using_indexes = 1# 二进制日志log_bin = /var/log/mysql/mysql-binbinlog_format = ROWexpire_logs_days = 7max_binlog_size = 100M[client]default-character-set = utf8mb4\n\n\n2. 用户与权限管理2.1 用户管理-- 创建用户CREATE USER &#x27;app_user&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;password123&#x27;;CREATE USER &#x27;app_user&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;password123&#x27;;-- 修改密码ALTER USER &#x27;app_user&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;newpassword&#x27;;SET PASSWORD FOR &#x27;app_user&#x27;@&#x27;localhost&#x27; = PASSWORD(&#x27;newpassword&#x27;);-- 删除用户DROP USER &#x27;app_user&#x27;@&#x27;localhost&#x27;;-- 查看用户SELECT user, host FROM mysql.user;SHOW GRANTS FOR &#x27;app_user&#x27;@&#x27;localhost&#x27;;\n\n2.2 权限管理-- 授予权限GRANT ALL PRIVILEGES ON database.* TO &#x27;app_user&#x27;@&#x27;localhost&#x27;;GRANT SELECT, INSERT, UPDATE ON database.table TO &#x27;app_user&#x27;@&#x27;localhost&#x27;;GRANT REPLICATION SLAVE ON *.* TO &#x27;repl_user&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;password&#x27;;-- 撤销权限REVOKE DELETE ON database.* FROM &#x27;app_user&#x27;@&#x27;localhost&#x27;;-- 刷新权限FLUSH PRIVILEGES;-- 查看权限SHOW GRANTS FOR &#x27;app_user&#x27;@&#x27;localhost&#x27;;\n\n2.3 角色管理（MySQL 8.0+）-- 创建角色CREATE ROLE &#x27;read_only&#x27;, &#x27;read_write&#x27;;-- 授予角色权限GRANT SELECT ON *.* TO &#x27;read_only&#x27;;GRANT SELECT, INSERT, UPDATE, DELETE ON *.* TO &#x27;read_write&#x27;;-- 授予用户角色GRANT &#x27;read_write&#x27; TO &#x27;app_user&#x27;@&#x27;localhost&#x27;;-- 设置默认角色SET DEFAULT ROLE &#x27;read_write&#x27; TO &#x27;app_user&#x27;@&#x27;localhost&#x27;;\n\n\n3. 数据库操作3.1 数据库管理-- 创建数据库CREATE DATABASE mydb CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;-- 查看数据库SHOW DATABASES;SHOW CREATE DATABASE mydb;-- 选择数据库USE mydb;-- 删除数据库DROP DATABASE mydb;\n\n3.2 表管理-- 创建表CREATE TABLE users (    id INT AUTO_INCREMENT PRIMARY KEY,    username VARCHAR(50) NOT NULL UNIQUE,    email VARCHAR(100) NOT NULL,    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,    INDEX idx_email (email)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;-- 查看表SHOW TABLES;DESCRIBE users;SHOW CREATE TABLE users;-- 修改表ALTER TABLE users ADD COLUMN phone VARCHAR(20);ALTER TABLE users MODIFY COLUMN email VARCHAR(200);ALTER TABLE users ADD INDEX idx_phone (phone);-- 删除表DROP TABLE users;TRUNCATE TABLE users;\n\n3.3 数据操作-- 插入数据INSERT INTO users (username, email) VALUES (&#x27;john&#x27;, &#x27;john@example.com&#x27;);INSERT INTO users (username, email) VALUES (&#x27;jane&#x27;, &#x27;jane@example.com&#x27;), (&#x27;bob&#x27;, &#x27;bob@example.com&#x27;);-- 查询数据SELECT * FROM users;SELECT id, username FROM users WHERE id &gt; 10;SELECT COUNT(*) FROM users;-- 更新数据UPDATE users SET email = &#x27;new@example.com&#x27; WHERE id = 1;-- 删除数据DELETE FROM users WHERE id = 1;\n\n\n4. 备份与恢复4.1 mysqldump 备份# 备份单个数据库mysqldump -u root -p mydb &gt; mydb_backup.sql# 备份所有数据库mysqldump -u root -p --all-databases &gt; all_databases.sql# 备份特定表mysqldump -u root -p mydb users orders &gt; tables_backup.sql# 压缩备份mysqldump -u root -p mydb | gzip &gt; mydb_backup.sql.gz# 带时间戳备份mysqldump -u root -p mydb &gt; mydb_$(date +%Y%m%d_%H%M%S).sql# 仅备份结构mysqldump -u root -p --no-data mydb &gt; mydb_structure.sql# 仅备份数据mysqldump -u root -p --no-create-info mydb &gt; mydb_data.sql\n\n4.2 恢复备份# 恢复数据库mysql -u root -p mydb &lt; mydb_backup.sql# 恢复压缩备份gunzip &lt; mydb_backup.sql.gz | mysql -u root -p mydb# 恢复所有数据库mysql -u root -p &lt; all_databases.sql\n\n4.3 物理备份# 停止 MySQLsystemctl stop mysqld# 复制数据目录cp -r /var/lib/mysql /backup/mysql_backup_$(date +%Y%m%d)# 启动 MySQLsystemctl start mysqld\n\n4.4 增量备份# 启用二进制日志# 在 my.cnf 中配置log_bin = /var/log/mysql/mysql-binbinlog_format = ROW# 刷新二进制日志mysql -u root -p -e &quot;FLUSH LOGS;&quot;# 查看二进制日志SHOW BINARY LOGS;# 使用二进制日志恢复mysqlbinlog mysql-bin.000001 | mysql -u root -p\n\n\n5. 性能优化5.1 索引优化-- 查看索引使用情况EXPLAIN SELECT * FROM users WHERE email = &#x27;test@example.com&#x27;;EXPLAIN FORMAT=JSON SELECT * FROM users WHERE email = &#x27;test@example.com&#x27;;-- 创建索引CREATE INDEX idx_email ON users(email);CREATE INDEX idx_name_age ON users(name, age);-- 查看索引SHOW INDEX FROM users;-- 删除索引DROP INDEX idx_email ON users;\n\n5.2 查询优化-- 避免 SELECT *SELECT id, username, email FROM users;-- 使用 LIMITSELECT * FROM users LIMIT 100;-- 避免在索引列上使用函数-- 不推荐SELECT * FROM users WHERE DATE(created_at) = &#x27;2024-01-01&#x27;;-- 推荐SELECT * FROM users WHERE created_at &gt;= &#x27;2024-01-01&#x27; AND created_at &lt; &#x27;2024-01-02&#x27;;-- 使用 JOIN 代替子查询SELECT u.*, o.* FROM users u JOIN orders o ON u.id = o.user_id;\n\n5.3 配置优化# 关键性能参数# 缓冲池（建议设置为物理内存的 50-70%）innodb_buffer_pool_size = 4Ginnodb_buffer_pool_instances = 8# 日志配置innodb_log_file_size = 512Minnodb_log_buffer_size = 32M# 连接配置max_connections = 1000thread_cache_size = 50# 表缓存table_open_cache = 4000table_definition_cache = 2000# 排序和临时表sort_buffer_size = 4Mread_buffer_size = 2Mread_rnd_buffer_size = 4Mtmp_table_size = 256Mmax_heap_table_size = 256M\n\n5.4 慢查询分析-- 查看慢查询日志SHOW VARIABLES LIKE &#x27;slow_query_log%&#x27;;SHOW VARIABLES LIKE &#x27;long_query_time&#x27;;-- 查看慢查询统计SELECT * FROM mysql.slow_log;-- 使用 pt-query-digest 分析pt-query-digest /var/log/mysql/slow.log &gt; slow_query_analysis.txt\n\n\n6. 主从复制6.1 配置主服务器# my.cnf[mysqld]server-id = 1log_bin = /var/log/mysql/mysql-binbinlog_format = ROWbinlog_do_db = mydb\n\n-- 创建复制用户CREATE USER &#x27;repl&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;password&#x27;;GRANT REPLICATION SLAVE ON *.* TO &#x27;repl&#x27;@&#x27;%&#x27;;-- 查看主服务器状态SHOW MASTER STATUS;-- 记录 File 和 Position\n\n6.2 配置从服务器# my.cnf[mysqld]server-id = 2relay_log = /var/log/mysql/mysql-relay-binread_only = 1\n\n-- 配置主从关系CHANGE MASTER TO    MASTER_HOST=&#x27;master_ip&#x27;,    MASTER_USER=&#x27;repl&#x27;,    MASTER_PASSWORD=&#x27;password&#x27;,    MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;,    MASTER_LOG_POS=154;-- 启动复制START SLAVE;-- 查看复制状态SHOW SLAVE STATUS\\G-- 检查 Slave_IO_Running 和 Slave_SQL_Running 是否为 Yes\n\n6.3 主从切换-- 停止主服务器写入FLUSH TABLES WITH READ LOCK;-- 等待从服务器同步SHOW SLAVE STATUS\\G-- 检查 Seconds_Behind_Master 为 0-- 提升从服务器为主STOP SLAVE;RESET SLAVE ALL;-- 在新主服务器上创建复制用户-- 配置其他从服务器指向新主\n\n\n7. 监控与诊断7.1 状态监控-- 查看服务器状态SHOW STATUS;SHOW GLOBAL STATUS;-- 查看变量SHOW VARIABLES;SHOW GLOBAL VARIABLES;-- 查看进程SHOW PROCESSLIST;SHOW FULL PROCESSLIST;-- 查看引擎状态SHOW ENGINE INNODB STATUS\\G\n\n7.2 性能监控-- 查看连接数SHOW STATUS LIKE &#x27;Threads_connected&#x27;;SHOW STATUS LIKE &#x27;Max_used_connections&#x27;;-- 查看缓存命中率SHOW STATUS LIKE &#x27;Qcache_hits&#x27;;SHOW STATUS LIKE &#x27;Qcache_inserts&#x27;;-- 查看表锁SHOW STATUS LIKE &#x27;Table_locks_waited&#x27;;SHOW STATUS LIKE &#x27;Table_locks_immediate&#x27;;-- 查看 InnoDB 状态SHOW STATUS LIKE &#x27;Innodb_row_lock%&#x27;;\n\n7.3 监控工具# MySQL Enterprise Monitor# Percona Monitoring and Management (PMM)pmmd-server start# Prometheus + mysqld_exportermysqld_exporter --config.my-cnf=/etc/mysql/debian.cnf# Grafana 仪表盘# 导入 MySQL 官方仪表盘 ID: 7362\n\n\n8. 安全加固8.1 基础安全-- 删除匿名用户DELETE FROM mysql.user WHERE User=&#x27;&#x27;;-- 删除测试数据库DROP DATABASE IF EXISTS test;-- 修改 root 密码ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;strong_password&#x27;;-- 限制 root 远程登录UPDATE mysql.user SET Host=&#x27;localhost&#x27; WHERE User=&#x27;root&#x27;;FLUSH PRIVILEGES;\n\n8.2 网络安全# my.cnf[mysqld]# 绑定到特定 IPbind-address = 127.0.0.1# 禁用本地文件导入local_infile = 0# 跳过符号链接symbolic-links = 0\n\n# 防火墙配置firewall-cmd --add-port=3306/tcp --permanentfirewall-cmd --reload# 或使用 iptablesiptables -A INPUT -p tcp --dport 3306 -s 192.168.1.0/24 -j ACCEPT\n\n8.3 审计日志# 启用审计插件（MySQL Enterprise）[mysqld]plugin_load_add=audit_logaudit_log_policy=ALLaudit_log_format=JSON\n\n\n9. 日常维护9.1 定期任务#!/bin/bash# daily_maintenance.sh# 备份数据库mysqldump -u root -p&#x27;password&#x27; --all-databases | gzip &gt; /backup/all_$(date +%Y%m%d).sql.gz# 清理旧备份find /backup -name &quot;*.sql.gz&quot; -mtime +7 -delete# 优化表mysql -u root -p&#x27;password&#x27; -e &quot;OPTIMIZE TABLE mydb.users; OPTIMIZE TABLE mydb.orders;&quot;# 清理二进制日志mysql -u root -p&#x27;password&#x27; -e &quot;PURGE BINARY LOGS BEFORE DATE_SUB(NOW(), INTERVAL 7 DAY);&quot;# 分析表mysqlcheck -u root -p&#x27;password&#x27; --analyze --all-databases\n\n9.2 表维护-- 优化表OPTIMIZE TABLE users;-- 分析表ANALYZE TABLE users;-- 检查表CHECK TABLE users;-- 修复表REPAIR TABLE users;\n\n9.3 日志轮转# /etc/logrotate.d/mysql/var/log/mysql/*.log &#123;    daily    rotate 7    compress    delaycompress    missingok    notifempty    create 640 mysql adm    postrotate        mysqladmin flush-logs    endscript&#125;\n\n\n文档版本: 1.0最后更新: 2026-02-27适用版本: MySQL 8.0+\n","categories":["软件部署与运维管理"]},{"title":"Prometheus 监控告警配置","url":"/2026/02/28/07-Prometheus%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6%E9%85%8D%E7%BD%AE/","content":"Prometheus 监控告警配置目录\nPrometheus 架构概述\nPrometheus 安装与配置\n数据抓取配置\nAlertmanager 配置\n告警规则编写\nGrafana 可视化\n常用 Exporter\n服务发现\n高可用配置\n\n\n1. Prometheus 架构概述1.1 核心组件Prometheus Server          # 数据采集、存储、查询├── TSDB                  # 时序数据库├── Retrieval             # 数据抓取└── HTTP Server           # API 服务Exporters                 # 数据导出器├── Node Exporter         # 主机指标├── MySQL Exporter        # 数据库指标├── Redis Exporter        # 缓存指标└── ...Alertmanager              # 告警管理├── 去重├── 分组└── 路由Pushgateway               # 推送网关（用于短期任务）Grafana                   # 可视化展示\n\n1.2 数据模型指标名称&#123;标签名=标签值, ...&#125;示例：http_requests_total&#123;method=&quot;POST&quot;, handler=&quot;/api/users&quot;, status=&quot;200&quot;&#125;node_cpu_seconds_total&#123;cpu=&quot;0&quot;, mode=&quot;idle&quot;&#125;\n\n\n2. Prometheus 安装与配置2.1 二进制安装# 下载 Prometheuswget https://github.com/prometheus/prometheus/releases/download/v2.40.0/prometheus-2.40.0.linux-amd64.tar.gztar xzf prometheus-2.40.0.linux-amd64.tar.gzcd prometheus-2.40.0.linux-amd64# 创建用户useradd -r -s /sbin/nologin prometheusmkdir -p /etc/prometheus /var/lib/prometheuschown -R prometheus:prometheus /var/lib/prometheus# 复制文件cp prometheus promtool /usr/local/bin/cp -r consoles/ console_libraries/ /etc/prometheus/cp prometheus.yml /etc/prometheus/\n\n2.2 Systemd 配置# /etc/systemd/system/prometheus.service[Unit]Description=PrometheusWants=network-online.targetAfter=network-online.target[Service]User=prometheusGroup=prometheusType=simpleExecStart=/usr/local/bin/prometheus \\  --config.file=/etc/prometheus/prometheus.yml \\  --storage.tsdb.path=/var/lib/prometheus/ \\  --storage.tsdb.retention.time=15d \\  --web.console.templates=/etc/prometheus/consoles \\  --web.console.libraries=/etc/prometheus/console_libraries \\  --web.listen-address=0.0.0.0:9090 \\  --web.enable-lifecycle[Install]WantedBy=multi-user.target\n\n# 启动 Prometheussystemctl daemon-reloadsystemctl start prometheussystemctl enable prometheussystemctl status prometheus\n\n2.3 基础配置# /etc/prometheus/prometheus.ymlglobal:  scrape_interval: 15s      # 抓取间隔  evaluation_interval: 15s  # 规则评估间隔  external_labels:    monitor: &#x27;prometheus-monitor&#x27;    environment: &#x27;production&#x27;# 告警管理器alerting:  alertmanagers:    - static_configs:        - targets:          - alertmanager:9093# 规则文件rule_files:  - /etc/prometheus/rules/*.yml# 抓取配置scrape_configs:  - job_name: &#x27;prometheus&#x27;    static_configs:      - targets: [&#x27;localhost:9090&#x27;]  - job_name: &#x27;node&#x27;    static_configs:      - targets: [&#x27;localhost:9100&#x27;]\n\n\n3. 数据抓取配置3.1 静态配置scrape_configs:  - job_name: &#x27;web-servers&#x27;    static_configs:      - targets: [&#x27;192.168.1.10:9100&#x27;, &#x27;192.168.1.11:9100&#x27;]        labels:          env: &#x27;production&#x27;          team: &#x27;infra&#x27;      - targets: [&#x27;192.168.1.20:9100&#x27;]        labels:          env: &#x27;staging&#x27;\n\n3.2 动态配置scrape_configs:  - job_name: &#x27;kubernetes-nodes&#x27;    kubernetes_sd_configs:      - role: node    relabel_configs:      - source_labels: [__address__]        regex: &#x27;(.*):10250&#x27;        replacement: &#x27;$&#123;1&#125;:9100&#x27;        target_label: __address__        action: replace\n\n3.3 抓取参数scrape_configs:  - job_name: &#x27;slow-service&#x27;    scrape_interval: 30s      # 覆盖全局配置    scrape_timeout: 10s       # 抓取超时    metrics_path: /metrics    # 指标路径    scheme: https             # HTTP/HTTPS    static_configs:      - targets: [&#x27;service:8080&#x27;]    tls_config:      ca_file: /etc/ssl/certs/ca.crt      cert_file: /etc/ssl/certs/client.crt      key_file: /etc/ssl/certs/client.key\n\n3.4 重标签配置scrape_configs:  - job_name: &#x27;webapp&#x27;    static_configs:      - targets: [&#x27;webapp:8080&#x27;]    relabel_configs:      # 保留特定标签      - source_labels: [__meta_kubernetes_pod_label_app]        regex: webapp        action: keep            # 替换标签      - source_labels: [__meta_kubernetes_namespace]        target_label: namespace            # 添加标签      - target_label: monitored_by        replacement: prometheus            # 删除标签      - regex: __meta_kubernetes_pod_label_.+        action: labeldrop\n\n\n4. Alertmanager 配置4.1 安装 Alertmanager# 下载 Alertmanagerwget https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gztar xzf alertmanager-0.25.0.linux-amd64.tar.gzcd alertmanager-0.25.0.linux-amd64# 安装cp alertmanager amtool /usr/local/bin/mkdir -p /etc/alertmanager /var/lib/alertmanager# Systemd 配置cat &gt; /etc/systemd/system/alertmanager.service &lt;&lt; EOF[Unit]Description=AlertmanagerAfter=network.target[Service]Type=simpleUser=prometheusExecStart=/usr/local/bin/alertmanager \\  --config.file=/etc/alertmanager/alertmanager.yml \\  --storage.path=/var/lib/alertmanager \\  --web.listen-address=0.0.0.0:9093[Install]WantedBy=multi-user.targetEOFsystemctl start alertmanagersystemctl enable alertmanager\n\n4.2 基础配置# /etc/alertmanager/alertmanager.ymlglobal:  smtp_smarthost: &#x27;smtp.example.com:587&#x27;  smtp_from: &#x27;alertmanager@example.com&#x27;  smtp_auth_username: &#x27;alertmanager@example.com&#x27;  smtp_auth_password: &#x27;password&#x27;  smtp_require_tls: true  # 默认通知模板  resolve_timeout: 5m# 模板文件templates:  - &#x27;/etc/alertmanager/templates/*.tmpl&#x27;# 路由配置route:  receiver: &#x27;default-receiver&#x27;  group_by: [&#x27;alertname&#x27;, &#x27;cluster&#x27;, &#x27;service&#x27;]  group_wait: 30s  group_interval: 5m  repeat_interval: 4h    routes:    - match:        severity: critical      receiver: &#x27;critical-receiver&#x27;      continue: true        - match:        team: database      receiver: &#x27;db-team&#x27;        - match_re:        service: web.*      receiver: &#x27;web-team&#x27;# 接收器receivers:  - name: &#x27;default-receiver&#x27;    email_configs:      - to: &#x27;ops-team@example.com&#x27;        send_resolved: true  - name: &#x27;critical-receiver&#x27;    email_configs:      - to: &#x27;oncall@example.com&#x27;        send_resolved: true    webhook_configs:      - url: &#x27;http://localhost:5001/webhook&#x27;        send_resolved: true  - name: &#x27;db-team&#x27;    email_configs:      - to: &#x27;db-team@example.com&#x27;        send_resolved: true  - name: &#x27;web-team&#x27;    email_configs:      - to: &#x27;web-team@example.com&#x27;        send_resolved: true# 抑制规则inhibit_rules:  - source_match:      severity: &#x27;critical&#x27;    target_match:      severity: &#x27;warning&#x27;    equal: [&#x27;alertname&#x27;, &#x27;cluster&#x27;, &#x27;service&#x27;]\n\n4.3 通知渠道邮件通知\nreceivers:  - name: &#x27;email-receiver&#x27;    email_configs:      - to: &#x27;team@example.com&#x27;        from: &#x27;alertmanager@example.com&#x27;        smarthost: &#x27;smtp.example.com:587&#x27;        auth_username: &#x27;alertmanager@example.com&#x27;        auth_password: &#x27;password&#x27;        send_resolved: true        headers:          Subject: &#x27;[&#123;&#123; .Status | toUpper &#125;&#125;] &#123;&#123; .GroupLabels.alertname &#125;&#125;&#x27;\n\n钉钉通知\nreceivers:  - name: &#x27;dingtalk&#x27;    webhook_configs:      - url: &#x27;https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN&#x27;        send_resolved: true\n\n企业微信通知\nreceivers:  - name: &#x27;wechat&#x27;    wechat_configs:      - corp_id: &#x27;YOUR_CORP_ID&#x27;        api_secret: &#x27;YOUR_API_SECRET&#x27;        agent_id: &#x27;YOUR_AGENT_ID&#x27;        to_user: &#x27;@all&#x27;        send_resolved: true\n\nSlack 通知\nreceivers:  - name: &#x27;slack&#x27;    slack_configs:      - api_url: &#x27;https://hooks.slack.com/services/YOUR/WEBHOOK/URL&#x27;        channel: &#x27;#alerts&#x27;        send_resolved: true        title: &#x27;&#123;&#123; .Status | toUpper &#125;&#125;: &#123;&#123; .GroupLabels.alertname &#125;&#125;&#x27;        text: &#x27;&#123;&#123; range .Alerts &#125;&#125;&#123;&#123; .Annotations.description &#125;&#125;&#123;&#123; end &#125;&#125;&#x27;\n\n\n5. 告警规则编写5.1 规则文件结构# /etc/prometheus/rules/alerts.ymlgroups:  - name: example-alerts    interval: 30s    rules:      - alert: InstanceDown        expr: up == 0        for: 5m        labels:          severity: critical        annotations:          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 已宕机&quot;          description: &quot;&#123;&#123; $labels.instance &#125;&#125; 已经宕机超过 5 分钟&quot;      - alert: HighCPUUsage        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) * 100) &gt; 80        for: 10m        labels:          severity: warning        annotations:          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; CPU 使用率过高&quot;          description: &quot;CPU 使用率：&#123;&#123; $value &#125;&#125;%&quot;\n\n5.2 常用告警规则主机监控\ngroups:  - name: node-alerts    rules:      - alert: NodeDown        expr: up&#123;job=&quot;node&quot;&#125; == 0        for: 5m        labels:          severity: critical        annotations:          summary: &quot;主机 &#123;&#123; $labels.instance &#125;&#125; 已宕机&quot;      - alert: HighCPUUsage        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) * 100) &gt; 80        for: 10m        labels:          severity: warning        annotations:          summary: &quot;主机 &#123;&#123; $labels.instance &#125;&#125; CPU 使用率过高&quot;          description: &quot;CPU 使用率：&#123;&#123; $value &#125;&#125;%&quot;      - alert: HighMemoryUsage        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 &gt; 85        for: 10m        labels:          severity: warning        annotations:          summary: &quot;主机 &#123;&#123; $labels.instance &#125;&#125; 内存使用率过高&quot;          description: &quot;内存使用率：&#123;&#123; $value &#125;&#125;%&quot;      - alert: HighDiskUsage        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 &gt; 85        for: 10m        labels:          severity: warning        annotations:          summary: &quot;主机 &#123;&#123; $labels.instance &#125;&#125; 磁盘使用率过高&quot;          description: &quot;磁盘使用率：&#123;&#123; $value &#125;&#125;%&quot;      - alert: HighLoadAverage        expr: node_load1 &gt; (count by(instance) (count by(instance, cpu) (node_cpu_seconds_total)))        for: 10m        labels:          severity: warning        annotations:          summary: &quot;主机 &#123;&#123; $labels.instance &#125;&#125; 负载过高&quot;          description: &quot;1 分钟负载：&#123;&#123; $value &#125;&#125;&quot;\n\n服务监控\ngroups:  - name: service-alerts    rules:      - alert: ServiceDown        expr: up == 0        for: 2m        labels:          severity: critical        annotations:          summary: &quot;服务 &#123;&#123; $labels.job &#125;&#125; 不可用&quot;      - alert: HighErrorRate        expr: sum(rate(http_requests_total&#123;status=~&quot;5..&quot;&#125;[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service) &gt; 0.05        for: 5m        labels:          severity: critical        annotations:          summary: &quot;服务 &#123;&#123; $labels.service &#125;&#125; 错误率过高&quot;          description: &quot;错误率：&#123;&#123; $value | humanizePercentage &#125;&#125;&quot;      - alert: HighLatency        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) &gt; 1        for: 10m        labels:          severity: warning        annotations:          summary: &quot;服务 &#123;&#123; $labels.service &#125;&#125; 延迟过高&quot;          description: &quot;P95 延迟：&#123;&#123; $value &#125;&#125;s&quot;\n\n数据库监控\ngroups:  - name: database-alerts    rules:      - alert: MySQLDown        expr: mysql_up == 0        for: 1m        labels:          severity: critical        annotations:          summary: &quot;MySQL &#123;&#123; $labels.instance &#125;&#125; 不可用&quot;      - alert: MySQLHighConnections        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections &gt; 0.8        for: 5m        labels:          severity: warning        annotations:          summary: &quot;MySQL &#123;&#123; $labels.instance &#125;&#125; 连接数过高&quot;          description: &quot;连接数使用率：&#123;&#123; $value | humanizePercentage &#125;&#125;&quot;      - alert: RedisDown        expr: redis_up == 0        for: 1m        labels:          severity: critical        annotations:          summary: &quot;Redis &#123;&#123; $labels.instance &#125;&#125; 不可用&quot;      - alert: RedisHighMemory        expr: redis_memory_used_bytes / redis_memory_max_bytes &gt; 0.8        for: 10m        labels:          severity: warning        annotations:          summary: &quot;Redis &#123;&#123; $labels.instance &#125;&#125; 内存使用率过高&quot;          description: &quot;内存使用率：&#123;&#123; $value | humanizePercentage &#125;&#125;&quot;\n\n5.3 验证告警规则# 检查配置文件promtool check config /etc/prometheus/prometheus.yml# 检查规则文件promtool check rules /etc/prometheus/rules/alerts.yml# 测试告警规则promtool test rules test.yml\n\n\n6. Grafana 可视化6.1 安装 Grafana# Ubuntu/Debianapt-get install -y apt-transport-https software-properties-commonwget -q -O - https://packages.grafana.com/gpg.key | apt-key add -echo &quot;deb https://packages.grafana.com/oss/deb stable main&quot; &gt;&gt; /etc/apt/sources.list.d/grafana.listapt-get updateapt-get install -y grafana# CentOS/RHELcat &gt; /etc/yum.repos.d/grafana.repo &lt;&lt; EOF[grafana]name=grafanabaseurl=https://packages.grafana.com/oss/rpmrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packages.grafana.com/gpg.keyEOFyum install -y grafana# 启动systemctl start grafana-serversystemctl enable grafana-server\n\n6.2 配置数据源# /etc/grafana/provisioning/datasources/prometheus.ymlapiVersion: 1datasources:  - name: Prometheus    type: prometheus    access: proxy    url: http://localhost:9090    isDefault: true    editable: false\n\n6.3 常用仪表盘\nNode Exporter Full: ID 1860\nPrometheus Stats: ID 2\nMySQL Overview: ID 7362\nRedis Dashboard: ID 11835\nDocker and System Metrics: ID 893\n\n\n7. 常用 Exporter7.1 Node Exporter（主机监控）# 安装wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gztar xzf node_exporter-1.5.0.linux-amd64.tar.gzcp node_exporter-1.5.0.linux-amd64/node_exporter /usr/local/bin/# Systemd 配置cat &gt; /etc/systemd/system/node_exporter.service &lt;&lt; EOF[Unit]Description=Node ExporterAfter=network.target[Service]Type=simpleUser=prometheusExecStart=/usr/local/bin/node_exporter[Install]WantedBy=multi-user.targetEOFsystemctl start node_exportersystemctl enable node_exporter\n\n7.2 其他常用 Exporter# MySQL Exporterhttps://github.com/prometheus/mysqld_exporter# Redis Exporterhttps://github.com/oliver006/redis_exporter# Nginx Exporterhttps://github.com/nginxinc/nginx-prometheus-exporter# Blackbox Exporter（黑盒监控）https://github.com/prometheus/blackbox_exporter# Kafka Exporterhttps://github.com/danielqsj/kafka_exporter# Elasticsearch Exporterhttps://github.com/prometheus-community/elasticsearch_exporter\n\n\n8. 服务发现8.1 Kubernetes 服务发现scrape_configs:  - job_name: &#x27;kubernetes-pods&#x27;    kubernetes_sd_configs:      - role: pod    relabel_configs:      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]        action: keep        regex: true      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]        action: replace        target_label: __metrics_path__        regex: (.+)      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]        action: replace        regex: ([^:]+)(?::\\d+)?;(\\d+)        replacement: $1:$2        target_label: __address__\n\n8.2 Consul 服务发现scrape_configs:  - job_name: &#x27;consul&#x27;    consul_sd_configs:      - server: &#x27;consul:8500&#x27;        services: []    relabel_configs:      - source_labels: [__meta_consul_service]        target_label: job\n\n8.3 Docker 服务发现scrape_configs:  - job_name: &#x27;docker&#x27;    docker_sd_configs:      - host: unix:///var/run/docker.sock    relabel_configs:      - source_labels: [__meta_docker_container_label_prometheus_scrape]        action: keep        regex: true\n\n\n9. 高可用配置9.1 多副本 Prometheus# 运行多个 Prometheus 实例# 使用相同的配置，独立存储数据# 通过负载均衡器分发查询请求\n\n9.2 Thanos 架构Thanos Sidecar → Prometheus     ↓Thanos Store → 对象存储（S3/GCS）     ↓Thanos Query → 统一查询入口     ↓Grafana → 可视化\n\n9.3 VictoriaMetrics# 作为 Prometheus 的长期存储替代# 更高的性能和压缩率# 兼容 PromQLdocker run -it --rm \\  -p 8428:8428 \\  -v /data:/storage \\  victoriametrics/victoria-metrics\n\n\n文档版本: 1.0最后更新: 2026-02-27适用版本: Prometheus 2.40+, Alertmanager 0.25+, Grafana 9.x\n","categories":["监控与告警"]},{"title":"Ansible 自动化运维手册","url":"/2026/02/28/08-Ansible%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4%E6%89%8B%E5%86%8C/","content":"Ansible 自动化运维手册目录\nAnsible 架构概述\n安装与配置\nInventory 管理\nAd-Hoc 命令\nPlaybook 编写\n角色（Roles）\n变量与模板\n常用模块\n最佳实践\n\n\n1. Ansible 架构概述1.1 核心概念Ansible Controller（控制节点）├── Inventory（主机清单）├── Playbooks（剧本）├── Modules（模块）├── Plugins（插件）└── Roles（角色）Managed Nodes（被管节点）├── SSH（Linux/Unix）└── WinRM（Windows）\n\n1.2 工作原理\n读取 Inventory 获取目标主机\n加载 Playbook 定义的任务\n通过 SSH 推送模块到目标主机\n执行模块并返回结果\n清理临时文件\n\n\n2. 安装与配置2.1 安装 Ansible# Ubuntu/Debianapt-get updateapt-get install -y software-properties-commonapt-add-repository --yes --update ppa:ansible/ansibleapt-get install -y ansible# CentOS/RHELyum install -y epel-releaseyum install -y ansible# pip 安装pip3 install ansible# 验证安装ansible --versionansible --version\n\n2.2 配置文件# /etc/ansible/ansible.cfg 或 ~/.ansible.cfg[defaults]# Inventory 文件位置inventory = /etc/ansible/hosts# 私钥文件private_key_file = ~/.ssh/id_rsa# 并发数forks = 20# 超时时间timeout = 30# 日志文件log_path = /var/log/ansible.log# 主机密钥检查host_key_checking = False# 重试次数retries = 3# 提升权限方式become_method = sudobecome_user = rootbecome_ask_pass = False# 事实缓存fact_caching = jsonfilefact_caching_connection = /tmp/ansible_factsfact_caching_timeout = 86400[privilege_escalation]become = Truebecome_method = sudobecome_user = rootbecome_ask_pass = False[ssh_connection]# SSH 参数ssh_args = -o ControlMaster=auto -o ControlPersist=60spipelining = True\n\n2.3 SSH 密钥配置# 生成密钥ssh-keygen -t rsa -b 4096 -f ~/.ssh/ansible_rsa# 分发公钥ssh-copy-id -i ~/.ssh/ansible_rsa.pub user@target-host# 测试连接ssh -i ~/.ssh/ansible_rsa user@target-host\n\n\n3. Inventory 管理3.1 静态 Inventory# /etc/ansible/hosts# 单个主机web1.example.com192.168.1.100# 主机组[webservers]web1.example.comweb2.example.comweb3.example.com[dbservers]db1.example.comdb2.example.com# 带变量的主机[webservers]web1.example.com http_port=80 max_clients=200web2.example.com http_port=8080 max_clients=150# 嵌套组[webgroup:children]webserversappservers# 变量定义[all:vars]ansible_user=deployansible_ssh_private_key_file=~/.ssh/ansible_rsaansible_python_interpreter=/usr/bin/python3[webservers:vars]nginx_version=1.21\n\n3.2 动态 Inventory#!/usr/bin/env python3# inventory.pyimport jsonimport argparsedef get_inventory():    inventory = &#123;        &#x27;_meta&#x27;: &#123;            &#x27;hostvars&#x27;: &#123;                &#x27;web1.example.com&#x27;: &#123;&#x27;http_port&#x27;: 80&#125;,                &#x27;web2.example.com&#x27;: &#123;&#x27;http_port&#x27;: 8080&#125;            &#125;        &#125;,        &#x27;webservers&#x27;: &#123;            &#x27;hosts&#x27;: [&#x27;web1.example.com&#x27;, &#x27;web2.example.com&#x27;],            &#x27;vars&#x27;: &#123;&#x27;ansible_user&#x27;: &#x27;deploy&#x27;&#125;        &#125;,        &#x27;dbservers&#x27;: &#123;            &#x27;hosts&#x27;: [&#x27;db1.example.com&#x27;, &#x27;db2.example.com&#x27;]        &#125;    &#125;    return inventoryif __name__ == &#x27;__main__&#x27;:    parser = argparse.ArgumentParser()    parser.add_argument(&#x27;--list&#x27;, action=&#x27;store_true&#x27;)    parser.add_argument(&#x27;--host&#x27;, type=str)    args = parser.parse_args()        if args.list:        print(json.dumps(get_inventory()))    elif args.host:        print(json.dumps(&#123;&#125;))\n\n# 使用动态 Inventoryansible -i inventory.py --list-hosts allansible-playbook -i inventory.py playbook.yml\n\n3.3 常用命令# 列出所有主机ansible-inventory --list# 查看特定主机变量ansible-inventory --host web1.example.com# 图形化显示ansible-inventory --graph# 验证 Inventoryansible-inventory --list -i hosts\n\n\n4. Ad-Hoc 命令4.1 基础命令# ping 所有主机ansible all -m ping# ping 特定组ansible webservers -m ping# 执行 shell 命令ansible all -m shell -a &quot;uptime&quot;ansible all -m command -a &quot;df -h&quot;# 复制文件ansible all -m copy -a &quot;src=/local/file dest=/remote/file&quot;# 修改文件权限ansible all -m file -a &quot;path=/tmp/test mode=755&quot;# 安装软件包ansible webservers -m apt -a &quot;name=nginx state=present&quot;ansible webservers -m yum -a &quot;name=httpd state=present&quot;# 管理服务ansible webservers -m service -a &quot;name=nginx state=started enabled=yes&quot;# 创建用户ansible all -m user -a &quot;name=testuser state=present&quot;# 查看事实信息ansible all -m setupansible all -m setup -a &quot;filter=ansible_distribution*&quot;\n\n4.2 提权执行# 使用 sudoansible all -m shell -a &quot;whoami&quot; --become# 指定提权用户ansible all -m shell -a &quot;whoami&quot; --become --become-user=root# 输入提权密码ansible all -m shell -a &quot;whoami&quot; --become -K\n\n4.3 并行控制# 指定并发数ansible all -m ping -f 10# 逐个执行ansible all -m ping -f 1# 按组滚动执行ansible all -m shell -a &quot;uptime&quot; --limit webservers\n\n\n5. Playbook 编写5.1 基础结构# playbook.yml---- name: 部署 Web 服务器  hosts: webservers  become: yes  vars:    http_port: 80    max_clients: 200    pre_tasks:    - name: 更新 apt 缓存      apt:        update_cache: yes      when: ansible_os_family == &quot;Debian&quot;    tasks:    - name: 安装 Nginx      apt:        name: nginx        state: present      tags:        - install        - name: 启动 Nginx 服务      service:        name: nginx        state: started        enabled: yes      tags:        - service        - name: 创建网站目录      file:        path: /var/www/html        state: directory        owner: www-data        group: www-data        mode: &#x27;0755&#x27;      tags:        - config    post_tasks:    - name: 验证 Nginx 运行      shell: systemctl is-active nginx      register: nginx_status      changed_when: false    handlers:    - name: 重启 Nginx      service:        name: nginx        state: restarted\n\n5.2 条件判断tasks:  - name: 安装 Apache（CentOS）    yum:      name: httpd      state: present    when: ansible_os_family == &quot;RedHat&quot;    - name: 安装 Nginx（Ubuntu）    apt:      name: nginx      state: present    when: ansible_os_family == &quot;Debian&quot;    - name: 配置大内存服务器    template:      src: mysql_large.cnf.j2      dest: /etc/mysql/my.cnf    when: ansible_memtotal_mb &gt; 8192\n\n5.3 循环迭代tasks:  - name: 创建多个用户    user:      name: &quot;&#123;&#123; item &#125;&#125;&quot;      state: present    loop:      - user1      - user2      - user3    - name: 安装多个软件包    apt:      name: &quot;&#123;&#123; item &#125;&#125;&quot;      state: present    loop:      - nginx      - mysql-server      - php-fpm    - name: 配置多个端口    ufw:      rule: allow      port: &quot;&#123;&#123; item &#125;&#125;&quot;    loop:      - 80      - 443      - 22    - name: 字典循环    user:      name: &quot;&#123;&#123; item.key &#125;&#125;&quot;      groups: &quot;&#123;&#123; item.value &#125;&#125;&quot;    loop: &quot;&#123;&#123; users | dict2items &#125;&#125;&quot;\n\n5.4 错误处理tasks:  - name: 执行可能失败的命令    shell: /opt/app/start.sh    ignore_errors: yes    - name: 重试任务    shell: /opt/app/check.sh    retries: 5    delay: 10    until: result.stdout == &quot;ready&quot;    register: result    - name: 失败时通知    mail:      to: admin@example.com      subject: &quot;部署失败&quot;      body: &quot;服务器 &#123;&#123; inventory_hostname &#125;&#125; 部署失败&quot;    when: result.failed\n\n\n6. 角色（Roles）6.1 角色结构roles/├── common/│   ├── tasks/│   │   └── main.yml│   ├── handlers/│   │   └── main.yml│   ├── templates/│   ├── files/│   ├── vars/│   │   └── main.yml│   ├── defaults/│   │   └── main.yml│   └── meta/│       └── main.yml├── nginx/├── mysql/└── app/\n\n6.2 创建角色# 使用 ansible-galaxy 创建ansible-galaxy init roles/nginxansible-galaxy init roles/mysql# 角色目录结构tree roles/nginx/\n\n6.3 使用角色# playbook.yml---- name: 部署服务器  hosts: all  become: yes    roles:    - role: common    - role: nginx      nginx_port: 8080    - role: mysql      when: &quot;&#x27;dbservers&#x27; in group_names&quot;    tasks:    - name: 部署应用      import_tasks: tasks/deploy_app.yml\n\n6.4 角色依赖# roles/app/meta/main.yml---dependencies:  - role: nginx    nginx_port: 80  - role: mysql    mysql_port: 3306\n\n6.5 使用 Galaxy 角色# 搜索角色ansible-galaxy search nginx# 下载角色ansible-galaxy install geerlingguy.nginxansible-galaxy install geerlingguy.mysql# 批量安装（requirements.yml）# requirements.yml- src: geerlingguy.nginx  version: 3.1.0- src: geerlingguy.mysql  version: 4.0.0ansible-galaxy install -r requirements.yml\n\n\n7. 变量与模板7.1 变量优先级1. 命令行变量 (-e)2. Play 中的 vars3. 角色中的 vars4. set_facts / register5. 主机 facts6. Inventory 变量7. 角色中的 defaults8. 额外变量\n\n7.2 变量定义# 在 Playbook 中定义vars:  app_name: myapp  app_port: 8080# 在 Inventory 中定义[webservers:vars]http_port=80# 在文件中定义（vars_files）vars_files:  - vars/common.yml  - vars/secrets.yml# 包含变量文件- include_vars: vars/production.yml\n\n7.3 Jinja2 模板# templates/nginx.conf.j2server &#123;    listen &#123;&#123; nginx_port | default(80) &#125;&#125;;    server_name &#123;&#123; server_name &#125;&#125;;        root &#123;&#123; web_root &#125;&#125;;    index index.html index.htm;        &#123;% if enable_ssl %&#125;    ssl_certificate &#123;&#123; ssl_cert_path &#125;&#125;;    ssl_certificate_key &#123;&#123; ssl_key_path &#125;&#125;;    &#123;% endif %&#125;        location / &#123;        try_files $uri $uri/ =404;    &#125;        &#123;% for location in custom_locations %&#125;    location &#123;&#123; location.path &#125;&#125; &#123;        &#123;&#123; location.config &#125;&#125;    &#125;    &#123;% endfor %&#125;&#125;\n\n# 使用模板tasks:  - name: 部署 Nginx 配置    template:      src: nginx.conf.j2      dest: /etc/nginx/nginx.conf      owner: root      group: root      mode: &#x27;0644&#x27;      backup: yes      validate: &#x27;nginx -t -c %s&#x27;    notify: restart nginx\n\n7.4 内置变量tasks:  - name: 显示主机信息    debug:      msg: |        主机名：&#123;&#123; ansible_hostname &#125;&#125;        IP 地址：&#123;&#123; ansible_default_ipv4.address &#125;&#125;        内存：&#123;&#123; ansible_memtotal_mb &#125;&#125; MB        CPU 核心：&#123;&#123; ansible_processor_vcpus &#125;&#125;        操作系统：&#123;&#123; ansible_distribution &#125;&#125; &#123;&#123; ansible_distribution_version &#125;&#125;\n\n\n8. 常用模块8.1 系统模块tasks:  - name: 管理用户    user:      name: deploy      state: present      groups: sudo      shell: /bin/bash      create_home: yes    - name: 管理组    group:      name: appgroup      state: present    - name: 管理文件    file:      path: /var/log/app      state: directory      owner: app      group: app      mode: &#x27;0755&#x27;    - name: 复制文件    copy:      src: /local/config.yml      dest: /etc/app/config.yml      owner: app      mode: &#x27;0644&#x27;      backup: yes    - name: 下载文件    get_url:      url: https://example.com/file.tar.gz      dest: /tmp/file.tar.gz      mode: &#x27;0644&#x27;\n\n8.2 包管理模块tasks:  - name: 安装软件包（Debian）    apt:      name:        - nginx        - mysql-server        - php-fpm      state: present      update_cache: yes    - name: 安装软件包（RedHat）    yum:      name:        - httpd        - mariadb-server      state: present    - name: 使用 pip 安装    pip:      name:        - requests        - flask      state: present\n\n8.3 服务管理模块tasks:  - name: 管理服务    service:      name: nginx      state: started      enabled: yes    - name: 使用 systemd    systemd:      name: docker      state: restarted      daemon_reload: yes\n\n8.4 网络模块tasks:  - name: 打开防火墙端口    ufw:      rule: allow      port: &#x27;80&#x27;      proto: tcp    - name: 配置网络接口    template:      src: interfaces.j2      dest: /etc/network/interfaces    notify: restart networking\n\n8.5 Docker 模块tasks:  - name: 运行 Docker 容器    docker_container:      name: nginx      image: nginx:latest      state: started      ports:        - &quot;80:80&quot;      volumes:        - /data/nginx:/usr/share/nginx/html      env:        ENVIRONMENT: production    - name: 构建 Docker 镜像    docker_image:      name: myapp      source:        build:          path: /path/to/context      state: present\n\n\n9. 最佳实践9.1 目录结构project/├── ansible.cfg├── inventory/│   ├── production│   ├── staging│   └── development├── group_vars/│   ├── all.yml│   ├── production.yml│   └── staging.yml├── host_vars/│   └── server1.yml├── roles/│   ├── common/│   ├── nginx/│   └── app/├── playbooks/│   ├── site.yml│   ├── deploy.yml│   └── backup.yml└── scripts/    └── validate.sh\n\n9.2 标签使用tasks:  - name: 安装 Nginx    apt:      name: nginx      state: present    tags:      - nginx      - install      - web    - name: 配置 Nginx    template:      src: nginx.conf.j2      dest: /etc/nginx/nginx.conf    tags:      - nginx      - config  # 运行特定标签ansible-playbook site.yml --tags &quot;nginx,install&quot;ansible-playbook site.yml --skip-tags &quot;config&quot;\n\n9.3 Vault 加密# 创建加密文件ansible-vault create secrets.yml# 加密现有文件ansible-vault encrypt secrets.yml# 解密文件ansible-vault decrypt secrets.yml# 查看加密文件ansible-vault view secrets.yml# 编辑加密文件ansible-vault edit secrets.yml# 运行 Playbookansible-playbook site.yml --ask-vault-passansible-playbook site.yml --vault-password-file ~/.vault_pass\n\n9.4 测试与验证# 语法检查ansible-playbook --syntax-check playbook.yml# 预演执行（dry run）ansible-playbook --check playbook.yml# 逐步执行ansible-playbook --step playbook.yml# 限制主机ansible-playbook --limit webservers playbook.yml# 指定用户ansible-playbook -u deploy playbook.yml# 详细输出ansible-playbook -v playbook.ymlansible-playbook -vvv playbook.yml\n\n9.5 CI&#x2F;CD 集成# .gitlab-ci.ymlstages:  - lint  - test  - deployansible-lint:  stage: lint  script:    - ansible-lint playbooks/ansible-test:  stage: test  script:    - ansible-playbook --syntax-check playbooks/site.yml    - ansible-playbook --check playbooks/site.ymldeploy:  stage: deploy  script:    - ansible-playbook -i inventory/production playbooks/site.yml  when:    - $CI_COMMIT_BRANCH == &quot;main&quot;\n\n\n文档版本: 1.0最后更新: 2026-02-27适用版本: Ansible 2.12+\n","categories":["软件部署与运维管理"]},{"title":"GitLab CI/CD 运维指南","url":"/2026/02/28/10-GitLab-CICD%E8%BF%90%E7%BB%B4%E6%8C%87%E5%8D%97/","content":"GitLab CI&#x2F;CD 运维指南目录\nGitLab 架构概述\nGitLab 安装与配置\nGitLab Runner 配置\nCI&#x2F;CD 配置文件\n流水线设计\nDocker 集成\nKubernetes 集成\n安全最佳实践\n监控与维护\n\n\n1. GitLab 架构概述1.1 核心组件GitLab Server├── GitLab Rails (应用层)├── GitLab Shell (SSH/Git)├── GitLab Workhorse (反向代理)├── PostgreSQL (数据库)├── Redis (缓存)└── Gitaly (Git RPC)GitLab Runner├── Executor (Docker/Shell/Kubernetes)├── Cache (缓存管理)└── Artifacts (构建产物)Registry├── Docker Registry└── Package Registry\n\n1.2 CI&#x2F;CD 流程代码提交 → Webhook 触发 → 创建 Pipeline    ↓Stage 1: Build (编译构建)    ↓Stage 2: Test (测试)    ↓Stage 3: Deploy (部署)    ↓Stage 4: Review (审查)\n\n\n2. GitLab 安装与配置2.1 Omnibus 安装# 添加 GitLab 仓库curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | bash# 安装 GitLab CEapt-get install -y gitlab-ce# 或安装 GitLab EEapt-get install -y gitlab-ee# 配置 GitLabvi /etc/gitlab/gitlab.rb# 基础配置external_url &#x27;https://gitlab.example.com&#x27;gitlab_rails[&#x27;gitlab_shell_ssh_port&#x27;] = 2222gitlab_rails[&#x27;gitlab_https_certificate&#x27;] = &#x27;/etc/ssl/certs/gitlab.crt&#x27;gitlab_rails[&#x27;gitlab_https_key&#x27;] = &#x27;/etc/ssl/private/gitlab.key&#x27;# 应用配置gitlab-ctl reconfigure# 查看状态gitlab-ctl status# 获取初始密码cat /etc/gitlab/initial_root_password\n\n2.2 Docker 安装docker run -d \\  --hostname gitlab.example.com \\  -p 443:443 \\  -p 80:80 \\  -p 2222:22 \\  --name gitlab \\  --restart always \\  --volume $GITLAB_HOME/config:/etc/gitlab \\  --volume $GITLAB_HOME/logs:/var/log/gitlab \\  --volume $GITLAB_HOME/data:/var/opt/gitlab \\  --shm-size 256m \\  gitlab/gitlab-ce:latest\n\n2.3 备份与恢复# 备份gitlab-backup create# 备份文件位置ls /var/opt/gitlab/backups/# 恢复（停止相关服务）gitlab-ctl stop unicorngitlab-ctl stop sidekiq# 恢复备份gitlab-backup restore BACKUP=1234567890_2024_01_01_1.0.0# 启动服务gitlab-ctl start# 定时备份crontab -e0 2 * * * /opt/gitlab/bin/gitlab-backup create CRON=1\n\n\n3. GitLab Runner 配置3.1 安装 Runner# Ubuntu/Debiancurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | bashapt-get install -y gitlab-runner# CentOS/RHELcurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | bashyum install -y gitlab-runner# Docker 安装docker run -d --name gitlab-runner --restart always \\  -v /srv/gitlab-runner/config:/etc/gitlab-runner \\  -v /var/run/docker.sock:/var/run/docker.sock \\  gitlab/gitlab-runner:latest\n\n3.2 注册 Runner# 交互式注册gitlab-runner register# 输入信息：# GitLab URL: https://gitlab.example.com# Registration token: &lt;从 GitLab 获取&gt;# Description: my-runner# Tags: docker,production# Executor: docker# Docker image: alpine:latest# 非交互式注册gitlab-runner register \\  --non-interactive \\  --url &quot;https://gitlab.example.com/&quot; \\  --registration-token &quot;YOUR_TOKEN&quot; \\  --executor &quot;docker&quot; \\  --description &quot;docker-runner&quot; \\  --docker-image &quot;alpine:latest&quot; \\  --tag-list &quot;docker,production&quot; \\  --run-untagged=&quot;true&quot; \\  --locked=&quot;false&quot;\n\n3.3 Runner 配置# /etc/gitlab-runner/config.tomlconcurrent = 10check_interval = 0[[runners]]  name = &quot;docker-runner&quot;  url = &quot;https://gitlab.example.com/&quot;  token = &quot;RUNNER_TOKEN&quot;  executor = &quot;docker&quot;  limit = 10    [runners.docker]    tls_verify = false    image = &quot;alpine:latest&quot;    privileged = true    disable_cache = false    volumes = [&quot;/cache&quot;, &quot;/var/run/docker.sock:/var/run/docker.sock&quot;]    shm_size = 0    [runners.cache]    Type = &quot;s3&quot;    Shared = true    [runners.cache.s3]      ServerAddress = &quot;s3.amazonaws.com&quot;      AccessKey = &quot;ACCESS_KEY&quot;      SecretKey = &quot;SECRET_KEY&quot;      BucketName = &quot;gitlab-runner-cache&quot;\n\n3.4 Runner 管理# 查看 Runnergitlab-runner list# 验证 Runnergitlab-runner verify# 删除 Runnergitlab-runner unregister --name runner-name# 重启 Runnersystemctl restart gitlab-runner# 查看日志journalctl -u gitlab-runner -f\n\n\n4. CI&#x2F;CD 配置文件4.1 基础配置# .gitlab-ci.ymlstages:  - build  - test  - deployvariables:  APP_NAME: myapp  DOCKER_DRIVER: overlay2before_script:  - echo &quot;Before each job&quot;after_script:  - echo &quot;After each job&quot;build_job:  stage: build  script:    - echo &quot;Building...&quot;    - npm install    - npm run build  artifacts:    paths:      - dist/    expire_in: 1 weektest_job:  stage: test  script:    - echo &quot;Testing...&quot;    - npm run test  dependencies:    - build_jobdeploy_job:  stage: deploy  script:    - echo &quot;Deploying...&quot;    - ./deploy.sh  only:    - main  when: manual\n\n4.2 关键字说明# 常用关键字stages:          # 定义阶段variables:       # 定义变量before_script:   # 每个 job 之前执行after_script:    # 每个 job 之后执行script:          # 执行命令image:           # Docker 镜像services:        # Docker 服务cache:           # 缓存配置artifacts:       # 构建产物dependencies:    # 依赖关系tags:            # Runner 标签only/except:     # 分支过滤rules:           # 条件规则when:            # 执行时机allow_failure:   # 允许失败timeout:         # 超时时间retry:           # 重试次数\n\n4.3 变量使用# 预定义变量variables:  CI_COMMIT_SHA: $CI_COMMIT_SHA  CI_COMMIT_BRANCH: $CI_COMMIT_BRANCH  CI_PROJECT_NAME: $CI_PROJECT_NAME  CI_REGISTRY_IMAGE: $CI_REGISTRY_IMAGE# 自定义变量variables:  DATABASE_URL: &quot;postgresql://user:pass@db:5432/mydb&quot;  NODE_ENV: &quot;production&quot;# 文件变量variables:  TLS_CERT:    file: certs/tls.crt  TLS_KEY:    file: certs/tls.key# 受保护变量（在 GitLab UI 中设置）# Settings → CI/CD → Variables# 勾选 Protected 和 Masked\n\n\n5. 流水线设计5.1 多阶段流水线stages:  - lint  - build  - test  - security  - deploylint:  stage: lint  script:    - npm run lintbuild:  stage: build  script:    - npm install    - npm run build  artifacts:    paths:      - dist/unit_test:  stage: test  script:    - npm run test:unitintegration_test:  stage: test  script:    - npm run test:integration  services:    - postgres:13security_scan:  stage: security  script:    - npm audit    - snyk test  allow_failure: truedeploy_staging:  stage: deploy  script:    - ./deploy.sh staging  environment:    name: staging  only:    - developdeploy_production:  stage: deploy  script:    - ./deploy.sh production  environment:    name: production  only:    - main  when: manual\n\n5.2 并行与矩阵# 并行执行test:  stage: test  parallel: 5  script:    - npm run test -- --shard=$CI_NODE_INDEX/$CI_NODE_TOTAL# 矩阵构建build:  stage: build  parallel:    matrix:      - NODE_VERSION: [14, 16, 18]        OS: [ubuntu-latest, macos-latest]  image: node:$NODE_VERSION  script:    - npm install    - npm run build\n\n5.3 条件执行# rules 语法deploy:  script:    - ./deploy.sh  rules:    - if: $CI_COMMIT_BRANCH == &quot;main&quot;      when: always    - if: $CI_COMMIT_BRANCH == &quot;develop&quot;      when: manual    - if: $CI_PIPELINE_SOURCE == &quot;schedule&quot;      when: always    - when: never# only/except 语法deploy_prod:  script:    - ./deploy.sh  only:    - main    - tags  except:    - schedules\n\n5.4 子流水线# 触发子流水线trigger_downstream:  stage: deploy  trigger:    project: group/sub-project    branch: main    strategy: depend  # 或 finish# 包含其他配置文件include:  - local: &#x27;.gitlab-ci-template.yml&#x27;  - remote: &#x27;https://example.com/.gitlab-ci.yml&#x27;  - template: Auto-DevOps.gitlab-ci.yml\n\n\n6. Docker 集成6.1 Docker in Docker# 使用 dind 服务variables:  DOCKER_HOST: tcp://docker:2375  DOCKER_DRIVER: overlay2services:  - docker:20.10.16-dindbuild:  image: docker:20.10.16  script:    - docker build -t myapp:$CI_COMMIT_SHA .    - docker push myapp:$CI_COMMIT_SHA\n\n6.2 Docker 构建与推送variables:  DOCKER_REGISTRY: registry.gitlab.example.com  DOCKER_IMAGE: $DOCKER_REGISTRY/$CI_PROJECT_PATHstages:  - build  - deploybuild_image:  stage: build  image: docker:latest  services:    - docker:dind  script:    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY    - docker build -t $DOCKER_IMAGE:$CI_COMMIT_SHA .    - docker build -t $DOCKER_IMAGE:latest .    - docker push $DOCKER_IMAGE:$CI_COMMIT_SHA    - docker push $DOCKER_IMAGE:latest  only:    - main    - developdeploy:  stage: deploy  image: bitnami/kubectl:latest  script:    - kubectl set image deployment/myapp myapp=$DOCKER_IMAGE:$CI_COMMIT_SHA  only:    - main\n\n6.3 多阶段构建build:  stage: build  image: docker:latest  services:    - docker:dind  script:    - docker build --target production -t myapp:$CI_COMMIT_SHA .    - docker push myapp:$CI_COMMIT_SHA# Dockerfile 示例FROM node:16 AS builderWORKDIR /appCOPY package*.json ./RUN npm ciCOPY . .RUN npm run buildFROM node:16-alpine AS productionWORKDIR /appCOPY --from=builder /app/dist ./distCOPY --from=builder /app/node_modules ./node_modulesCMD [&quot;node&quot;, &quot;dist/server.js&quot;]\n\n\n7. Kubernetes 集成7.1 配置 Kubernetes 访问# 创建 Service Accountkubectl create namespace gitlabkubectl create serviceaccount gitlab-deployer -n gitlab# 绑定权限kubectl create clusterrolebinding gitlab-deployer \\  --clusterrole=cluster-admin \\  --serviceaccount=gitlab:gitlab-deployer# 获取 Tokenkubectl get secret $(kubectl get serviceaccount gitlab-deployer -n gitlab -o jsonpath=&#x27;&#123;.secrets[0].name&#125;&#x27;) -n gitlab -o jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d# 在 GitLab 中设置变量# Settings → CI/CD → Variables# KUBE_CONTEXT: production# KUBE_NAMESPACE: myapp# KUBE_TOKEN: &lt;上面获取的 token&gt;# KUBE_CA_CERT: &lt;k8s CA 证书&gt;\n\n7.2 部署到 Kubernetesdeploy:  stage: deploy  image: bitnami/kubectl:latest  script:    - kubectl config set-cluster k8s --server=$KUBE_SERVER --certificate-authority=$KUBE_CA_CERT    - kubectl config set-credentials deployer --token=$KUBE_TOKEN    - kubectl config set-context default --cluster=k8s --user=deployer --namespace=$KUBE_NAMESPACE    - kubectl config use-context default    - kubectl set image deployment/$APP_NAME $APP_NAME=$DOCKER_IMAGE:$CI_COMMIT_SHA    - kubectl rollout status deployment/$APP_NAME  only:    - main\n\n7.3 Helm 部署deploy_helm:  stage: deploy  image: alpine/helm:latest  before_script:    - apk add --no-cache curl    - curl -LO https://get.kubectl.io/$(curl -s https://get.kubectl.io)/bin/linux/$(curl -s https://get.kubectl.io)/kubectl    - chmod +x ./kubectl    - mv ./kubectl /usr/local/bin/kubectl  script:    - helm repo add myrepo https://charts.example.com    - helm upgrade --install myapp myrepo/myapp \\        --set image.tag=$CI_COMMIT_SHA \\        --set replicaCount=3 \\        --namespace $KUBE_NAMESPACE \\        --wait  only:    - main\n\n\n8. 安全最佳实践8.1 凭证管理# 使用 GitLab Variables（加密存储）# Settings → CI/CD → Variables# 勾选：Protected, Maskeddeploy:  script:    - echo $DATABASE_PASSWORD    - aws deploy --token $AWS_TOKEN# 使用外部密钥管理deploy:  script:    - curl -H &quot;X-Vault-Token: $VAULT_TOKEN&quot; $VAULT_ADDR/v1/secret/data/app | jq &#x27;.data.data&#x27;\n\n8.2 权限控制# 限制 Runner 权限[[runners]]  executor = &quot;docker&quot;  [runners.docker]    privileged = false    disable_cache = false    cap_drop = [&quot;ALL&quot;]    cap_add = [&quot;NET_BIND_SERVICE&quot;]# 使用受保护的分支# Settings → Repository → Protected Branches# main: Maintainers + Allowed to merge# develop: Developers + Maintainers# 使用受保护的标签# Settings → Repository → Protected Tags\n\n8.3 安全扫描# 包含 GitLab 安全模板include:  - template: Security/SAST.gitlab-ci.yml  - template: Security/Dependency-Scanning.gitlab-ci.yml  - template: Security/Container-Scanning.gitlab-ci.yml  - template: Security/DAST.gitlab-ci.yml# 自定义安全扫描security_scan:  stage: test  script:    - npm audit    - snyk test    - trivy image myapp:$CI_COMMIT_SHA  allow_failure: true\n\n\n9. 监控与维护9.1 监控指标# GitLab 内置监控# Admin → Monitoring → Metrics# Prometheus 端点curl https://gitlab.example.com/-/metrics# 关键指标- gitlab_ci_pipelines_total- gitlab_ci_builds_total- gitlab_runner_jobs_total- gitlab_http_requests_total\n\n9.2 日志管理# 查看日志gitlab-ctl tailgitlab-ctl tail nginxgitlab-ctl tail sidekiqgitlab-ctl tail gitlab-rails# Runner 日志journalctl -u gitlab-runner -f# 日志轮转# /etc/gitlab/gitlab.rblogrotate[&#x27;enable&#x27;] = truelogrotate[&#x27;max_size&#x27;] = &quot;100M&quot;logrotate[&#x27;rotate&#x27;] = 30\n\n9.3 性能优化# /etc/gitlab/gitlab.rb# Puma 配置puma[&#x27;worker_processes&#x27;] = 4puma[&#x27;worker_timeout&#x27;] = 60# Sidekiq 配置sidekiq[&#x27;max_concurrency&#x27;] = 20sidekiq[&#x27;job_timeout&#x27;] = 60# PostgreSQL 配置postgresql[&#x27;shared_buffers&#x27;] = &quot;256MB&quot;postgresql[&#x27;max_connections&#x27;] = 400# Redis 配置redis[&#x27;maxclients&#x27;] = 10000# 应用配置gitlab-ctl reconfigure\n\n9.4 备份策略#!/bin/bash# /opt/gitlab-backup.sh# 备份/opt/gitlab/bin/gitlab-backup create# 清理 7 天前的备份find /var/opt/gitlab/backups -name &quot;*.tar&quot; -mtime +7 -delete# 同步到远程存储rsync -avz /var/opt/gitlab/backups/ backup-server:/backup/gitlab/# crontab0 2 * * * /opt/gitlab-backup.sh\n\n\n文档版本: 1.0最后更新: 2026-02-27适用版本: GitLab 15.x+, GitLab Runner 15.x+\n","categories":["软件部署与运维管理"]},{"title":"Redis 缓存运维指南","url":"/2026/02/28/06-Redis%E7%BC%93%E5%AD%98%E8%BF%90%E7%BB%B4%E6%8C%87%E5%8D%97/","content":"Redis 缓存运维指南目录\nRedis 安装与配置\n核心配置详解\n数据持久化\n主从复制\n哨兵模式\n集群模式\n性能优化\n监控与诊断\n安全加固\n\n\n1. Redis 安装与配置1.1 源码安装# 下载 Rediswget https://download.redis.io/releases/redis-7.0.5.tar.gztar xzf redis-7.0.5.tar.gzcd redis-7.0.5# 编译安装makemake install# 验证安装redis-server --versionredis-cli --version\n\n1.2 系统配置# 修改内核参数cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOFvm.overcommit_memory = 1net.core.somaxconn = 65535vm.swappiness = 0EOFsysctl -p# 禁用透明大页echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledecho never &gt; /sys/kernel/mm/transparent_hugepage/defrag# 创建 redis 用户useradd -r -s /sbin/nologin redismkdir -p /var/lib/redis /var/log/redischown -R redis:redis /var/lib/redis /var/log/redis\n\n1.3 配置文件# 复制配置文件cp redis.conf /etc/redis/redis.conf# 关键配置修改sed -i &#x27;s/daemonize no/daemonize yes/&#x27; /etc/redis/redis.confsed -i &#x27;s/# bind 127.0.0.1/bind 0.0.0.0/&#x27; /etc/redis/redis.confsed -i &#x27;s/protected-mode yes/protected-mode no/&#x27; /etc/redis/redis.confsed -i &#x27;s|dir ./|dir /var/lib/redis|&#x27; /etc/redis/redis.confsed -i &#x27;s|logfile &quot;&quot;|logfile /var/log/redis/redis.log|&#x27; /etc/redis/redis.conf\n\n1.4 Systemd 配置# /etc/systemd/system/redis.service[Unit]Description=Redis In-Memory Data StoreAfter=network.target[Service]User=redisGroup=redisExecStart=/usr/local/bin/redis-server /etc/redis/redis.confExecStop=/usr/local/bin/redis-cli shutdownRestart=always[Install]WantedBy=multi-user.target\n\n# 启动 Redissystemctl daemon-reloadsystemctl start redissystemctl enable redissystemctl status redis\n\n\n2. 核心配置详解2.1 网络配置# 绑定地址bind 127.0.0.1 ::1# 端口port 6379# 超时时间（0 表示永不超时）timeout 0# TCP keepalivetcp-keepalive 300# 保护模式protected-mode yes\n\n2.2 内存配置# 最大内存maxmemory 2gb# 内存淘汰策略# volatile-lru: 对设置了过期时间的 key 使用 LRU 算法# allkeys-lru: 对所有 key 使用 LRU 算法# volatile-ttl: 对设置了过期时间的 key 使用 TTL 算法# noeviction: 不淘汰任何 key（默认）maxmemory-policy allkeys-lru# LRU 采样数量maxmemory-samples 5\n\n2.3 连接配置# 最大客户端连接数maxclients 10000# 密码认证requirepass your_password# 重命名危险命令rename-command FLUSHALL &quot;&quot;rename-command FLUSHDB &quot;&quot;rename-command CONFIG &quot;&quot;rename-command DEBUG &quot;&quot;\n\n\n3. 数据持久化3.1 RDB 快照# RDB 配置save 900 1        # 900 秒内至少 1 个 key 变化save 300 10       # 300 秒内至少 10 个 key 变化save 60 10000     # 60 秒内至少 10000 个 key 变化# RDB 文件名dbfilename dump.rdb# RDB 压缩rdbcompression yes# RDB 校验和rdbchecksum yes# 持久化目录dir /var/lib/redis\n\n# 手动触发 RDB 快照redis-cli BGSAVEredis-cli SAVE  # 阻塞式，不推荐生产使用# 查看 RDB 信息redis-cli INFO persistence\n\n3.2 AOF 日志# AOF 配置appendonly yesappendfilename &quot;appendonly.aof&quot;# AOF 同步策略# always: 每次写入都同步（最安全，性能最差）# everysec: 每秒同步一次（推荐）# no: 由操作系统决定何时同步（性能最好，安全性最差）appendfsync everysec# AOF 重写auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb\n\n# 手动触发 AOF 重写redis-cli BGREWRITEAOF# 查看 AOF 信息redis-cli INFO persistence\n\n3.3 混合持久化（Redis 4.0+）# 启用 RDB-AOF 混合持久化aof-use-rdb-preamble yes\n\n\n4. 主从复制4.1 配置从节点# 从节点配置replicaof 192.168.1.100 6379masterauth your_master_password# 从节点只读replica-read-only yes# 复制超时repl-timeout 60# 复制 ping 间隔repl-ping-replica-period 10\n\n4.2 动态配置# 在从节点上执行redis-cli SLAVEOF 192.168.1.100 6379# 断开主从关系redis-cli SLAVEOF NO ONE\n\n4.3 监控复制# 查看复制信息redis-cli INFO replication# 主节点查看role# 输出：master,connected_slaves:2# 从节点查看role# 输出：slave,master_host:192.168.1.100,master_port:6379\n\n\n5. 哨兵模式5.1 哨兵配置# sentinel.confport 26379daemonize yespidfile /var/run/redis/redis-sentinel.pidlogfile /var/log/redis/sentinel.log# 监控主节点sentinel monitor mymaster 192.168.1.100 6379 2# 认证sentinel auth-pass mymaster your_password# 故障判定时间（毫秒）sentinel down-after-milliseconds mymaster 5000# 并行同步数sentinel parallel-syncs mymaster 1# 故障转移超时（毫秒）sentinel failover-timeout mymaster 10000# 通知脚本sentinel notification-script mymaster /var/redis/notify.sh\n\n5.2 启动哨兵# 启动哨兵redis-sentinel /etc/redis/sentinel.conf# 或使用 systemdsystemctl start redis-sentinel\n\n5.3 哨兵命令# 查看主节点信息redis-cli -p 26379 SENTINEL masters# 查看从节点信息redis-cli -p 26379 SENTINEL slaves mymaster# 查看主节点地址redis-cli -p 26379 SENTINEL get-master-addr-by-name mymaster# 故障转移redis-cli -p 26379 SENTINEL failover mymaster\n\n\n6. 集群模式6.1 创建集群# 使用 redis-cli 创建集群redis-cli --cluster create \\  192.168.1.100:6379 192.168.1.101:6379 192.168.1.102:6379 \\  192.168.1.103:6379 192.168.1.104:6379 192.168.1.105:6379 \\  --cluster-replicas 1# 创建空集群redis-cli --cluster create 192.168.1.100:6379 --cluster-empty\n\n6.2 节点配置# 启用集群模式cluster-enabled yes# 集群配置文件cluster-config-file nodes.conf# 节点超时时间（毫秒）cluster-node-timeout 5000# 集群密码masterauth your_passwordrequirepass your_password\n\n6.3 集群管理# 查看集群信息redis-cli -c -p 6379 CLUSTER INFOredis-cli -c -p 6379 CLUSTER NODES# 查看槽位分布redis-cli --cluster check 192.168.1.100:6379# 添加节点redis-cli --cluster add-node 192.168.1.106:6379 192.168.1.100:6379# 删除节点redis-cli --cluster del-node 192.168.1.100:6379 &lt;node-id&gt;# 重新分片redis-cli --cluster reshard 192.168.1.100:6379# 故障转移redis-cli --cluster failover 192.168.1.100:6379\n\n\n7. 性能优化7.1 内存优化# 使用更高效的数据结构# 例如：hash-max-ziplist-entries, hash-max-ziplist-valuehash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-size -2set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64\n\n7.2 网络优化# TCP  backlogtcp-backlog 65535# 禁用 THPecho never &gt; /sys/kernel/mm/transparent_hugepage/enabled# 增加文件描述符限制ulimit -n 65535\n\n7.3 批量操作# 使用管道redis-cli --pipe &lt; commands.txt# 使用 MSET/MGETredis-cli MSET key1 value1 key2 value2 key3 value3redis-cli MGET key1 key2 key3# 使用 Lua 脚本redis-cli EVAL &quot;return redis.call(&#x27;SET&#x27;, KEYS[1], ARGV[1])&quot; 1 key1 value1\n\n\n8. 监控与诊断8.1 INFO 命令# 查看所有信息redis-cli INFO# 查看特定部分redis-cli INFO memoryredis-cli INFO persistenceredis-cli INFO replicationredis-cli INFO statsredis-cli INFO keyspace\n\n8.2 慢查询日志# 慢查询阈值（微秒）slowlog-log-slower-than 10000# 慢查询记录数slowlog-max-len 128\n\n# 查看慢查询redis-cli SLOWLOG GET 10redis-cli SLOWLOG LENredis-cli SLOWLOG RESET\n\n8.3 实时监控# 实时监控命令redis-cli --statredis-cli --bigkeysredis-cli --hotkeys# 监控延迟redis-cli --intrinsic-latency 100\n\n8.4 监控工具# Redis Monitorredis-monitor# Prometheus Exporterredis_exporter --redis.addr=localhost:6379# Grafana 仪表盘# 导入 Redis 官方仪表盘 ID: 11835\n\n\n9. 安全加固9.1 访问控制# 设置密码requirepass StrongP@ssw0rd123# 绑定内网 IPbind 192.168.1.100# 禁用危险命令rename-command FLUSHALL &quot;&quot;rename-command FLUSHDB &quot;&quot;rename-command CONFIG &quot;&quot;rename-command DEBUG &quot;&quot;rename-command SHUTDOWN SHUTDOWN_SECRET\n\n9.2 网络安全# 防火墙配置firewall-cmd --add-port=6379/tcp --permanentfirewall-cmd --add-rich-rule=&#x27;rule family=&quot;ipv4&quot; source address=&quot;192.168.1.0/24&quot; port port=&quot;6379&quot; protocol=&quot;tcp&quot; accept&#x27; --permanentfirewall-cmd --reload# 或使用 iptablesiptables -A INPUT -p tcp --dport 6379 -s 192.168.1.0/24 -j ACCEPT\n\n9.3 SSL&#x2F;TLS（Redis 6.0+）# 启用 TLStls-port 6379port 0tls-cert-file /etc/redis/tls/redis.crttls-key-file /etc/redis/tls/redis.keytls-ca-cert-file /etc/redis/tls/ca.crttls-auth-clients yes\n\n\n文档版本: 1.0最后更新: 2026-02-27适用版本: Redis 6.0+, 7.0+\n","categories":["软件部署与运维管理"]},{"title":"华为交换机经典组网配置案例","url":"/2026/02/28/12-%E5%8D%8E%E4%B8%BA%E4%BA%A4%E6%8D%A2%E6%9C%BA%E7%BB%8F%E5%85%B8%E7%BB%84%E7%BD%91%E9%85%8D%E7%BD%AE%E6%A1%88%E4%BE%8B/","content":"华为交换机经典组网配置案例目录\n小型企业网络组网\n中型园区网络组网\n大型数据中心网络组网\nMSTP+VRRP 高可用组网\n堆叠组网配置\n无线 AC+AP 组网\nQinQ 组网配置\n\n\n1. 小型企业网络组网1.1 组网拓扑             Internet                |            [防火墙]                |            [核心交换机]             /       \\            /         \\ [接入交换机 1]    [接入交换机 2]    /    \\            /    \\  PC1   PC2        PC3   PC4VLAN10 VLAN20    VLAN10 VLAN20\n\n1.2 需求分析\n2 个部门：行政部（VLAN10）、技术部（VLAN20）\n核心交换机提供 VLAN 间路由\n接入交换机二层接入\n统一出口上网\n\n1.3 核心交换机配置# 设备名称&lt;Huawei&gt; system-view[Huawei] sysname Core-SW# 创建 VLAN[Core-SW] vlan batch 10 20 100# 配置连接接入交换机的接口[Core-SW] interface GigabitEthernet 0/0/1[Core-SW-GigabitEthernet0/0/1] description To_Access_SW1[Core-SW-GigabitEthernet0/0/1] port link-type trunk[Core-SW-GigabitEthernet0/0/1] port trunk allow-pass vlan 10 20[Core-SW-GigabitEthernet0/0/1] quit[Core-SW] interface GigabitEthernet 0/0/2[Core-SW-GigabitEthernet0/0/2] description To_Access_SW2[Core-SW-GigabitEthernet0/0/2] port link-type trunk[Core-SW-GigabitEthernet0/0/2] port trunk allow-pass vlan 10 20[Core-SW-GigabitEthernet0/0/2] quit# 配置连接防火墙的接口[Core-SW] interface GigabitEthernet 0/0/24[Core-SW-GigabitEthernet0/0/24] description To_Firewall[Core-SW-GigabitEthernet0/0/24] port link-type access[Core-SW-GigabitEthernet0/0/24] port default vlan 100[Core-SW-GigabitEthernet0/0/24] quit# 配置 VLANIF 接口（VLAN 间路由）[Core-SW] interface Vlanif 10[Core-SW-Vlanif10] description HR_Department[Core-SW-Vlanif10] ip address 192.168.10.1 255.255.255.0[Core-SW-Vlanif10] quit[Core-SW] interface Vlanif 20[Core-SW-Vlanif20] description IT_Department[Core-SW-Vlanif20] ip address 192.168.20.1 255.255.255.0[Core-SW-Vlanif20] quit[Core-SW] interface Vlanif 100[Core-SW-Vlanif100] description To_Internet[Core-SW-Vlanif100] ip address 192.168.100.2 255.255.255.0[Core-SW-Vlanif100] quit# 启用 IP 路由[Core-SW] ip routing# 配置默认路由指向防火墙[Core-SW] ip route-static 0.0.0.0 0.0.0.0 192.168.100.1# 配置 DHCP 服务[Core-SW] dhcp enable[Core-SW] ip pool vlan10[Core-SW-ip-pool-vlan10] network 192.168.10.0 mask 255.255.255.0[Core-SW-ip-pool-vlan10] gateway-list 192.168.10.1[Core-SW-ip-pool-vlan10] dns-list 114.114.114.114 8.8.8.8[Core-SW-ip-pool-vlan10] quit[Core-SW] ip pool vlan20[Core-SW-ip-pool-vlan20] network 192.168.20.0 mask 255.255.255.0[Core-SW-ip-pool-vlan20] gateway-list 192.168.20.1[Core-SW-ip-pool-vlan20] dns-list 114.114.114.114 8.8.8.8[Core-SW-ip-pool-vlan20] quit[Core-SW] interface Vlanif 10[Core-SW-Vlanif10] dhcp select global[Core-SW-Vlanif10] quit[Core-SW] interface Vlanif 20[Core-SW-Vlanif20] dhcp select global[Core-SW-Vlanif20] quit# 保存配置&lt;Core-SW&gt; save\n\n1.4 接入交换机配置# 接入交换机 1 配置&lt;Huawei&gt; system-view[Huawei] sysname Access-SW1# 创建 VLAN[Access-SW1] vlan batch 10 20# 配置连接 PC 的接口[Access-SW1] interface GigabitEthernet 0/0/1[Access-SW1-GigabitEthernet0/0/1] description To_PC1_HR[Access-SW1-GigabitEthernet0/0/1] port link-type access[Access-SW1-GigabitEthernet0/0/1] port default vlan 10[Access-SW1-GigabitEthernet0/0/1] quit[Access-SW1] interface GigabitEthernet 0/0/2[Access-SW1-GigabitEthernet0/0/2] description To_PC2_IT[Access-SW1-GigabitEthernet0/0/2] port link-type access[Access-SW1-GigabitEthernet0/0/2] port default vlan 20[Access-SW1-GigabitEthernet0/0/2] quit# 配置上行接口[Access-SW1] interface GigabitEthernet 0/0/24[Access-SW1-GigabitEthernet0/0/24] description To_Core_SW[Access-SW1-GigabitEthernet0/0/24] port link-type trunk[Access-SW1-GigabitEthernet0/0/24] port trunk allow-pass vlan 10 20[Access-SW1-GigabitEthernet0/0/24] quit# 保存配置&lt;Access-SW1&gt; save# 接入交换机 2 配置（类似）&lt;Huawei&gt; system-view[Huawei] sysname Access-SW2[Access-SW2] vlan batch 10 20[Access-SW2] interface GigabitEthernet 0/0/1[Access-SW2-GigabitEthernet0/0/1] port link-type access[Access-SW2-GigabitEthernet0/0/1] port default vlan 10[Access-SW2] interface GigabitEthernet 0/0/2[Access-SW2-GigabitEthernet0/0/2] port link-type access[Access-SW2-GigabitEthernet0/0/2] port default vlan 20[Access-SW2] interface GigabitEthernet 0/0/24[Access-SW2-GigabitEthernet0/0/24] port link-type trunk[Access-SW2-GigabitEthernet0/0/24] port trunk allow-pass vlan 10 20&lt;Access-SW2&gt; save\n\n\n2. 中型园区网络组网2.1 组网拓扑             Internet                |            [防火墙]                |         [核心交换机 1] &lt;====&gt; [核心交换机 2]         /    |    \\          /    |    \\        /     |     \\        /     |     \\[汇聚 1]  [汇聚 2]  [汇聚 3]  [汇聚 1]  [汇聚 2]  [汇聚 3]  /  \\     /  \\     /  \\      /  \\     /  \\     /  \\接入  接入 接入  接入 接入  接入  接入  接入 接入  接入 接入\n\n2.2 需求分析\n核心层双机冗余\n汇聚层链路聚合\n多 VLAN 隔离\n生成树防环\n无线覆盖\n\n2.3 核心交换机配置（MSTP+VRRP）# 核心交换机 1&lt;Huawei&gt; system-view[Huawei] sysname Core-SW1# 创建 VLAN[Core-SW1] vlan batch 10 20 30 40 100# 配置 MSTP[Core-SW1] stp mode mstp[Core-SW1] stp region-configuration[Core-SW1-mst-region] region-name CAMPUS[Core-SW1-mst-region] instance 1 vlan 10 20[Core-SW1-mst-region] instance 2 vlan 30 40[Core-SW1-mst-region] revision-level 1[Core-SW1-mst-region] active region-configuration[Core-SW1-mst-region] quit# 配置 MSTP 实例优先级（Core-SW1 为实例 1 的主根）[Core-SW1] stp instance 1 priority 0[Core-SW1] stp instance 2 priority 4096# 配置 VRRP[Core-SW1] interface Vlanif 10[Core-SW1-Vlanif10] ip address 192.168.10.2 255.255.255.0[Core-SW1-Vlanif10] vrrp vrid 1 virtual-ip 192.168.10.1[Core-SW1-Vlanif10] vrrp vrid 1 priority 120[Core-SW1-Vlanif10] vrrp vrid 1 preempt-mode timer delay 20[Core-SW1-Vlanif10] quit[Core-SW1] interface Vlanif 20[Core-SW1-Vlanif20] ip address 192.168.20.2 255.255.255.0[Core-SW1-Vlanif20] vrrp vrid 2 virtual-ip 192.168.20.1[Core-SW1-Vlanif20] vrrp vrid 2 priority 120[Core-SW1-Vlanif20] quit[Core-SW1] interface Vlanif 30[Core-SW1-Vlanif30] ip address 192.168.30.2 255.255.255.0[Core-SW1-Vlanif30] vrrp vrid 3 virtual-ip 192.168.30.1[Core-SW1-Vlanif30] vrrp vrid 3 priority 100[Core-SW1-Vlanif30] quit[Core-SW1] interface Vlanif 40[Core-SW1-Vlanif40] ip address 192.168.40.2 255.255.255.0[Core-SW1-Vlanif40] vrrp vrid 4 virtual-ip 192.168.40.1[Core-SW1-Vlanif40] vrrp vrid 4 priority 100[Core-SW1-Vlanif40] quit# 配置与 Core-SW2 的互联[Core-SW1] interface Eth-Trunk 1[Core-SW1-Eth-Trunk1] description To_Core-SW2[Core-SW1-Eth-Trunk1] port link-type trunk[Core-SW1-Eth-Trunk1] port trunk allow-pass vlan 10 20 30 40 100[Core-SW1-Eth-Trunk1] mode lacp[Core-SW1-Eth-Trunk1] quit[Core-SW1] interface GigabitEthernet 1/0/1[Core-SW1-GigabitEthernet1/0/1] eth-trunk 1[Core-SW1] interface GigabitEthernet 1/0/2[Core-SW1-GigabitEthernet1/0/2] eth-trunk 1# 配置与汇聚交换机互联[Core-SW1] interface Eth-Trunk 10[Core-SW1-Eth-Trunk10] description To_Aggregation-SW1[Core-SW1-Eth-Trunk10] port link-type trunk[Core-SW1-Eth-Trunk10] port trunk allow-pass vlan 10 20 30 40[Core-SW1-Eth-Trunk10] quit[Core-SW1] interface GigabitEthernet 1/0/10[Core-SW1-GigabitEthernet1/0/10] eth-trunk 10# 配置 OSPF[Core-SW1] ospf 1 router-id 1.1.1.1[Core-SW1-ospf-1] area 0[Core-SW1-ospf-1-area-0.0.0.0] network 192.168.10.0 0.0.0.255[Core-SW1-ospf-1-area-0.0.0.0] network 192.168.20.0 0.0.0.255[Core-SW1-ospf-1-area-0.0.0.0] network 192.168.30.0 0.0.0.255[Core-SW1-ospf-1-area-0.0.0.0] network 192.168.40.0 0.0.0.255[Core-SW1-ospf-1-area-0.0.0.0] network 192.168.100.0 0.0.0.255# 配置默认路由[Core-SW1] ip route-static 0.0.0.0 0.0.0.0 192.168.100.254&lt;Core-SW1&gt; save\n\n2.4 核心交换机 2 配置&lt;Huawei&gt; system-view[Huawei] sysname Core-SW2# VLAN 和 MSTP 配置与 Core-SW1 相同[Core-SW2] vlan batch 10 20 30 40 100[Core-SW2] stp mode mstp[Core-SW2] stp region-configuration[Core-SW2-mst-region] region-name CAMPUS[Core-SW2-mst-region] instance 1 vlan 10 20[Core-SW2-mst-region] instance 2 vlan 30 40[Core-SW2-mst-region] revision-level 1[Core-SW2-mst-region] active region-configuration# MSTP 实例优先级（Core-SW2 为实例 2 的主根）[Core-SW2] stp instance 1 priority 4096[Core-SW2] stp instance 2 priority 0# VRRP 配置（优先级相反）[Core-SW2] interface Vlanif 10[Core-SW2-Vlanif10] ip address 192.168.10.3 255.255.255.0[Core-SW2-Vlanif10] vrrp vrid 1 virtual-ip 192.168.10.1[Core-SW2-Vlanif10] vrrp vrid 1 priority 100[Core-SW2-Vlanif10] quit[Core-SW2] interface Vlanif 20[Core-SW2-Vlanif20] ip address 192.168.20.3 255.255.255.0[Core-SW2-Vlanif20] vrrp vrid 2 virtual-ip 192.168.20.1[Core-SW2-Vlanif20] vrrp vrid 2 priority 100[Core-SW2-Vlanif20] quit[Core-SW2] interface Vlanif 30[Core-SW2-Vlanif30] ip address 192.168.30.3 255.255.255.0[Core-SW2-Vlanif30] vrrp vrid 3 virtual-ip 192.168.30.1[Core-SW2-Vlanif30] vrrp vrid 3 priority 120[Core-SW2-Vlanif30] quit[Core-SW2] interface Vlanif 40[Core-SW2-Vlanif40] ip address 192.168.40.3 255.255.255.0[Core-SW2-Vlanif40] vrrp vrid 4 virtual-ip 192.168.40.1[Core-SW2-Vlanif40] vrrp vrid 4 priority 120[Core-SW2-Vlanif40] quit# 其他配置与 Core-SW1 类似...&lt;Core-SW2&gt; save\n\n\n3. 大型数据中心网络组网3.1 组网拓扑（Spine-Leaf 架构）      [核心路由器]           |      [Spine 1] &lt;====&gt; [Spine 2]        /    \\          /    \\       /      \\        /      \\ [Leaf 1]    [Leaf 2]    [Leaf 3]    [Leaf 4]   /  \\       /  \\       /  \\       /  \\[服务器集群] [服务器集群] [服务器集群] [服务器集群]\n\n3.2 需求分析\n高带宽、低延迟\n无阻塞转发\n横向扩展能力\nVXLAN  overlay 网络\n\n3.3 Spine 交换机配置&lt;Huawei&gt; system-view[Huawei] sysname Spine-1# 基础配置[Spine-1] vlan batch 100[Spine-1] interface Eth-Trunk 1[Spine-1-Eth-Trunk1] description To_Spine-2[Spine-1-Eth-Trunk1] port link-type trunk[Spine-1-Eth-Trunk1] port trunk allow-pass vlan 100[Spine-1-Eth-Trunk1] mode lacp# 配置与 Leaf 的互联[Spine-1] interface 100GE 1/0/1[Spine-1-100GE1/0/1] description To_Leaf-1[Spine-1-100GE1/0/1] port link-type trunk[Spine-1-100GE1/0/1] port trunk allow-pass vlan 100[Spine-1] interface 100GE 1/0/2[Spine-1-100GE1/0/2] description To_Leaf-2[Spine-1-100GE1/0/2] port link-type trunk[Spine-1-100GE1/0/2] port trunk allow-pass vlan 100# 配置 OSPF（Underlay）[Spine-1] ospf 1 router-id 1.1.1.1[Spine-1-ospf-1] area 0[Spine-1-ospf-1-area-0.0.0.0] network 10.0.0.0 0.255.255.255# 配置 BGP（Overlay）[Spine-1] bgp 65001[Spine-1-bgp] router-id 1.1.1.1[Spine-1-bgp] peer 10.0.0.2 as-number 65001[Spine-1-bgp] peer 10.0.0.4 as-number 65001[Spine-1-bgp] peer 10.0.0.6 as-number 65001[Spine-1-bgp] peer 10.0.0.8 as-number 65001[Spine-1-bgp] ipv4-family unicast[Spine-1-bgp-af-ipv4] peer 10.0.0.2 enable[Spine-1-bgp-af-ipv4] peer 10.0.0.4 enable[Spine-1-bgp-af-ipv4] peer 10.0.0.6 enable[Spine-1-bgp-af-ipv4] peer 10.0.0.8 enable&lt;Spine-1&gt; save\n\n3.4 Leaf 交换机配置（VXLAN）&lt;Huawei&gt; system-view[Huawei] sysname Leaf-1# 启用 VXLAN[Leaf-1] vxlan# 创建 VNI[Leaf-1] vxlan 10[Leaf-1-vxlan-10] vni 5010[Leaf-1-vxlan-10] quit[Leaf-1] vxlan 20[Leaf-1-vxlan-20] vni 5020[Leaf-1-vxlan-20] quit# 配置 VBDIF 接口[Leaf-1] interface Vbdif 10[Leaf-1-Vbdif10] ip address 192.168.10.1 255.255.255.0[Leaf-1-Vbdif10] arp collect host enable[Leaf-1-Vbdif10] quit[Leaf-1] interface Vbdif 20[Leaf-1-Vbdif20] ip address 192.168.20.1 255.255.255.0[Leaf-1-Vbdif20] arp collect host enable[Leaf-1-Vbdif20] quit# 配置 VXLAN 隧道[Leaf-1] interface Nve 1[Leaf-1-Nve1] source 10.0.0.1[Leaf-1-Nve1] vni 5010 head-end peer-list 10.0.0.2[Leaf-1-Nve1] vni 5020 head-end peer-list 10.0.0.2[Leaf-1-Nve1] quit# 配置与服务器连接[Leaf-1] interface 10GE 1/0/1[Leaf-1-10GE1/0/1] port link-type access[Leaf-1-10GE1/0/1] port default vlan 10[Leaf-1-10GE1/0/1] quit[Leaf-1] interface 10GE 1/0/2[Leaf-1-10GE1/0/2] port link-type access[Leaf-1-10GE1/0/2] port default vlan 20[Leaf-1-10GE1/0/2] quit# 配置与 Spine 连接[Leaf-1] interface 100GE 1/0/49[Leaf-1-100GE1/0/49] port link-type trunk[Leaf-1-100GE1/0/49] port trunk allow-pass vlan 100[Leaf-1-100GE1/0/49] quit[Leaf-1] interface 100GE 1/0/50[Leaf-1-100GE1/0/50] port link-type trunk[Leaf-1-100GE1/0/50] port trunk allow-pass vlan 100[Leaf-1-100GE1/0/50] quit# 配置 OSPF[Leaf-1] ospf 1 router-id 10.0.0.1[Leaf-1-ospf-1] area 0[Leaf-1-ospf-1-area-0.0.0.0] network 10.0.0.0 0.255.255.255# 配置 BGP EVPN[Leaf-1] bgp 65001[Leaf-1-bgp] router-id 10.0.0.1[Leaf-1-bgp] peer 10.0.0.100 as-number 65001[Leaf-1-bgp] ipv4-family unicast[Leaf-1-bgp-af-ipv4] peer 10.0.0.100 enable[Leaf-1-bgp] l2vpn-family evpn[Leaf-1-bgp-af-evpn] peer 10.0.0.100 enable[Leaf-1-bgp-af-evpn] peer 10.0.0.100 advertise-all-vni&lt;Leaf-1&gt; save\n\n\n4. MSTP+VRRP 高可用组网4.1 组网拓扑  [核心交换机 A] &lt;====&gt; [核心交换机 B]       ||                     ||       ||                     ||  [汇聚交换机 A] &lt;====&gt; [汇聚交换机 B]      /   \\                 /   \\     /     \\               /     \\[接入 A1] [接入 A2]   [接入 B1] [接入 B2]\n\n4.2 配置要点# 核心交换机 A - MSTP 配置[Core-A] stp mode mstp[Core-A] stp region-configuration[Core-A-mst-region] region-name DC[Core-A-mst-region] instance 1 vlan 10 30[Core-A-mst-region] instance 2 vlan 20 40[Core-A-mst-region] active region-configuration# 核心交换机 A 为实例 1 的主根，实例 2 的备根[Core-A] stp instance 1 priority 0[Core-A] stp instance 2 priority 4096# 核心交换机 A - VRRP 配置[Core-A] interface Vlanif 10[Core-A-Vlanif10] ip address 192.168.10.2 24[Core-A-Vlanif10] vrrp vrid 1 virtual-ip 192.168.10.1[Core-A-Vlanif10] vrrp vrid 1 priority 120[Core-A-Vlanif10] vrrp vrid 1 preempt-mode timer delay 20[Core-A] interface Vlanif 20[Core-A-Vlanif20] ip address 192.168.20.2 24[Core-A-Vlanif20] vrrp vrid 2 virtual-ip 192.168.20.1[Core-A-Vlanif20] vrrp vrid 2 priority 100# 核心交换机 B - MSTP 配置[Core-B] stp mode mstp[Core-B] stp region-configuration[Core-B-mst-region] region-name DC[Core-B-mst-region] instance 1 vlan 10 30[Core-B-mst-region] instance 2 vlan 20 40[Core-B-mst-region] active region-configuration# 核心交换机 B 为实例 2 的主根，实例 1 的备根[Core-B] stp instance 1 priority 4096[Core-B] stp instance 2 priority 0# 核心交换机 B - VRRP 配置[Core-B] interface Vlanif 10[Core-B-Vlanif10] ip address 192.168.10.3 24[Core-B-Vlanif10] vrrp vrid 1 virtual-ip 192.168.10.1[Core-B-Vlanif10] vrrp vrid 1 priority 100[Core-B] interface Vlanif 20[Core-B-Vlanif20] ip address 192.168.20.3 24[Core-B-Vlanif20] vrrp vrid 2 virtual-ip 192.168.20.1[Core-B-Vlanif20] vrrp vrid 2 priority 120[Core-B-Vlanif20] vrrp vrid 2 preempt-mode timer delay 20\n\n4.3 配置验证# 验证 MSTPdisplay stp briefdisplay stp instance 1display stp instance 2# 验证 VRRPdisplay vrrp briefdisplay vrrp# 预期结果：# - VLAN10/30: Core-A 为 Master，Core-B 为 Backup# - VLAN20/40: Core-B 为 Master，Core-A 为 Backup# - 流量负载分担在两条路径上\n\n\n5. 堆叠组网配置5.1 组网拓扑[堆叠交换机 1] &lt;==== 堆叠电缆 ====&gt; [堆叠交换机 2]     /    \\                          /    \\    /      \\                        /      \\[服务器]  [服务器]              [服务器]  [服务器]\n\n5.2 堆叠配置（以 S5700 为例）# 交换机 1 配置（主交换机）&lt;Huawei&gt; system-view[Huawei] sysname Stack-Member1# 配置堆叠 ID 和优先级[Stack-Member1] stack[Stack-Member1-stack] stack member 1 priority 150[Stack-Member1-stack] stack member 1 renumber 1[Stack-Member1-stack] quit# 配置堆叠端口[Stack-Member1] interface 10GE 1/0/25[Stack-Member1-10GE1/0/25] stack port 1[Stack-Member1] interface 10GE 1/0/26[Stack-Member1-10GE1/0/26] stack port 1# 保存并重启&lt;Stack-Member1&gt; save&lt;Stack-Member1&gt; reboot# 交换机 2 配置（备交换机）&lt;Huawei&gt; system-view[Huawei] sysname Stack-Member2# 配置堆叠 ID 和优先级[Stack-Member2] stack[Stack-Member2-stack] stack member 1 priority 100[Stack-Member2-stack] stack member 1 renumber 2[Stack-Member2-stack] quit# 配置堆叠端口[Stack-Member2] interface 10GE 1/0/25[Stack-Member2-10GE1/0/25] stack port 1[Stack-Member2] interface 10GE 1/0/26[Stack-Member2-10GE1/0/26] stack port 1# 保存并重启&lt;Stack-Member2&gt; save&lt;Stack-Member2&gt; reboot# 使用堆叠电缆连接两台交换机的堆叠端口# 先启动主交换机，再启动备交换机\n\n5.3 堆叠验证# 查看堆叠状态&lt;Stack&gt; display stack&lt;Stack&gt; display stack topology&lt;Stack&gt; display stack configuration# 查看成员交换机&lt;Stack&gt; display device# 预期输出：# Slot  Sub  Type         Online    Register      Status# 1     1    S5720-28X    Present   Registered    Master# 2     2    S5720-28X    Present   Registered    Standby\n\n5.4 堆叠分裂检测（MAD）# 配置直连检测[Stack] mad enable[Stack] interface Eth-Trunk 10[Stack-Eth-Trunk10] mad detect mode direct# 配置代理检测[Stack] interface GigabitEthernet 1/0/1[Stack-GigabitEthernet1/0/1] mad detect mode agent# 查看 MAD 状态&lt;Stack&gt; display mad\n\n\n6. 无线 AC+AP 组网6.1 组网拓扑     [核心交换机]          |     [AC 控制器]          |     [PoE 交换机]     /    |    \\    /     |     \\[AP1]   [AP2]   [AP3]\n\n6.2 核心交换机配置&lt;Huawei&gt; system-view[Huawei] sysname Core-SW# 创建 VLAN[Core-SW] vlan batch 10 100 200# 配置管理 VLAN[Core-SW] interface Vlanif 100[Core-SW-Vlanif100] ip address 192.168.100.1 255.255.255.0[Core-SW-Vlanif100] quit# 配置业务 VLAN[Core-SW] interface Vlanif 200[Core-SW-Vlanif200] ip address 192.168.200.1 255.255.255.0[Core-SW-Vlanif200] quit# 配置 DHCP[Core-SW] dhcp enable[Core-SW] ip pool ap-management[Core-SW-ip-pool-ap-management] network 192.168.100.0 mask 255.255.255.0[Core-SW-ip-pool-ap-management] gateway-list 192.168.100.1[Core-SW-ip-pool-ap-management] option 43 sub-option 3 ascii 192.168.100.254[Core-SW-ip-pool-ap-management] quit[Core-SW] ip pool station[Core-SW-ip-pool-station] network 192.168.200.0 mask 255.255.255.0[Core-SW-ip-pool-station] gateway-list 192.168.200.1[Core-SW-ip-pool-station] dns-list 114.114.114.114[Core-SW-ip-pool-station] quit[Core-SW] interface Vlanif 100[Core-SW-Vlanif100] dhcp select global[Core-SW-Vlanif100] quit# 配置连接 AC 的接口[Core-SW] interface GigabitEthernet 0/0/24[Core-SW-GigabitEthernet0/0/24] port link-type trunk[Core-SW-GigabitEthernet0/0/24] port trunk allow-pass vlan 100 200[Core-SW-GigabitEthernet0/0/24] port trunk pvid vlan 100\n\n6.3 AC 控制器配置&lt;Huawei&gt; system-view[Huawei] sysname AC# 配置 WLAN 基本参数[AC] wlan[AC-wlan-view] ap auth-mode no-auth  # 或 mac-auth / sn-auth# 配置 AP 组[AC-wlan-view] ap-group name default[AC-wlan-ap-group-default] quit# 配置射频模板[AC-wlan-view] radio-2g-profile name default[AC-wlan-radio-2g-prof-default] channel 20mhz[AC-wlan-radio-2g-prof-default] eirp 27[AC-wlan-radio-2g-prof-default] quit[AC-wlan-view] radio-5g-profile name default[AC-wlan-radio-5g-prof-default] channel 80mhz[AC-wlan-radio-5g-prof-default] eirp 30[AC-wlan-radio-5g-prof-default] quit# 配置 VAP 模板[AC-wlan-view] vap-profile name default[AC-wlan-vap-prof-default] forward-mode tunnel[AC-wlan-vap-prof-default] service-vlan vlan 200[AC-wlan-vap-prof-default] ssid-profile name default[AC-wlan-vap-prof-default] security-profile name default[AC-wlan-vap-prof-default] quit# 配置 SSID 模板[AC-wlan-view] ssid-profile name default[AC-wlan-ssid-prof-default] ssid Huawei-WLAN[AC-wlan-ssid-prof-default] quit# 配置安全模板[AC-wlan-view] security-profile name default[AC-wlan-sec-prof-default] security wpa2 psk pass-phrase Huawei@123 aes[AC-wlan-sec-prof-default] quit# 将配置应用到 AP 组[AC-wlan-view] ap-group name default[AC-wlan-ap-group-default] radio 0[AC-wlan-ap-group-default-radio-0] vap-profile default wlan 1[AC-wlan-ap-group-default-radio-0] radio-2g-profile default[AC-wlan-ap-group-default-radio-0] quit[AC-wlan-ap-group-default] radio 1[AC-wlan-ap-group-default-radio-1] vap-profile default wlan 1[AC-wlan-ap-group-default-radio-1] radio-5g-profile default[AC-wlan-ap-group-default-radio-1] quit[AC-wlan-ap-group-default] quit# 查看 AP 状态[AC] display ap all[AC] display station all\n\n\n7. QinQ 组网配置7.1 组网拓扑[用户 Site A]                    [用户 Site B]     |                                |[CE-A]                            [CE-B]     |                                |[PE-A] ======= 运营商网络 ======= [PE-B]\n\n7.2 PE 交换机配置&lt;Huawei&gt; system-view[Huawei] sysname PE-A# 创建 VLAN[PE-A] vlan batch 10 100# 配置连接用户的接口（添加外层 VLAN）[PE-A] interface GigabitEthernet 0/0/1[PE-A-GigabitEthernet0/0/1] description To_CE-A[PE-A-GigabitEthernet0/0/1] port link-type hybrid[PE-A-GigabitEthernet0/0/1] port hybrid tagged vlan 100[PE-A-GigabitEthernet0/0/1] qinq vlan-translation enable[PE-A-GigabitEthernet0/0/1] port vlan-stacking vlan 10 stack-vlan 100[PE-A-GigabitEthernet0/0/1] quit# 配置连接运营商网络的接口[PE-A] interface GigabitEthernet 0/0/24[PE-A-GigabitEthernet0/0/24] description To_P-Network[PE-A-GigabitEthernet0/0/24] port link-type trunk[PE-A-GigabitEthernet0/0/24] port trunk allow-pass vlan 100[PE-A-GigabitEthernet0/0/24] quit# 查看 QinQ 配置[PE-A] display qinq vlan-translation[PE-A] display port vlan-stacking\n\n7.3 灵活 QinQ 配置# 基于内层 VLAN ID 添加不同外层 VLAN[PE-A] interface GigabitEthernet 0/0/1[PE-A-GigabitEthernet0/0/1] port vlan-stacking vlan 10 to 20 stack-vlan 100[PE-A-GigabitEthernet0/0/1] port vlan-stacking vlan 30 to 40 stack-vlan 200# 基于 802.1p 优先级添加外层 VLAN[PE-A] interface GigabitEthernet 0/0/1[PE-A-GigabitEthernet0/0/1] port vlan-stacking 8021p 5 stack-vlan 100[PE-A-GigabitEthernet0/0/1] port vlan-stacking 8021p 6 stack-vlan 200\n\n\n文档版本: 1.0最后更新: 2026-02-27适用设备: 华为 S5700&#x2F;S6700&#x2F;S7700&#x2F;S9700&#x2F;CE 系列交换机\n","categories":["硬件部署与运维管理"]},{"title":"网络运维与故障排查","url":"/2026/02/28/09-%E7%BD%91%E7%BB%9C%E8%BF%90%E7%BB%B4%E4%B8%8E%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/","content":"网络运维与故障排查目录\n网络基础配置\n网络监控工具\n性能测试\n故障排查方法\n常见问题解决\n网络安全\n网络优化\n\n\n1. 网络基础配置1.1 IP 地址配置# 查看网络接口ip addr showip -brief addr showifconfig -a# 配置 IP 地址（临时）ip addr add 192.168.1.100/24 dev eth0ip addr del 192.168.1.100/24 dev eth0# 配置 IP 地址（永久 - Ubuntu/Netplan）cat &gt; /etc/netplan/01-netcfg.yaml &lt;&lt; EOFnetwork:  version: 2  ethernets:    eth0:      addresses:        - 192.168.1.100/24      gateway4: 192.168.1.1      nameservers:        addresses: [8.8.8.8, 8.8.4.4]EOFnetplan apply# 配置 IP 地址（永久 - CentOS/NetworkManager）nmcli con mod eth0 ipv4.addresses 192.168.1.100/24nmcli con mod eth0 ipv4.gateway 192.168.1.1nmcli con mod eth0 ipv4.dns &quot;8.8.8.8 8.8.4.4&quot;nmcli con up eth0\n\n1.2 路由配置# 查看路由表ip route showroute -nnetstat -rn# 添加默认网关ip route add default via 192.168.1.1# 添加静态路由ip route add 10.0.0.0/8 via 192.168.1.254ip route add 172.16.0.0/16 dev eth1# 删除路由ip route del 10.0.0.0/8# 永久路由（CentOS）echo &quot;GATEWAY=192.168.1.1&quot; &gt;&gt; /etc/sysconfig/networkecho &quot;10.0.0.0/8 via 192.168.1.254&quot; &gt;&gt; /etc/sysconfig/network-scripts/route-eth0\n\n1.3 DNS 配置# 查看 DNScat /etc/resolv.confnmcli dev show | grep DNS# 配置 DNS（临时）echo &quot;nameserver 8.8.8.8&quot; &gt; /etc/resolv.confecho &quot;nameserver 8.8.4.4&quot; &gt;&gt; /etc/resolv.conf# 配置 DNS（永久 - Ubuntu）cat &gt; /etc/netplan/01-netcfg.yaml &lt;&lt; EOFnetwork:  version: 2  ethernets:    eth0:      nameservers:        addresses: [8.8.8.8, 1.1.1.1]EOFnetplan apply# 配置 DNS（永久 - CentOS）nmcli con mod eth0 ipv4.dns &quot;8.8.8.8 1.1.1.1&quot;nmcli con up eth0# 测试 DNS 解析nslookup example.comdig example.comhost example.com\n\n1.4 网络接口管理# 启用/禁用接口ip link set eth0 upip link set eth0 down# 查看接口状态ip link showethtool eth0# 查看接口统计ip -s link show eth0ethtool -S eth0# 修改 MTUip link set eth0 mtu 9000ethtool -K eth0 gro on tso on gso on\n\n\n2. 网络监控工具2.1 流量监控# iftop - 实时流量监控iftop -i eth0iftop -n -N  # 不解析端口和服务名# nethogs - 按进程监控nethogs eth0# iptraf - 交互式流量监控iptraf-ng# vnstat - 流量统计vnstat -i eth0vnstat -h      # 小时统计vnstat -d      # 天统计vnstat -m      # 月统计\n\n2.2 连接监控# 查看网络连接ss -tulpnnetstat -tulpnlsof -i# 查看 TCP 连接ss -tannetstat -tan# 查看监听端口ss -tlnpnetstat -tlnp# 监控连接变化watch -n1 &#x27;ss -tan | wc -l&#x27;\n\n2.3 带宽测试# iperf3 - 网络性能测试# 服务端iperf3 -s# 客户端iperf3 -c server_ipiperf3 -c server_ip -P 4  # 4 个并行连接iperf3 -c server_ip -R    # 反向测试（下载）# speedtest-cli - 网速测试speedtest-clispeedtest-cli --share\n\n2.4 数据包捕获# tcpdump - 抓包工具tcpdump -i eth0tcpdump -i eth0 -n port 80tcpdump -i eth0 -n host 192.168.1.100tcpdump -i eth0 -w capture.pcaptcpdump -r capture.pcap# tshark - Wireshark 命令行版tshark -i eth0tshark -i eth0 -f &quot;port 80&quot;tshark -r capture.pcap# wireshark - 图形界面wireshark capture.pcap\n\n\n3. 性能测试3.1 延迟测试# ping - 基础延迟测试ping example.comping -c 10 example.comping -i 0.2 example.com  # 快速 ping# mtr - 路由追踪 + pingmtr example.commtr -rwc 10 example.com  # 报告模式# 延迟监控ping -D example.com | awk &#x27;&#123;print strftime(&quot;%Y-%m-%d %H:%M:%S&quot;), $7&#125;&#x27;\n\n3.2 路由追踪# traceroute - 路由追踪traceroute example.comtraceroute -I example.com  # 使用 ICMP# tracepath - 无需 roottracepath example.com# mtr - 动态路由追踪mtr example.commtr --report example.com\n\n3.3 DNS 性能测试# dig 测试dig @8.8.8.8 example.comdig +stats example.com# DNS 查询时间time dig example.com# 批量 DNS 测试for i in &#123;1..10&#125;; do dig example.com | grep &quot;Query time&quot;; done\n\n3.4 HTTP 性能测试# curl 测试curl -o /dev/null -s -w &quot;DNS: %&#123;time_namelookup&#125;s\\nConnect: %&#123;time_connect&#125;s\\nTTFB: %&#123;time_starttransfer&#125;s\\nTotal: %&#123;time_total&#125;s\\n&quot; https://example.com# ab - Apache Benchmarkab -n 1000 -c 100 https://example.com/# wrk - 现代 HTTP 基准测试wrk -t12 -c400 -d30s https://example.com/\n\n\n4. 故障排查方法4.1 排查流程1. 确认问题范围   - 单台主机还是多台？   - 特定服务还是所有服务？   - 内网还是外网？2. 检查物理层   - 网线连接   - 接口状态   - LED 指示灯3. 检查网络层   - IP 配置   - 路由表   - DNS 解析4. 检查传输层   - 防火墙规则   - 端口监听   - 连接状态5. 检查应用层   - 服务配置   - 日志信息   - 资源使用\n\n4.2 诊断命令# 1. 检查网络接口ip addr showip link showethtool eth0# 2. 检查路由ip route showtraceroute 8.8.8.8# 3. 检查 DNScat /etc/resolv.confnslookup example.comdig example.com# 4. 检查连接ss -tulpnnetstat -tan | grep ESTABLISHED | wc -l# 5. 检查防火墙iptables -L -nfirewall-cmd --list-allufw status# 6. 检查服务systemctl status servicejournalctl -u service -f\n\n4.3 日志分析# 系统日志tail -f /var/log/syslogtail -f /var/log/messagesjournalctl -f# 网络相关日志journalctl -u NetworkManager -fjournalctl -u systemd-networkd -fdmesg | grep -i eth# 应用日志tail -f /var/log/nginx/error.logtail -f /var/log/apache2/error.log\n\n\n5. 常见问题解决5.1 无法访问外网# 1. 检查网关ip route showping 192.168.1.1  # 网关# 2. 检查 DNSnslookup www.baidu.comdig www.baidu.com# 3. 检查防火墙iptables -L -nfirewall-cmd --list-all# 4. 检查 NATiptables -t nat -L -n# 5. 临时解决方案echo &quot;nameserver 8.8.8.8&quot; &gt; /etc/resolv.confip route add default via 192.168.1.1\n\n5.2 DNS 解析失败# 1. 检查 resolv.confcat /etc/resolv.conf# 2. 测试 DNS 服务器nslookup example.com 8.8.8.8nslookup example.com 114.114.114.114# 3. 检查 systemd-resolvedsystemctl status systemd-resolvedresolvectl status# 4. 修复方案cat &gt; /etc/resolv.conf &lt;&lt; EOFnameserver 8.8.8.8nameserver 114.114.114.114EOF# 5. 清除 DNS 缓存systemctl restart systemd-resolved# 或/etc/init.d/nscd restart\n\n5.3 端口无法访问# 1. 检查服务是否监听ss -tlnp | grep :80netstat -tlnp | grep :80# 2. 检查防火墙iptables -L -n | grep 80firewall-cmd --list-portsufw status# 3. 开放端口# firewall-cmdfirewall-cmd --add-port=80/tcp --permanentfirewall-cmd --reload# ufwufw allow 80/tcp# iptablesiptables -A INPUT -p tcp --dport 80 -j ACCEPT# 4. 检查 SELinuxgetenforcesetenforce 0  # 临时禁用测试# 5. 检查云服务商安全组# 需要在云平台控制台配置\n\n5.4 网络连接数过多# 1. 查看连接数ss -tan | wc -lnetstat -tan | wc -l# 2. 查看各状态连接数netstat -tan | awk &#x27;&#123;print $6&#125;&#x27; | sort | uniq -c# 3. 查看 TIME_WAIT 连接netstat -tan | grep TIME_WAIT | wc -l# 4. 优化内核参数cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF# 允许重用 TIME_WAIT socketnet.ipv4.tcp_tw_reuse = 1# 缩短 FIN-WAIT-2 超时时间net.ipv4.tcp_fin_timeout = 30# 增加本地端口范围net.ipv4.ip_local_port_range = 1024 65535# 增加最大文件描述符fs.file-max = 2097152# 增加连接队列net.core.somaxconn = 65535net.ipv4.tcp_max_syn_backlog = 65535EOFsysctl -p\n\n5.5 网络延迟高# 1. 测试延迟ping -c 100 example.commtr --report example.com# 2. 检查路由traceroute example.com# 3. 检查带宽iftop -n# 4. 优化 TCP 参数cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF# 启用 BBR 拥塞控制net.core.default_qdisc=fqnet.ipv4.tcp_congestion_control=bbr# 增加缓冲区net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_rmem = 4096 87380 16777216net.ipv4.tcp_wmem = 4096 65536 16777216EOFsysctl -p# 5. 启用 BBRmodprobe tcp_bbrecho &quot;net.ipv4.tcp_congestion_control=bbr&quot; &gt;&gt; /etc/sysctl.conf\n\n\n6. 网络安全6.1 防火墙配置# iptables 基础配置# 默认策略iptables -P INPUT DROPiptables -P FORWARD DROPiptables -P OUTPUT ACCEPT# 允许回环iptables -A INPUT -i lo -j ACCEPT# 允许已建立的连接iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT# 允许 SSHiptables -A INPUT -p tcp --dport 22 -j ACCEPT# 允许 HTTP/HTTPSiptables -A INPUT -p tcp --dport 80 -j ACCEPTiptables -A INPUT -p tcp --dport 443 -j ACCEPT# 允许 ICMPiptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPT# 保存规则iptables-save &gt; /etc/iptables/rules.v4# firewalld 配置firewall-cmd --permanent --add-service=sshfirewall-cmd --permanent --add-service=httpfirewall-cmd --permanent --add-service=httpsfirewall-cmd --reload# ufw 配置ufw default deny incomingufw default allow outgoingufw allow sshufw allow httpufw allow httpsufw enable\n\n6.2 SSH 安全加固# /etc/ssh/sshd_configPort 2222Protocol 2PermitRootLogin noPasswordAuthentication noPubkeyAuthentication yesMaxAuthTries 3ClientAliveInterval 300ClientAliveCountMax 2AllowUsers admin deployDenyUsers root# 重启 SSHsystemctl restart sshd\n\n6.3 DDoS 防护# 限制连接速率iptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT# 防止 SYN 洪水iptables -A INPUT -p tcp --syn -m limit --limit 1/s --limit-burst 3 -j ACCEPT# 防止 Ping 洪水iptables -A INPUT -p icmp --icmp-type echo-request -m limit --limit 1/s --limit-burst 4 -j ACCEPT# 安装 fail2banapt-get install fail2bansystemctl enable fail2bansystemctl start fail2ban\n\n\n7. 网络优化7.1 内核参数优化# /etc/sysctl.conf# 网络性能优化net.core.default_qdisc = fqnet.ipv4.tcp_congestion_control = bbrnet.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_rmem = 4096 87380 16777216net.ipv4.tcp_wmem = 4096 65536 16777216# 连接优化net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_fin_timeout = 30net.ipv4.ip_local_port_range = 1024 65535net.core.somaxconn = 65535net.ipv4.tcp_max_syn_backlog = 65535# 应用优化net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_keepalive_time = 600net.ipv4.tcp_keepalive_intvl = 30net.ipv4.tcp_keepalive_probes = 10# 应用sysctl -p\n\n7.2 网卡优化# 查看网卡设置ethtool eth0# 启用卸载功能ethtool -K eth0 gro on tso on gso on lro on# 调整环缓冲区ethtool -G eth0 rx 4096 tx 4096# 设置中断亲和性cat /proc/irq/*/smp_affinity_list# 多队列优化ethtool -l eth0\n\n7.3 负载均衡# HAProxy 配置global    maxconn 4096    nbthread 4defaults    mode http    timeout connect 5s    timeout client 50s    timeout server 50sfrontend http_front    bind *:80    default_backend http_backbackend http_back    balance roundrobin    server web1 192.168.1.10:80 check    server web2 192.168.1.11:80 check    server web3 192.168.1.12:80 check# Nginx 负载均衡upstream backend &#123;    least_conn;    server 192.168.1.10:8080;    server 192.168.1.11:8080;    server 192.168.1.12:8080;&#125;server &#123;    location / &#123;        proxy_pass http://backend;    &#125;&#125;\n\n\n文档版本: 1.0最后更新: 2026-02-27适用系统: Linux (CentOS&#x2F;RHEL, Ubuntu&#x2F;Debian)\n","categories":["故障处理与问题排查"]},{"title":"华为交换机故障排查分析案例","url":"/2026/02/28/13-%E5%8D%8E%E4%B8%BA%E4%BA%A4%E6%8D%A2%E6%9C%BA%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/","content":"华为交换机故障排查分析案例目录\n网络连通性故障\nVLAN 故障\n生成树故障\n链路聚合故障\n路由协议故障\nDHCP 故障\n安全特性故障\n性能故障\n硬件故障\n故障排查方法论\n\n\n1. 网络连通性故障1.1 故障现象\nPC 无法访问网络\nPing 不通网关\n部分 VLAN 无法通信\n\n1.2 排查步骤步骤 1：检查物理连接# 查看接口状态&lt;SW1&gt; display interface GigabitEthernet 0/0/1# 检查项：# - Current state: UP/DOWN# - Line protocol current state: UP/DOWN# - Input/Output errors# 批量查看接口状态&lt;SW1&gt; display interface brief# 快速定位 DOWN 的接口# 查看接口统计&lt;SW1&gt; display interface GigabitEthernet 0/0/1 | include error|discard\n\n步骤 2：检查 VLAN 配置# 查看 VLAN 信息&lt;SW1&gt; display vlan&lt;SW1&gt; display vlan 10# 查看接口 VLAN 配置&lt;SW1&gt; display port vlan GigabitEthernet 0/0/1# 查看 MAC 地址表&lt;SW1&gt; display mac-address&lt;SW1&gt; display mac-address vlan 10&lt;SW1&gt; display mac-address interface GigabitEthernet 0/0/1\n\n步骤 3：检查 IP 配置# 查看 VLANIF 接口&lt;SW1&gt; display ip interface brief&lt;SW1&gt; display interface Vlanif 10# 查看 ARP 表&lt;SW1&gt; display arp&lt;SW1&gt; display arp vlan 10# 测试连通性&lt;SW1&gt; ping 192.168.10.1&lt;SW1&gt; ping -a 192.168.10.1 192.168.20.1  # 指定源地址\n\n1.3 典型案例案例 1：Access 端口 VLAN 配置错误现象: PC 无法获取 IP，无法上网\n排查:\n&lt;SW1&gt; display current-configuration interface GigabitEthernet 0/0/1# 发现配置：# port link-type trunk# port trunk allow-pass vlan 10&lt;SW1&gt; display port vlan GigabitEthernet 0/0/1# Port link-type: trunk# PVID: 1# Trunk VLAN pass: 10\n\n问题: Access 设备连接了 Trunk 端口，且 PVID 不匹配\n解决:\n&lt;SW1&gt; system-view[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] port link-type access[SW1-GigabitEthernet0/0/1] port default vlan 10\n\n案例 2：VLANIF 接口 DOWN现象: 同 VLAN 内可以通信，无法跨 VLAN 通信\n排查:\n&lt;SW1&gt; display ip interface brief# Vlanif10    192.168.10.1/24    DOWN&lt;SW1&gt; display interface Vlanif 10# Current state: DOWN# Line protocol current state: DOWN&lt;SW1&gt; display vlan 10# VLAN 10 没有活动的物理端口\n\n问题: VLAN 10 没有 UP 的物理端口，VLANIF 自动 DOWN\n解决:\n# 方法 1：确保 VLAN 内有 UP 的物理端口# 方法 2：配置 VLANIF 强制 UP（某些版本支持）[SW1] interface Vlanif 10[SW1-Vlanif10] undo shutdown\n\n\n2. VLAN 故障2.1 故障现象\nVLAN 间无法通信\n部分端口无法加入 VLAN\nVLAN 配置不生效\n\n2.2 排查命令# 查看 VLAN 配置display vlandisplay vlan summarydisplay vlan 10# 查看接口 VLAN 成员display port vlandisplay port vlan interface GigabitEthernet 0/0/1# 查看 VLAN MAC 地址display mac-address vlan 10# 查看 VLAN 路由display ip routing-table vlan 10\n\n2.3 典型案例案例 1：Trunk 端口未放行 VLAN现象: 跨交换机同 VLAN 无法通信\n排查:\n# SW1 配置&lt;SW1&gt; display interface GigabitEthernet 0/0/24# Port link-type: trunk# Trunk VLAN pass: 10 20# SW2 配置&lt;SW2&gt; display interface GigabitEthernet 0/0/24# Port link-type: trunk# Trunk VLAN pass: 10\n\n问题: SW2 的 Trunk 端口未放行 VLAN 20\n解决:\n[SW2] interface GigabitEthernet 0/0/24[SW2-GigabitEthernet0/0/24] port trunk allow-pass vlan 10 20\n\n案例 2：VLAN 接口 IP 配置错误现象: VLAN 间路由不通\n排查:\n&lt;SW1&gt; display ip interface brief# Vlanif10    192.168.10.1/24    UP# Vlanif20    192.168.20.1/24    UP&lt;SW1&gt; display current-configuration | include ip routing# 没有 ip routing 配置\n\n问题: 未启用 IP 路由功能\n解决:\n[SW1] ip routing\n\n\n3. 生成树故障3.1 故障现象\n网络环路\n部分端口被阻塞\n网络收敛慢\n\n3.2 排查命令# 查看 STP 状态display stpdisplay stp briefdisplay stp interface GigabitEthernet 0/0/1# 查看 MSTPdisplay stp region-configurationdisplay stp instance 1# 查看 STP 统计display stp statisticsdisplay stp tc# 查看 BPDU 信息debugging stp bpdu\n\n3.3 典型案例案例 1：网络环路导致广播风暴现象: 网络缓慢，CPU 利用率高，接口流量异常\n排查:\n&lt;SW1&gt; display cpu-usage# CPU utilization: 95%&lt;SW1&gt; display interface brief | include up# 多个接口流量接近 100%&lt;SW1&gt; display stp brief# 发现多个端口处于 FORWARDING 状态，存在潜在环路\n\n解决:\n# 1. 启用 STP[SW1] stp enable[SW1] stp mode rstp# 2. 配置边缘端口[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] stp edged-port enable# 3. 启用 BPDU 保护[SW1] stp bpdu-protection# 4. 排查物理环路# 检查是否有两根网线连接同一交换机\n\n案例 2：根桥位置不当现象: 次优路径，部分链路带宽浪费\n排查:\n&lt;SW1&gt; display stp brief# 发现接入交换机成为了根桥&lt;SW1&gt; display stp | include Root# Root ID Priority: 32768# 所有交换机优先级相同，比较 MAC 地址\n\n解决:\n# 在核心交换机配置[Core-SW] stp priority 0# 或[Core-SW] stp root primary# 在汇聚交换机配置[Agg-SW] stp priority 4096# 或[Agg-SW] stp root secondary\n\n\n4. 链路聚合故障4.1 故障现象\nEth-Trunk 接口 DOWN\n成员接口未加入成功\n负载分担不均\n\n4.2 排查命令# 查看 Eth-Trunk 状态display eth-trunkdisplay eth-trunk 1# 查看 LACP 信息display lacp statistics eth-trunk 1display lacp peer eth-trunk 1# 查看负载分担display load-balancedisplay interface Eth-Trunk 1 | include rate\n\n4.3 典型案例案例 1：LACP 模式不匹配现象: Eth-Trunk 无法 UP\n排查:\n&lt;SW1&gt; display eth-trunk 1# Eth-Trunk1&#x27;s state information is:# Local:#   Mode: LACP# Peer:#   Mode: - (无信息)&lt;SW2&gt; display eth-trunk 1# Local:#   Mode: Manual Load Balance\n\n问题: 两端模式不匹配（一端 LACP，一端手工）\n解决:\n# 统一配置为 LACP 模式[SW2] interface Eth-Trunk 1[SW2-Eth-Trunk1] mode lacp\n\n案例 2：成员接口配置不一致现象: 部分成员接口无法加入 Eth-Trunk\n排查:\n&lt;SW1&gt; display eth-trunk 1# 发现部分成员接口状态为 UNSELECT&lt;SW1&gt; display interface GigabitEthernet 0/0/2# 发现该接口有独立配置\n\n解决:\n# 清除成员接口独立配置[SW1] clear configuration interface GigabitEthernet 0/0/2# 重新加入 Eth-Trunk[SW1] interface GigabitEthernet 0/0/2[SW1-GigabitEthernet0/0/2] eth-trunk 1\n\n\n5. 路由协议故障5.1 故障现象\nOSPF 邻居无法建立\n路由学习不到\n路由震荡\n\n5.2 排查命令# OSPF 排查display ospf briefdisplay ospf peerdisplay ospf interfacedisplay ospf routingdisplay ospf error# 静态路由排查display ip routing-tabledisplay ip routing-table protocol staticdisplay ip routing-table protocol ospf# BGP 排查display bgp peerdisplay bgp routing-table\n\n5.3 典型案例案例 1：OSPF 邻居无法建立现象: OSPF 邻居状态停留在 INIT 或 2-WAY\n排查:\n&lt;SW1&gt; display ospf peer# Neighbor brief information# Area 0.0.0.0# Router ID: 2.2.2.2    Address: 192.168.1.2    State: Init&lt;SW1&gt; display ospf interface Vlanif 10# 检查 Hello/Dead 间隔# 检查认证配置\n\n常见问题及解决:\n# 1. 区域 ID 不匹配[SW1] ospf 1[SW1-ospf-1] area 0  # 确保两端区域 ID 一致# 2. Hello/Dead 间隔不匹配[SW1] interface Vlanif 10[SW1-Vlanif10] ospf timer hello 10[SW1-Vlanif10] ospf timer dead 40# 3. 认证不匹配[SW1-ospf-1-area-0.0.0.0] authentication-mode md5 1 cipher Huawei@123# 4. 网络类型不匹配[SW1-Vlanif10] ospf network-type broadcast\n\n案例 2：路由震荡现象: 路由频繁变化，网络不稳定\n排查:\n&lt;SW1&gt; display ospf statistics# 发现大量 SPF 计算&lt;SW1&gt; display logbuffer | include OSPF# 查看 OSPF 日志\n\n解决:\n# 1. 配置 SPF 延迟计算[SW1] ospf 1[SW1-ospf-1] spf-schedule-interval 5# 2. 配置接口开销[SW1] interface Vlanif 10[SW1-Vlanif10] ospf cost 100# 3. 配置路由聚合[SW1-ospf-1-area-0.0.0.0] abr-summary 192.168.0.0 255.255.0.0\n\n\n6. DHCP 故障6.1 故障现象\n客户端无法获取 IP\n获取到错误网段 IP\nIP 地址冲突\n\n6.2 排查命令# 查看 DHCP 配置display dhcp server treedisplay dhcp server conflictdisplay dhcp server free-ip# 查看 DHCP 统计display dhcp server statistics# 查看 DHCP Snoopingdisplay dhcp snoopingdisplay dhcp snooping binding\n\n6.3 典型案例案例 1：DHCP 客户端无法获取 IP现象: PC 获取到 169.254.x.x 地址\n排查:\n&lt;SW1&gt; display dhcp server statistics# 发现没有 DHCP Discover 消息&lt;SW1&gt; display current-configuration | include dhcp# 检查 DHCP 是否启用\n\n解决:\n# 1. 启用 DHCP[SW1] dhcp enable# 2. 配置 IP 池[SW1] ip pool vlan10[SW1-ip-pool-vlan10] network 192.168.10.0 mask 255.255.255.0[SW1-ip-pool-vlan10] gateway-list 192.168.10.1[SW1-ip-pool-vlan10] dns-list 114.114.114.114# 3. 接口启用 DHCP[SW1] interface Vlanif 10[SW1-Vlanif10] dhcp select global# 4. 检查 DHCP Snooping 信任接口[SW1] interface GigabitEthernet 0/0/24[SW1-GigabitEthernet0/0/24] dhcp snooping trusted\n\n案例 2：DHCP 地址耗尽现象: 新客户端无法获取 IP\n排查:\n&lt;SW1&gt; display dhcp server tree vlan 10# 查看已分配地址&lt;SW1&gt; display dhcp server free-ip# 查看剩余地址\n\n解决:\n# 1. 扩大地址池[SW1] ip pool vlan10[SW1-ip-pool-vlan10] network 192.168.10.0 mask 255.255.255.0[SW1-ip-pool-vlan10] gateway-list 192.168.10.1[SW1-ip-pool-vlan10] excluded-ip-address 192.168.10.1 192.168.10.10[SW1-ip-pool-vlan10] lease day 1  # 缩短租期# 2. 清理过期租约&lt;SW1&gt; reset dhcp server tree all\n\n\n7. 安全特性故障7.1 故障现象\n合法用户无法接入\n端口安全误拦截\n802.1X 认证失败\n\n7.2 排查命令# 端口安全display port-securitydisplay mac-address# 802.1Xdisplay dot1xdisplay dot1x connections# DHCP Snoopingdisplay dhcp snoopingdisplay dhcp snooping binding# ACLdisplay acldisplay traffic-filter applied-record\n\n7.3 典型案例案例 1：端口安全导致用户无法接入现象: 更换 PC 后无法上网\n排查:\n&lt;SW1&gt; display port-security interface GigabitEthernet 0/0/1# Max MAC count: 1# Current MAC count: 1# Protect action: shutdown&lt;SW1&gt; display mac-address interface GigabitEthernet 0/0/1# 发现是旧 PC 的 MAC 地址\n\n解决:\n# 方法 1：清除旧 MAC[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] undo port-security mac-address sticky# 方法 2：增加 MAC 数量[SW1-GigabitEthernet0/0/1] port-security max-mac-count 5# 方法 3：修改保护动作[SW1-GigabitEthernet0/0/1] port-security protect-action restrict\n\n案例 2：802.1X 认证失败现象: 用户认证失败，无法接入网络\n排查:\n&lt;SW1&gt; display dot1x connections# 无认证连接&lt;SW1&gt; display dot1x statistics# 查看认证失败统计&lt;SW1&gt; display radius-configuration# 检查 RADIUS 配置\n\n解决:\n# 1. 检查 RADIUS 服务器连通性[SW1] test-aaa radius template radius1# 2. 检查共享密钥[SW1] display current-configuration | include radius-server shared-key# 3. 检查接口 802.1X 配置[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] dot1x enable\n\n\n8. 性能故障8.1 故障现象\n网络延迟高\n吞吐量低\n丢包严重\n\n8.2 排查命令# CPU 和内存display cpu-usagedisplay memory-usage# 接口统计display interface | include rate|error|discarddisplay interface GigabitEthernet 0/0/1# 缓存和队列display qos queue statisticsdisplay qos queue interface# 风暴控制display storm-control\n\n8.3 典型案例案例 1：广播风暴现象: 网络缓慢，接口流量异常\n排查:\n&lt;SW1&gt; display interface brief# 发现多个接口广播包计数很高&lt;SW1&gt; display storm-control# 查看风暴控制状态\n\n解决:\n# 1. 启用风暴控制[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] storm-control broadcast min-rate 1000 max-rate 2000[SW1-GigabitEthernet0/0/1] storm-control multicast min-rate 1000 max-rate 2000# 2. 排查环路# 检查物理连接# 检查 STP 配置# 3. 隔离问题端口[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] shutdown\n\n案例 2：接口错包现象: 接口有大量 error&#x2F;discarded 包\n排查:\n&lt;SW1&gt; display interface GigabitEthernet 0/0/1# Input: 1000 packets, 100 errors# Output: 1000 packets, 50 errors\n\n解决:\n# 1. 检查双工模式[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] duplex full[SW1-GigabitEthernet0/0/1] speed 1000# 2. 检查网线质量# 更换网线测试# 3. 检查光模块display transceiver interface GigabitEthernet 0/0/1# 更换光模块测试\n\n\n9. 硬件故障9.1 故障现象\n设备无法启动\n接口频繁 UP&#x2F;DOWN\n风扇&#x2F;电源告警\n\n9.2 排查命令# 设备信息display devicedisplay versiondisplay elabel# 环境信息display environmentdisplay fandisplay power# 光模块信息display transceiver interface\n\n9.3 典型案例案例 1：光模块故障现象: 光口频繁 UP&#x2F;DOWN\n排查:\n&lt;SW1&gt; display transceiver interface GigabitEthernet 0/0/24# Voltage: 3.3V (Normal: 3.1-3.5V)# Temperature: 45C (Normal: 0-70C)# Tx Power: -20dBm (Normal: -9 to -3dBm)  # 偏低# Rx Power: -25dBm (Normal: -20 to -3dBm)  # 偏低\n\n解决:\n# 1. 清洁光纤# 2. 检查光纤长度# 3. 更换光模块\n\n案例 2：电源故障现象: 设备告警，部分模块不工作\n排查:\n&lt;SW1&gt; display power# Power 1: OK# Power 2: Fault&lt;SW1&gt; display environment# Temperature: OK# Voltage: Warning\n\n解决:\n# 1. 检查电源连接# 2. 更换电源模块# 3. 检查供电环境\n\n\n10. 故障排查方法论10.1 分层排查法应用层  → 检查应用程序、服务配置传输层  → 检查端口、连接状态网络层  → 检查 IP、路由、ACL数据链路层 → 检查 VLAN、MAC、STP物理层  → 检查线缆、接口、硬件\n\n10.2 对比法# 与正常设备对比配置display current-configurationdisplay saved-configuration# 与基线对比display baseline-configuration\n\n10.3 分段法源端 → 接入 → 汇聚 → 核心 → 汇聚 → 接入 → 目的端逐段 Ping 测试，定位故障点\n\n10.4 常用排查流程# 1. 收集信息display current-configurationdisplay logbufferdisplay trapbufferdisplay diagnostic-information  # 收集诊断信息# 2. 分析问题# 根据现象定位可能的故障点# 3. 制定方案# 确定排查步骤和解决方案# 4. 实施解决# 执行配置变更或硬件更换# 5. 验证结果ping testservice test# 6. 记录归档# 记录故障现象、原因、解决方案\n\n10.5 诊断信息收集# 收集完整诊断信息&lt;SW1&gt; display diagnostic-information# 保存到文件&lt;SW1&gt; display diagnostic-information &gt; flash:/diag.txt# 收集特定模块信息&lt;SW1&gt; display logbuffer &gt; flash:/log.txt&lt;SW1&gt; display trapbuffer &gt; flash:/trap.txt\n\n\n附录：常用故障排查命令速查连通性ping &lt;ip&gt;tracert &lt;ip&gt;telnet &lt;ip&gt; &lt;port&gt;\n\n接口display interface briefdisplay interface &lt;interface&gt;display mac-addressdisplay arp\n\nVLANdisplay vlandisplay port vlandisplay interface Vlanif\n\n路由display ip routing-tabledisplay ospf peerdisplay bgp peer\n\n安全display acldisplay port-securitydisplay dhcp snooping\n\n系统display devicedisplay cpu-usagedisplay memory-usagedisplay logbuffer\n\n\n文档版本: 1.0最后更新: 2026-02-27适用设备: 华为 S5700&#x2F;S6700&#x2F;S7700&#x2F;S9700&#x2F;CE 系列交换机\n","categories":["硬件部署与运维管理"]},{"title":"Hexo + GitHub Pages 搭建个人博客全流程指南","url":"/2026/02/26/hexo_github%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","content":"🌐 Hexo + GitHub Pages 搭建个人博客全流程指南（2024 最新版）\n💡 本指南适用于 Windows&#x2F;macOS&#x2F;Linux，全程约 30 分钟，附关键避坑提示\n\n\n🔑 一、前置准备\n\n\n项目\n要求\n验证命令\n\n\n\nGitHub 账号\n注册地址\n-\n\n\nNode.js (LTS)\n≥ 18.x\nnode -v npm -v\n\n\nGit\n≥ 2.30\ngit --version\n\n\n编辑器\nVS Code &#x2F; Typora 等\n-\n\n\n✅ 加速建议（国内用户）：\n# 设置 npm 淘宝镜像npm config set registry https://registry.npmmirror.com# 可选：安装 cnpmnpm install -g cnpm --registry=https://registry.npmmirror.com\n\n\n📦 二、安装与初始化 Hexo# 1. 全局安装 Hexo CLInpm install -g hexo-cli# 2. 创建博客目录（my-blog 可自定义）hexo init my-blogcd my-blog# 3. 安装依赖（国内建议用 cnpm）npm install  # 或 cnpm install# 4. 本地预览（浏览器访问 http://localhost:4000）hexo clean &amp;&amp; hexo g &amp;&amp; hexo s\n✅ 出现 Hexo 默认欢迎页即成功！\n\n🎨 三、个性化配置（关键步骤）1️⃣ 基础配置（_config.yml）# 站点信息title: 我的博客subtitle: 记录成长author: 你的名字language: zh-CNtimezone: Asia/Shanghai# URL（部署后修改为你的域名）url: https://yourname.github.ioroot: /# 生成设置permalink: :year/:month/:day/:title/permalink_defaults:\n\n2️⃣ 安装主题（以 Butterfly 为例）# 进入 themes 目录cd themesgit clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git butterflycd ../# 修改 _config.ymltheme: butterfly\n📌 主题配置：复制 themes/butterfly/_config.yml.example 为 _config.butterfly.yml，按需修改（菜单、评论、SEO等）\n3️⃣ 常用插件（按需安装）npm install hexo-generator-searchdb --save    # 站内搜索npm install hexo-wordcount --save            # 字数统计npm install hexo-abbrlink --save             # 永久链接（避免中文路径问题）\n\n\n📝 四、撰写与预览# 创建新文章（自动在 source/_posts/ 生成 .md 文件）hexo new &quot;我的第一篇博客&quot;# 本地实时预览（修改后自动刷新）hexo clean &amp;&amp; hexo g &amp;&amp; hexo s --debug\n✨ 写作技巧：\n\n使用 Markdown 编辑（推荐 Typora&#x2F;VS Code + Markdown 插件）\n图片建议存入 source/images/，引用相对路径\n文章 Front-matter 添加分类&#x2F;标签：---title: 示例date: 2024-02-26tags: [Hexo, 教程]categories: 技术---\n\n\n🚀 五、部署到 GitHub Pages（核心步骤）1️⃣ 创建仓库\n仓库名必须为：你的GitHub用户名.github.io（如 zhangsan.github.io）\n选择 Public（免费用户私有仓库无法启用 Pages）\n\n2️⃣ 配置 SSH 密钥（免密部署）# 生成密钥（一路回车）ssh-keygen -t ed25519 -C &quot;your_email@example.com&quot;# 复制公钥内容cat ~/.ssh/id_ed25519.pub  # Windows: type %USERPROFILE%\\.ssh\\id_ed25519.pub# GitHub 操作：# Settings → SSH and GPG keys → New SSH key → 粘贴公钥\n✅ 测试连接：ssh -T git@github.com（看到 “Hi xxx! You’ve successfully authenticated” 即成功）\n3️⃣ 配置部署（_config.yml 末尾）deploy:  type: git  repo: git@github.com:你的用户名/你的用户名.github.io.git  branch: main  # ⚠️ 重要：确认仓库默认分支名（新版 GitHub 为 main）\n\n4️⃣ 安装部署插件 &amp; 部署npm install hexo-deployer-git --savehexo clean &amp;&amp; hexo g &amp;&amp; hexo deploy\n🌐 访问：https://你的用户名.github.io（首次部署需等待 2-5 分钟）\n\n🌍 六、绑定自定义域名（可选但推荐）\n购买域名（阿里云&#x2F;腾讯云等）\n添加 CNAME 文件：\n在 source/ 目录新建 CNAME 文件（无后缀），内容为：www.yourdomain.com\n\n\nDNS 解析设置：\nA 记录 → 指向 GitHub Pages IP（任选其一）：185.199.108.153185.199.109.153185.199.110.153185.199.111.153\n或 CNAME 记录 → 指向 你的用户名.github.io\n\n\nGitHub 仓库设置：\nSettings → Pages → Custom domain 填写域名 → 勾选 ✅ Enforce HTTPS\n\n\n\n\n🛠️ 七、高频问题解决方案\n\n\n问题\n解决方案\n\n\n\n部署失败&#x2F;权限错误\n检查 SSH 密钥是否添加；ssh -T git@github.com 测试\n\n\n页面空白&#x2F;样式丢失\n检查 _config.yml 中 url 是否为部署后地址；清除浏览器缓存\n\n\n中文路径 404\n安装 hexo-abbrlink 插件，配置永久链接\n\n\n图片不显示\n使用相对路径；或设置 _config.yml 中 post_asset_folder: true\n\n\n部署后内容未更新\nhexo clean 清除缓存后重新部署\n\n\nGitHub Pages 未生效\n检查仓库 Settings → Pages → Branch 是否为 main&#x2F;gh-pages\n\n\n\n🔒 八、维护与进阶建议\n备份源码：将整个 my-blog 目录（含 source/, themes/, _config.yml）存至私有仓库或网盘\n自动化部署：配置 GitHub Actions 实现 push 后自动构建（适合高级用户）\n增强功能：\n评论系统：Valine &#x2F; Waline &#x2F; Gitalk\n统计：Google Analytics &#x2F; 不蒜子\nSEO：sitemap + robots.txt\n\n\n更新组件：npm update hexo-cli -g      # 更新 Hexocd themes/butterfly &amp;&amp; git pull  # 更新主题\n\n\n💡 最后提醒\n不要删除 .deploy_git 目录（部署缓存，但无需备份）\n所有修改均在本地完成，部署仅推送生成的静态文件\n遇到问题优先查阅：\nHexo 官方文档\n主题 GitHub Issues\n搜索错误关键词 + “Hexo”\n\n\n\n✨ 恭喜！你的专属技术博客已上线！坚持写作，让知识流动起来～如有细节疑问，欢迎提供具体报错信息进一步分析！\n","categories":["经验分享"]},{"title":"华为交换机典型配置命令手册","url":"/2026/02/28/11-%E5%8D%8E%E4%B8%BA%E4%BA%A4%E6%8D%A2%E6%9C%BA%E5%85%B8%E5%9E%8B%E9%85%8D%E7%BD%AE%E5%91%BD%E4%BB%A4%E6%89%8B%E5%86%8C/","content":"华为交换机典型配置命令手册目录\n基础配置命令\nVLAN 配置\n链路聚合\n生成树协议\n路由配置\nACL 访问控制\nQoS 配置\n安全配置\n管理与维护\n\n\n1. 基础配置命令1.1 登录与视图切换# 通过 Console 口登录&lt;Huawei&gt; system-view                    # 进入系统视图[Huawei] sysname SW1                    # 修改设备名称[SW1] quit                              # 退出当前视图[SW1] return                            # 直接返回用户视图# 视图层级用户视图      &lt;Huawei&gt;                  # 查看状态，不能配置系统视图      [Huawei]                  # 全局配置接口视图      [Huawei-GigabitEthernet0/0/1]VLAN 视图      [Huawei-vlan10]协议视图      [Huawei-stp]\n\n1.2 接口基础配置# 进入接口视图[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] # 配置接口描述[SW1-GigabitEthernet0/0/1] description To_PC1# 配置接口速率和双工模式[SW1-GigabitEthernet0/0/1] speed 1000   # 10/100/1000/auto[SW1-GigabitEthernet0/0/1] duplex full  # full/half/auto# 开启/关闭接口[SW1-GigabitEthernet0/0/1] undo shutdown[SW1-GigabitEthernet0/0/1] shutdown# 查看接口状态[SW1] display interface GigabitEthernet 0/0/1[SW1] display interface brief           # 查看简要信息\n\n1.3 接口类型配置# Access 端口（连接终端）[SW1-GigabitEthernet0/0/1] port link-type access[SW1-GigabitEthernet0/0/1] port default vlan 10# Trunk 端口（连接交换机）[SW1-GigabitEthernet0/0/2] port link-type trunk[SW1-GigabitEthernet0/0/2] port trunk allow-pass vlan 10 20 30[SW1-GigabitEthernet0/0/2] port trunk pvid vlan 1# Hybrid 端口（灵活 tagging）[SW1-GigabitEthernet0/0/3] port link-type hybrid[SW1-GigabitEthernet0/0/3] port hybrid pvid vlan 10[SW1-GigabitEthernet0/0/3] port hybrid untagged vlan 10 20[SW1-GigabitEthernet0/0/3] port hybrid tagged vlan 30 40# 恢复接口默认配置[SW1] clear configuration interface GigabitEthernet 0/0/1\n\n1.4 设备管理配置# 配置系统时间[SW1] clock timezone Beijing add 08:00:00[SW1] clock datetime 14:30:00 2024-01-15# 配置设备名称和描述[SW1] sysname Core-SW1[SW1] info-center enable                # 开启信息中心# 保存配置&lt;SW1&gt; save&lt;SW1&gt; save config.cfg                   # 指定文件名# 查看配置&lt;SW1&gt; display current-configuration     # 查看当前配置&lt;SW1&gt; display saved-configuration       # 查看保存的配置\n\n\n2. VLAN 配置2.1 创建 VLAN# 创建单个 VLAN[SW1] vlan 10[SW1-vlan10] description HR_Department[SW1-vlan10] quit# 批量创建 VLAN[SW1] vlan batch 10 20 30               # 创建多个不连续 VLAN[SW1] vlan batch 10 to 50               # 创建连续 VLAN# 查看 VLAN 信息[SW1] display vlan                      # 查看所有 VLAN[SW1] display vlan 10                   # 查看特定 VLAN[SW1] display vlan summary              # 查看 VLAN 摘要\n\n2.2 将端口加入 VLAN# Access 端口加入 VLAN[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] port link-type access[SW1-GigabitEthernet0/0/1] port default vlan 10# Trunk 端口允许 VLAN 通过[SW1] interface GigabitEthernet 0/0/24[SW1-GigabitEthernet0/0/24] port link-type trunk[SW1-GigabitEthernet0/0/24] port trunk allow-pass vlan 10 20 30[SW1-GigabitEthernet0/0/24] port trunk pvid vlan 1# 批量配置端口 VLAN[SW1] port-group 1[SW1-port-group-1] group-member GigabitEthernet 0/0/1 to 0/0/10[SW1-port-group-1] port link-type access[SW1-port-group-1] port default vlan 10\n\n2.3 VLAN 间路由（三层交换）# 创建 VLANIF 接口[SW1] interface Vlanif 10[SW1-Vlanif10] ip address 192.168.10.1 255.255.255.0[SW1-Vlanif10] quit[SW1] interface Vlanif 20[SW1-Vlanif20] ip address 192.168.20.1 255.255.255.0[SW1-Vlanif20] quit# 启用 IP 路由[SW1] ip routing# 查看路由表[SW1] display ip routing-table\n\n2.4 Super VLAN 配置# 创建 Super VLAN[SW1] vlan 100[SW1-vlan100] description Super_VLAN[SW1-vlan100] quit# 创建 Sub VLAN[SW1] vlan batch 101 102 103# 配置 Sub VLAN[SW1] vlan 101[SW1-vlan101] subvlan[SW1-vlan101] quit# 关联 Super VLAN 和 Sub VLAN[SW1] vlan 100[SW1-vlan100] aggregate-vlan[SW1-vlan100] access-vlan 101 to 103# 配置 VLANIF[SW1] interface Vlanif 100[SW1-Vlanif100] ip address 192.168.100.1 255.255.255.0\n\n\n3. 链路聚合3.1 手工负载分担模式# 创建 Eth-Trunk 接口[SW1] interface Eth-Trunk 1[SW1-Eth-Trunk1] description To_SW2[SW1-Eth-Trunk1] quit# 将物理接口加入 Eth-Trunk[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] eth-trunk 1[SW1-GigabitEthernet0/0/1] quit[SW1] interface GigabitEthernet 0/0/2[SW1-GigabitEthernet0/0/2] eth-trunk 1# 配置 Eth-Trunk 为 Trunk[SW1] interface Eth-Trunk 1[SW1-Eth-Trunk1] port link-type trunk[SW1-Eth-Trunk1] port trunk allow-pass vlan 10 20 30# 查看 Eth-Trunk 状态[SW1] display eth-trunk 1[SW1] display interface Eth-Trunk 1\n\n3.2 LACP 模式# 创建 LACP 模式 Eth-Trunk[SW1] interface Eth-Trunk 1[SW1-Eth-Trunk1] mode lacp[SW1-Eth-Trunk1] quit# 配置系统优先级（可选，越小优先级越高）[SW1] lacp priority 100# 将接口加入 Eth-Trunk[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] eth-trunk 1[SW1-GigabitEthernet0/0/1] lacp priority 100  # 接口优先级# 配置活动接口数上限[SW1] interface Eth-Trunk 1[SW1-Eth-Trunk1] max active-linknumber 4# 查看 LACP 信息[SW1] display eth-trunk 1[SW1] display lacp statistics eth-trunk 1\n\n3.3 Eth-Trunk 负载分担方式# 配置负载分担模式[SW1] load-balance ?  dst-ip          目的 IP  dst-mac         目的 MAC  src-ip          源 IP  src-mac         源 MAC  src-dst-ip      源 + 目的 IP  src-dst-mac     源 + 目的 MAC# 配置全局负载分担[SW1] load-balance src-dst-ip# 查看负载分担配置[SW1] display load-balance\n\n\n4. 生成树协议4.1 STP 基础配置# 启用 STP[SW1] stp enable# 配置 STP 模式[SW1] stp mode stp          # 标准 STP[SW1] stp mode rstp         # 快速 STP（推荐）[SW1] stp mode mstp         # 多实例 STP# 配置交换机优先级（越小越优先成为根桥）[SW1] stp priority 0        # 0, 4096, 8192... 61440[SW1] stp root primary      # 设为根桥[SW1] stp root secondary    # 设为备份根桥# 查看 STP 状态[SW1] display stp[SW1] display stp brief\n\n4.2 RSTP 配置# 启用 RSTP[SW1] stp mode rstp# 配置边缘端口（连接终端）[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] stp edged-port enable# 配置防 BPDU 攻击[SW1-GigabitEthernet0/0/1] stp bpdu-protection# 配置根保护[SW1] interface GigabitEthernet 0/0/24[SW1-GigabitEthernet0/0/24] stp root-protection# 查看 RSTP 状态[SW1] display stp\n\n4.3 MSTP 配置# 启用 MSTP[SW1] stp mode mstp# 进入 MST 域配置[SW1] stp region-configuration[SW1-mst-region] region-name RG1[SW1-mst-region] instance 1 vlan 10 20[SW1-mst-region] instance 2 vlan 30 40[SW1-mst-region] revision-level 1[SW1-mst-region] active region-configuration# 配置实例优先级[SW1] stp instance 1 priority 0[SW1] stp instance 2 priority 4096# 查看 MSTP 配置[SW1] display stp region-configuration[SW1] display stp instance 1\n\n4.4 STP 保护功能# BPDU 保护（全局）[SW1] stp bpdu-protection# 根保护（接口）[SW1] interface GigabitEthernet 0/0/24[SW1-GigabitEthernet0/0/24] stp root-protection# 环路保护[SW1-GigabitEthernet0/0/24] stp loop-protection# TC 保护[SW1] stp tc-protection enable[SW1] stp tc-protection threshold 10\n\n\n5. 路由配置5.1 静态路由# 启用 IP 路由[SW1] ip routing# 配置静态路由[SW1] ip route-static 192.168.100.0 255.255.255.0 10.1.1.2[SW1] ip route-static 0.0.0.0 0.0.0.0 10.1.1.1    # 默认路由# 配置浮动静态路由（通过优先级实现备份）[SW1] ip route-static 192.168.100.0 255.255.255.0 10.1.1.2 preference 60[SW1] ip route-static 192.168.100.0 255.255.255.0 10.1.2.2 preference 100# 查看路由表[SW1] display ip routing-table[SW1] display ip routing-table protocol static\n\n5.2 OSPF 配置# 启用 OSPF[SW1] ospf 1 router-id 1.1.1.1[SW1-ospf-1] area 0[SW1-ospf-1-area-0.0.0.0] network 192.168.10.0 0.0.0.255[SW1-ospf-1-area-0.0.0.0] network 192.168.20.0 0.0.0.255# 配置 OSPF 接口参数[SW1] interface Vlanif 10[SW1-Vlanif10] ospf cost 10[SW1-Vlanif10] ospf priority 100# 配置 OSPF 认证[SW1-ospf-1-area-0.0.0.0] authentication-mode md5 1 cipher Huawei@123# 查看 OSPF 信息[SW1] display ospf brief[SW1] display ospf peer[SW1] display ospf routing\n\n5.3 VRRP 配置# 配置 VRRP 组[SW1] interface Vlanif 10[SW1-Vlanif10] ip address 192.168.10.2 255.255.255.0[SW1-Vlanif10] vrrp vrid 1 virtual-ip 192.168.10.1[SW1-Vlanif10] vrrp vrid 1 priority 120      # 优先级（默认 100）[SW1-Vlanif10] vrrp vrid 1 preempt-mode timer delay 20# 配置 VRRP 认证[SW1-Vlanif10] vrrp vrid 1 authentication-mode md5 Huawei@123# 配置 VRRP 跟踪接口[SW1-Vlanif10] vrrp vrid 1 track interface GigabitEthernet 0/0/24 reduced 30# 查看 VRRP 状态[SW1] display vrrp brief[SW1] display vrrp\n\n\n6. ACL 访问控制6.1 基本 ACL（2000-2999）# 创建基本 ACL[SW1] acl 2000[SW1-acl-basic-2000] rule 5 permit source 192.168.10.0 0.0.0.255[SW1-acl-basic-2000] rule 10 deny source 192.168.20.0 0.0.0.255[SW1-acl-basic-2000] rule 15 permit source any# 应用 ACL 到接口（出方向）[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] traffic-filter outbound acl 2000# 查看 ACL[SW1] display acl 2000[SW1] display acl all\n\n6.2 高级 ACL（3000-3999）# 创建高级 ACL[SW1] acl 3000[SW1-acl-adv-3000] rule 5 permit ip source 192.168.10.0 0.0.0.255 destination 192.168.30.0 0.0.0.255[SW1-acl-adv-3000] rule 10 permit tcp source 192.168.10.0 0.0.0.255 destination 192.168.30.0 0.0.0.255 destination-port eq 80[SW1-acl-adv-3000] rule 15 deny ip source any destination any# 应用 ACL[SW1] interface Vlanif 10[SW1-Vlanif10] traffic-filter inbound acl 3000# 基于时间的 ACL[SW1] time-range work-time 08:00 to 18:00 working-day[SW1] acl 3001[SW1-acl-adv-3001] rule 5 permit tcp source any destination any destination-port eq 80 time-range work-time\n\n6.3 二层 ACL（4000-4999）# 创建二层 ACL[SW1] acl 4000[SW1-acl-link-4000] rule 5 permit vlan-id 10[SW1-acl-link-4000] rule 10 deny source-mac 00e0-fc00-0001 ffff-ffff-ffff# 应用二层 ACL[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] traffic-filter inbound acl 4000\n\n6.4 ACL 日志记录# 启用 ACL 日志[SW1] acl 3000[SW1-acl-adv-3000] rule 5 deny ip source any destination any logging# 查看 ACL 匹配统计[SW1] display acl 3000[SW1] display traffic-filter applied-record\n\n\n7. QoS 配置7.1 流量分类# 创建 ACL 定义流量[SW1] acl 3000[SW1-acl-adv-3000] rule 5 permit tcp destination-port eq 80[SW1-acl-adv-3000] rule 10 permit tcp destination-port eq 443# 创建流分类[SW1] traffic classifier WEB[SW1-classifier-WEB] if-match acl 3000# 创建流分类（基于 DSCP）[SW1] traffic classifier VOIP[SW1-classifier-VOIP] if-match dscp ef\n\n7.2 流量行为# 创建流行为（重标记）[SW1] traffic behavior WEB_MARK[SW1-behavior-WEB_MARK] remark dscp af21# 创建流行为（限速）[SW1] traffic behavior LIMIT[SW1-behavior-LIMIT] car cir 10000 pir 20000# 创建流行为（队列）[SW1] traffic behavior VOICE[SW1-behavior-VOICE] queue ef bandwidth pct 30\n\n7.3 流策略# 创建流策略并绑定分类和行为[SW1] traffic policy WEB_POLICY[SW1-trafficpolicy-WEB_POLICY] classifier WEB behavior WEB_MARK# 应用流策略到接口[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] traffic-policy WEB_POLICY inbound# 查看流策略[SW1] display traffic-policy WEB_POLICY[SW1] display traffic-policy applied-record\n\n7.4 端口限速# 配置端口入方向限速[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] qos lr inbound cir 10000 pir 20000# 配置端口出方向限速[SW1-GigabitEthernet0/0/1] qos lr outbound cir 50000 pir 100000# 配置风暴抑制[SW1-GigabitEthernet0/0/1] storm-control broadcast min-rate 1000 max-rate 2000[SW1-GigabitEthernet0/0/1] storm-control multicast min-rate 1000 max-rate 2000[SW1-GigabitEthernet0/0/1] storm-control unicast min-rate 1000 max-rate 2000\n\n\n8. 安全配置8.1 端口安全# 启用端口安全[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] port-security enable# 配置最大 MAC 地址数[SW1-GigabitEthernet0/0/1] port-security max-mac-count 5# 配置保护动作[SW1-GigabitEthernet0/0/1] port-security protect-action restrict  # protect/restrict/shutdown# 配置 Sticky MAC[SW1-GigabitEthernet0/0/1] port-security mac-address sticky# 查看端口安全[SW1] display port-security[SW1] display mac-address\n\n8.2 802.1X 认证# 启用 802.1X[SW1] dot1x enable# 配置认证方案[SW1] aaa[SW1-aaa] authentication-scheme dot1x[SW1-aaa-authen-dot1x] authentication-mode radius# 配置 RADIUS 服务器[SW1] radius-server template radius1[SW1-radius-radius1] radius-server authentication 192.168.100.10 1812[SW1-radius-radius1] radius-server shared-key cipher Huawei@123[SW1-radius-radius1] quit# 在接口启用 802.1X[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] dot1x enable# 查看 802.1X 状态[SW1] display dot1x[SW1] display dot1x connections\n\n8.3 DHCP Snooping# 启用 DHCP Snooping[SW1] dhcp enable[SW1] dhcp snooping enable# 配置信任接口（连接 DHCP 服务器）[SW1] interface GigabitEthernet 0/0/24[SW1-GigabitEthernet0/0/24] dhcp snooping trusted# 配置非信任接口限速[SW1] interface GigabitEthernet 0/0/1[SW1-GigabitEthernet0/0/1] dhcp snooping check dhcp-request enable[SW1-GigabitEthernet0/0/1] dhcp snooping check dhcp-chaddr enable# 查看 DHCP Snooping[SW1] display dhcp snooping[SW1] display dhcp snooping binding\n\n8.4 DAI（动态 ARP 检测）# 启用 DAI[SW1] arp anti-attack check user-bind enable# 在 VLAN 启用 DAI[SW1] vlan 10[SW1-vlan10] arp anti-attack dynamic-check enable# 配置信任接口[SW1] interface GigabitEthernet 0/0/24[SW1-GigabitEthernet0/0/24] arp anti-attack trust enable# 查看 DAI[SW1] display arp anti-attack statistics\n\n\n9. 管理与维护9.1 SSH 配置# 生成本地密钥对[SW1] rsa local-key-pair create# 启用 SSH 服务[SW1] stelnet server enable[SW1] sftp server enable# 创建本地用户[SW1] aaa[SW1-aaa] local-user admin password irreversible-cipher Huawei@123[SW1-aaa] local-user admin privilege level 15[SW1-aaa] local-user admin service-type ssh# 配置 SSH 用户认证[SW1] ssh user admin authentication-type password[SW1] ssh user admin service-type stelnet# 配置 VTY 支持 SSH[SW1] user-interface vty 0 4[SW1-ui-vty0-4] authentication-mode aaa[SW1-ui-vty0-4] protocol inbound ssh# 查看 SSH 信息[SW1] display ssh server status[SW1] display ssh user-information\n\n9.2 SNMP 配置# 启用 SNMP[SW1] snmp-agent# 配置 SNMP 版本[SW1] snmp-agent sys-info version v3# 配置团体名（v2c）[SW1] snmp-agent community read cipher public[SW1] snmp-agent community write cipher private# 配置 SNMPv3 用户[SW1] snmp-agent usm-user v3 admin[SW1] snmp-agent usm-user v3 admin authentication-mode sha[SW1] snmp-agent usm-user v3 admin privacy-mode aes128# 配置 Trap 目标[SW1] snmp-agent target-host trap address udp-domain 192.168.100.100 params securityname public v2c# 查看 SNMP[SW1] display snmp-agent sys-info\n\n9.3 NTP 配置# 启用 NTP[SW1] ntp enable# 配置 NTP 服务器[SW1] ntp-server 192.168.100.10# 配置 NTP 认证[SW1] ntp-service authentication enable[SW1] ntp-service authentication-keyid 1 authentication-mode md5 Huawei@123[SW1] ntp-service trusted authentication-keyid 1# 查看 NTP 状态[SW1] display ntp-service status[SW1] display ntp-service sessions\n\n9.4 日志配置# 启用日志中心[SW1] info-center enable# 配置日志主机[SW1] info-center loghost 192.168.100.100# 配置日志级别[SW1] info-center source DHCP log level warning# 配置日志缓冲区[SW1] info-center logbuffer size 1024[SW1] info-center logbuffer level informational# 查看日志[SW1] display logbuffer[SW1] display trapbuffer[SW1] terminal monitor[SW1] terminal logging\n\n9.5 设备维护命令# 查看设备信息&lt;SW1&gt; display device                    # 查看硬件信息&lt;SW1&gt; display version                   # 查看版本信息&lt;SW1&gt; display elabel                    # 查看电子标签# 查看 CPU 和内存&lt;SW1&gt; display cpu-usage                 # CPU 使用率&lt;SW1&gt; display memory-usage              # 内存使用率# 查看温度和环境&lt;SW1&gt; display environment               # 环境信息&lt;SW1&gt; display fan                       # 风扇状态&lt;SW1&gt; display power                     # 电源状态# 诊断命令&lt;SW1&gt; ping 192.168.1.1                  # Ping 测试&lt;SW1&gt; tracert 192.168.1.1               # 路由追踪&lt;SW1&gt; telnet 192.168.1.1                # Telnet 测试# 重启设备&lt;SW1&gt; reboot                            # 重启&lt;SW1&gt; reset saved-configuration         # 清除保存配置\n\n\n文档版本: 1.0最后更新: 2026-02-27适用设备: 华为 S5700&#x2F;S6700&#x2F;S7700&#x2F;S9700 系列交换机\n","categories":["硬件部署与运维管理"]},{"title":"dpdk占用导致网口消失问题排查","url":"/2026/02/26/dpdk%E5%8D%A0%E7%94%A8%E6%8E%92%E6%9F%A5/","content":"当网卡“消失”且怀疑被 DPDK 程序占用时（如 eth0 在 ip link 中不可见，但 lspci 仍能识别硬件），核心原因是：DPDK 通过 UIO&#x2F;VFIO 驱动将网卡从内核解绑，移交至用户态程序控制。以下是精准排查与定位方法：\n\n🔍 三步定位：是否被 DPDK 占用 + 谁在占用✅ 第一步：确认网卡是否被绑定到 DPDK 驱动# 1. 找到网卡 PCI 地址（示例）lspci -nn | grep -i ethernet# 输出示例：01:00.0 Ethernet controller [0200]: Intel Corporation ...# 2. 检查当前绑定的驱动lspci -k -s 0000:01:00.0  # 替换为实际 PCI 地址\n\n关键判断：Kernel driver in use: igb_uio &#x2F; vfio-pci &#x2F; uio_pci_generic → 已被 DPDK 占用Kernel driver in use: ixgbe &#x2F; e1000e 等 → 未被 DPDK 占用（排查其他原因）\n\n✅ 第二步：定位占用进程（核心！）# 方法1：检查打开的 UIO/VFIO 设备（最直接）sudo lsof /dev/uio* /dev/vfio/* 2&gt;/dev/null | grep -v &quot;COMMAND&quot;# 或sudo fuser -v /dev/uio* /dev/vfio/* 2&gt;/dev/null# 方法2：扫描所有进程的 fd（需 root）sudo find /proc/[0-9]*/fd -lname &quot;*uio*&quot; -o -lname &quot;*vfio*&quot; 2&gt;/dev/null | \\  while read fd; do     pid=$(echo $fd | cut -d/ -f3)    echo &quot;PID: $pid | $(ps -p $pid -o comm= 2&gt;/dev/null || echo &#x27;terminated&#x27;)&quot;  done# 方法3：检查 DPDK 进程特征ps aux | grep -E &quot;testpmd|l2fwd|l3fwd|dpdk|ovs|vpp|fd.io&quot; | grep -v greppgrep -a -f &quot;dpdk|testpmd&quot; 2&gt;/dev/null\n\n输出示例：testpmd 12345 root 5u CHR 241,0 ... /dev/uio0 → PID 12345 的 testpmd 占用\n\n✅ 第三步：辅助验证（增强可信度）# 检查 DPDK 绑定工具状态（若已安装）dpdk-devbind.py --status 2&gt;/dev/null | grep -A 5 &quot;0000:01:00.0&quot;# 检查内核日志（绑定时间点）dmesg | grep -i &quot;uio\\|vfio\\|bound to driver&quot; | tail -20# 检查 UIO 设备关联ls -l /sys/class/uio/ 2&gt;/dev/null &amp;&amp; cat /sys/class/uio/uio*/name\n\n\n📌 关键特征总结（快速判断）\n\n\n现象\n说明\n\n\n\nlspci 能看到网卡，但 ip link 无对应接口\n高度疑似 DPDK 占用\n\n\nlspci -k 显示驱动为 igb_uio&#x2F;vfio-pci\n确认被 DPDK 驱动接管\n\n\n/dev/uio* 或 /dev/vfio/* 被进程打开\n直接定位占用程序\n\n\ndpdk-devbind.py --status 标注 “drv&#x3D;igb_uio”\nDPDK 绑定状态明确\n\n\n\n⚠️ 注意事项\n权限要求：lsof&#x2F;fuser&#x2F;/proc 扫描需 root 权限，否则可能漏检。\n进程已退出但驱动未解绑：  \n若 lsof 无输出但驱动仍为 igb_uio，说明进程已退出但未释放设备。  \n恢复方法：  echo &quot;0000:01:00.0&quot; | sudo tee /sys/bus/pci/drivers/igb_uio/unbindecho &quot;0000:01:00.0&quot; | sudo tee /sys/bus/pci/drivers/ixgbe/bind  # 替换为原驱动名\n\n\n云环境&#x2F;容器：  \n容器内运行的 DPDK 程序需在宿主机排查（检查宿主机 /dev 和进程）。\n云平台（如阿里云）需确认是否启用 SR-IOV + VF 被 DPDK 占用。\n\n\n安全操作：  \n切勿直接 kill 进程！先确认业务影响（如 OVS-DPDK、VPP、自研转发程序）。  \n恢复网卡前，确保 DPDK 程序已安全停止。\n\n\n\n\n💡 一句话总结\n“网卡硬件存在但内核看不见” + “驱动显示 igb_uio&#x2F;vfio-pci” &#x3D; DPDK 占用；用 lsof /dev/uio* 或扫描 /proc/*/fd 精准定位占用进程。\n\n通过以上方法，可快速区分“命名规则变更”与“DPDK 占用”，避免误判。如需进一步分析，提供 lspci -k -s &lt;PCI&gt; 和 lsof /dev/uio* 输出即可精准定位。\n","categories":["故障处理与问题排查"]},{"title":"P4-vSwitch实验环境部署和实验操作简要手册","url":"/2026/02/27/p4-vswitch-install/","content":"目录 {#目录 .TOC-Heading}1 概述 5\n1.1 项目背景 5\n1.2 环境信息 5\n2 环境部署 6\n2.1 系统安装 6\n2.2 Switch节点 6\n2.3 Generator节点&#x2F;Receiver节点11\n3 l2_switch实验 14\n3.1 实验准备 14\n3.2 实验操作 16\n3.2.1 Switch节点 16\n3.2.2 Generator节点 &amp; Receiver节点19\n4 Simple_router实验 23\n4.1 实验准备 23\n4.2 实验操作 27\n4.2.1 Switch节点 27\n4.2.2 Generator节点 &amp; Receiver节点29\n表1. 文档修改记录 1\n表2. 服务器信息表 5\n图1. 网络拓扑连接图 6\n图2. dpdk端口绑定情况 9\n图3. 大页内存情况 10\n图4. dpdk端口绑定情况 13\n图5. 大页内存情况 13\n图6. l2_switch实验文件 14\n图7. ovs网桥情况 18\n图8. l2_switch实验流表 19\n图9. 发包软件启动 22\n图10. 流表变化 23\n图11. simple_router实验文件24\n图12. ovs网桥情况 28\n图13. simple_router实验流表29\n图14. 流表变化 30\n概述项目背景参考Github项目。\nhttps://github.com/P4-vSwitch\n{#section .图名}环境信息项目部署环境为虚拟机，需将其中的脚本和代码迁移至物理机运行。\n实验环境共3台服务器，基本信息如下，实验室网络可登录。\n\n[]{#_Toc17707 .anchor}服务器信息表\n\n+:———-:+:————–:+:———–:+:———–:+:—————-:+| 服务器名称 | IP地址         | 用户名      | 密码        | 备注             |+————+—————-+————-+————-+——————+| p4switch   | 192.168.61.133 | root&#x2F;ubuntu | abcd@1234   | system           ||            |                |             |             |                  ||            |                |             |             | Ubuntu 14.04.4   ||            |                |             |             |                  ||            |                |             |             | kernel           ||            |                |             |             |                  ||            |                |             |             | 4.2.0-27-generic |+————+—————-+             |             |                  || p4recv     | 192.168.61.135 |             |             |                  |+————+—————-+             |             |                  || p4gen      | 192.168.61.134 |             |             |                  |+————+—————-+————-+————-+——————+\n拓扑连接图如下。\n{width&#x3D;”5.758333333333334in”height&#x3D;”3.122916666666667in”}\n网络拓扑连接图 {#网络拓扑连接图 .图名}环境部署系统安装Ubuntu 14.04.4，内核版本4.2.0-27-generic。\nSwitch节点使用root用户登录Switch节点，更新apt源，下载必要的软件依赖,建议将自带源替换为国内源。\napt-get update\n#apt-get upgrade\napt-get -y install git python-pip fuse libfuse-dev dh-autoreconf openssllibssl-dev cmake libpcap-dev python-yaml\n安装ply，且要求版本&lt;3.10，建议使用国内pip源。\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple ply&#x3D;&#x3D;3.9\n创建工作目录，并下载项目代码。\ncd &#x2F;home\ngit clone https://github.com/P4-vSwitch/vagrant.git\n下载安装p4-hlir模块\ncd &#x2F;home&#x2F;vagrant\ngit clone https://github.com/p4lang/p4-hlir.git\ncd p4-hlir&#x2F;\npython setup.py install\n下载安装p4c-behavioral模块\ncd &#x2F;home&#x2F;vagrant\ngit clone https://github.com/P4-vSwitch/p4c-behavioral.git\ncd p4c-behavioral&#x2F;\ngit checkout ovs\npython setup.py install\n下载OVS模块\ncd &#x2F;home&#x2F;vagrant\ngit clone https://github.com/P4-vSwitch/ovs.git\ncd ovs&#x2F;\ngit checkout p4\ngit submodule update --init\nBuild DPDK模块\ncd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;deps&#x2F;dpdk\npatch -p1 -N &lt; ..&#x2F;..&#x2F;setup-scripts&#x2F;patches&#x2F;dpdk.patch\nmake -j 2 install T&#x3D;x86_64-native-linuxapp-gcc\n导入环境变量，建议填入~&#x2F;.bashrc，避免每次新开窗口都需要手动导入。\nexport RTE_SDK&#x3D;&#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;deps&#x2F;dpdk\nexport RTE_TARGET&#x3D;x86_64-native-linuxapp-gcc\nexport DPDK_DIR&#x3D;$RTE_SDK\nexport DPDK_BUILD&#x3D;$DPDK_DIR&#x2F;$RTE_TARGET&#x2F;\n配置DPDK内核模块\ncd &#x2F;home&#x2F;vagrant\nmodprobe uio\ninsmod $RTE_SDK&#x2F;$RTE_TARGET&#x2F;kmod&#x2F;igb_uio.ko\ninsmod $RTE_SDK&#x2F;$RTE_TARGET&#x2F;kmod&#x2F;rte_kni.ko &quot;lo_mode&#x3D;lo_mode_ring&quot;\n将服务器端口绑定至DPDK\nifconfig eth0 down\n$RTE_SDK&#x2F;tools&#x2F;dpdk_nic_bind.py -b igb_uio eth0\nifconfig eth1 down\n$RTE_SDK&#x2F;tools&#x2F;dpdk_nic_bind.py -b igb_uio eth1\n查看绑定情况\n$RTE_SDK&#x2F;tools&#x2F;dpdk_nic_bind.py --status\n{width&#x3D;”5.758333333333334in”height&#x3D;”1.7638888888888888in”}\ndpdk端口绑定情况 {#dpdk端口绑定情况 .图名}配置大页内存\ncd &#x2F;home&#x2F;vagrant\nmkdir -p &#x2F;mnt&#x2F;huge\n(mount | grep hugetlbfs) &gt; &#x2F;dev&#x2F;null || sudo mount -t hugetlbfsnodev &#x2F;mnt&#x2F;huge\necho 1024 &gt;&#x2F;sys&#x2F;devices&#x2F;system&#x2F;node&#x2F;node0&#x2F;hugepages&#x2F;hugepages-2048kB&#x2F;nr_hugepages\n查看大页内存\ngrep -i huge &#x2F;proc&#x2F;meminfo\n{width&#x3D;”5.763888888888889in”height&#x3D;”1.1131944444444444in”}\n大页内存情况 {#大页内存情况 .图名}Build OVS\ncd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;\n.&#x2F;boot.sh\n.&#x2F;configure --with-dpdk&#x3D;$DPDK_BUILD CFLAGS&#x3D;&quot;-g -O2 -Wno-cast-align&quot;\\\np4inputfile&#x3D;.&#x2F;include&#x2F;p4&#x2F;examples&#x2F;l2_switch&#x2F;l2_switch.p4 \\\np4outputdir&#x3D;.&#x2F;include&#x2F;p4&#x2F;src\nmake -j 2\n创建OVS数据库文件和文件路径\nmkdir -p &#x2F;usr&#x2F;local&#x2F;etc&#x2F;openvswitch\nmkdir -p &#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;openvswitch\ncd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;ovsdb&#x2F;\n.&#x2F;ovsdb-tool create &#x2F;usr&#x2F;local&#x2F;etc&#x2F;openvswitch&#x2F;conf.db..&#x2F;vswitchd&#x2F;vswitch.ovsschema\nGenerator节点&#x2F;Receiver节点两节点安装步骤一致，合并描述。\n使用root用户登录Generator或Receiver节点，更新apt源，下载必要的软件依赖,建议将自带源替换为国内源。\napt-get update\napt-get upgrade\napt-get -y install git python-pip fuse libfuse-dev dh-autoreconf openssllibssl-dev cmake libpcap-dev python-yaml\n创建工作目录，并下载项目代码。\ncd &#x2F;home\ngit clone https://github.com/P4-vSwitch/vagrant.git\n下载Pktgen项目代码\ncd &#x2F;home&#x2F;vagrant\ngit clone https://github.com/P4-vSwitch/pktgen.git\ncd pktgen&#x2F;\ngit submodule update --init\nBuild DPDK模块\ncd &#x2F;home&#x2F;vagrant&#x2F;pktgen&#x2F;deps&#x2F;dpdk\nmake -j 2 install T&#x3D;x86_64-native-linuxapp-gcc\n导入环境变量，建议填入~&#x2F;.bashrc，避免每次新开窗口都需要手动导入。\nexport RTE_SDK&#x3D;&#x2F;home&#x2F;vagrant&#x2F;pktgen&#x2F;deps&#x2F;dpdk\nexport RTE_TARGET&#x3D;x86_64-native-linuxapp-gcc\nexport DPDK_DIR&#x3D;$RTE_SDK\nexport DPDK_BUILD&#x3D;$DPDK_DIR&#x2F;$RTE_TARGET&#x2F;\n配置DPDK内核模块\ncd &#x2F;home&#x2F;vagrant\nmodprobe uio\ninsmod $RTE_SDK&#x2F;$RTE_TARGET&#x2F;kmod&#x2F;igb_uio.ko\ninsmod $RTE_SDK&#x2F;$RTE_TARGET&#x2F;kmod&#x2F;rte_kni.ko &quot;lo_mode&#x3D;lo_mode_ring&quot;\n将服务器端口绑定至DPDK\nifconfig eth0 down\n$RTE_SDK&#x2F;tools&#x2F;dpdk_nic_bind.py -b igb_uio eth0\nifconfig eth1 down\n$RTE_SDK&#x2F;tools&#x2F;dpdk_nic_bind.py -b igb_uio eth1\n查看绑定情况\n$RTE_SDK&#x2F;tools&#x2F;dpdk_nic_bind.py --status\n{width&#x3D;”5.763888888888889in”height&#x3D;”1.7833333333333334in”}\ndpdk端口绑定情况 {#dpdk端口绑定情况-1 .图名}配置大页内存\ncd &#x2F;home&#x2F;vagrant\nmkdir -p &#x2F;mnt&#x2F;huge\n(mount | grep hugetlbfs) &gt; &#x2F;dev&#x2F;null || sudo mount -t hugetlbfsnodev &#x2F;mnt&#x2F;huge\necho 512 &gt;&#x2F;sys&#x2F;devices&#x2F;system&#x2F;node&#x2F;node0&#x2F;hugepages&#x2F;hugepages-2048kB&#x2F;nr_hugepages\n查看大页内存\ngrep -i huge &#x2F;proc&#x2F;meminfo\n{width&#x3D;”5.764583333333333in”height&#x3D;”1.332638888888889in”}\n大页内存情况 {#大页内存情况-1 .图名}Build Pktgen模块\ncd &#x2F;home&#x2F;vagrant&#x2F;pktgen\nmake\nl2_switch实验实验准备实验脚本文件和配置文件中的参数需根据服务器网口实际情况进行修改，实验路径如下图所示。不同节点需要修改的位置不同，以下分别描述。\n{width&#x3D;”5.761805555555555in”height&#x3D;”1.2694444444444444in”}\nl2_switch实验文件 {#l2_switch实验文件 .图名}Switch节点：\nl2_switch.p4&#x2F;generator.pkt&#x2F;receiver.pkt：保持不变\nl2_switch.sh：将流表中的mac地址，更换为Generator和Receiver服务器分别连接Switch的网口的mac地址，如下标红位置所示。\n#! &#x2F;bin&#x2F;sh -ve\n# Please make sure that you update the path to the current OVSdirectory.\nDIR&#x3D;&#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;utilities\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 del-flows br0\n# SMAC Table 0\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;0,priority&#x3D;32768,ethernet__srcAddr&#x3D;0x74a4b500eee4actions&#x3D;resubmit(,1)&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;0,priority&#x3D;32768,ethernet__srcAddr&#x3D;0x74a4b500ef02actions&#x3D;resubmit(,1)&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;0,priority&#x3D;0 actions&#x3D;controller&quot;\n# DMAC Table 1\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;1,priority&#x3D;32768,ethernet__dstAddr&#x3D;0x74a4b500eee4actions&#x3D;set_field:1-&gt;reg0,resubmit(,2)&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;1,priority&#x3D;32768,ethernet__dstAddr&#x3D;0x74a4b500ef02actions&#x3D;set_field:2-&gt;reg0,resubmit(,2)&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;1,priority&#x3D;0 actions&#x3D;flood&quot;\n# SRC Pruning Table 2\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;32768,in_port&#x3D;1,reg0&#x3D;1 actions&#x3D;&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;32768,in_port&#x3D;2,reg0&#x3D;2 actions&#x3D;&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;32768,in_port&#x3D;3,reg0&#x3D;3 actions&#x3D;&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;32768,in_port&#x3D;4,reg0&#x3D;4 actions&#x3D;&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;32768,in_port&#x3D;5,reg0&#x3D;5 actions&#x3D;&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;32768,in_port&#x3D;6,reg0&#x3D;6 actions&#x3D;&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;0 actions&#x3D;deparse,output:NXM_NX_REG0[]&quot;\ngenerator节点：\n只修改generator.pkt文件，将generator与switch连接的网口mac地址填入，如下所示。\nset mac 0 74:a4:b5:00:ee:e4\nreceiver节点：\n只修改receiver.pkt文件，将receiver与switch连接的网口mac地址填入，如下所示。\nset mac 0 74:a4:b5:00:ef:02\n实验操作Switch节点使用root用户，登录switch节点。\n编译l2_switch.p4cd &#x2F;home&#x2F;vagrant&#x2F;ovs\n.&#x2F;configure --with-dpdk&#x3D;$DPDK_BUILD CFLAGS&#x3D;&quot;-g -O2 -Wno-cast-align&quot;p4inputfile&#x3D;&#x2F;home&#x2F;vagrant&#x2F;examples&#x2F;l2_switch&#x2F;l2_switch.p4p4outputdir&#x3D;.&#x2F;include&#x2F;p4&#x2F;src\nmake clean\nmake -j 2\n启动ovsdb-server(保持后台运行)cd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;ovsdb\nnohup .&#x2F;ovsdb-server--remote&#x3D;punix:&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;openvswitch&#x2F;db.sock \\\n--remote&#x3D;db:Open_vSwitch,Open_vSwitch,manager_options --pidfile &amp;\n启动ovs-vswitchd(保持后台运行)cd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;vswitchd\nnohup .&#x2F;ovs-vswitchd --dpdk -c 0x1 -n 4 --unix:&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;openvswitch&#x2F;db.sock --pidfile &amp;\n创建OVS网桥cd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;utilities\n.&#x2F;ovs-vsctl --no-wait init\n.&#x2F;ovs-vsctl add-br br0 -- set bridge br0 datapath_type&#x3D;netdev\n.&#x2F;ovs-vsctl set bridge br0 protocols&#x3D;OpenFlow15\n.&#x2F;ovs-vsctl add-port br0 dpdk0 -- set Interface dpdk0 type&#x3D;dpdk\n.&#x2F;ovs-vsctl add-port br0 dpdk1 -- set Interface dpdk1 type&#x3D;dpdk\n如果需要删除，则执行.&#x2F;ovs-vsctl del-br br0\n查看网桥执行.&#x2F;ovs-vsctl show\n{width&#x3D;”5.7659722222222225in”height&#x3D;”2.2305555555555556in”}\novs网桥情况 {#ovs网桥情况 .图名}加载流表cd &#x2F;home&#x2F;vagrant&#x2F;examples&#x2F;l2_switch&#x2F;\n.&#x2F;l2_switch.sh\n加载完成后，可执行如下命令查看。\ncd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;utilities\n.&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 dump-flows br0\n{width&#x3D;”5.752777777777778in”height&#x3D;”1.0763888888888888in”}\nl2_switch实验流表 {#l2_switch实验流表 .图名}Generator节点 &amp; Receiver节点使用root用户，分别从不同终端窗口登录generator节点和receiver节点。\n启动发包程序Generator节点：\ncd &#x2F;home&#x2F;vagrant&#x2F;pktgen\n.&#x2F;app&#x2F;app&#x2F;x86_64-native-linuxapp-gcc&#x2F;app&#x2F;pktgen -c 0x3 -n 4 -- -P -m&quot;1.0&quot; -f &#x2F;home&#x2F;vagrant&#x2F;examples&#x2F;l2_switch&#x2F;generator.pkt\nReceiver节点：\ncd &#x2F;home&#x2F;vagrant&#x2F;pktgen\n.&#x2F;app&#x2F;app&#x2F;x86_64-native-linuxapp-gcc&#x2F;app&#x2F;pktgen -c 0x3 -n 4 -- -P -m&quot;1.0&quot; -f &#x2F;home&#x2F;vagrant&#x2F;examples&#x2F;l2_switch&#x2F;receiver.pkt\n启动后出现如下图所示回显。\n{width&#x3D;”5.759722222222222in”height&#x3D;”5.345833333333333in”}\n{width&#x3D;”5.7625in”height&#x3D;”4.083333333333333in”}\n{width&#x3D;”5.759722222222222in”height&#x3D;”3.6256944444444446in”}\n{width&#x3D;”5.7659722222222225in”height&#x3D;”3.7909722222222224in”}\n{width&#x3D;”5.7625in”height&#x3D;”3.9631944444444445in”}\n发包软件启动 {#发包软件启动 .图名}开始发包回到generator节点的界面，输入并执行start 0，开始发包。\n此时，在switch节点可查看流表，若数据包数量随时间出现增长，则说明发报成功，如下图所示。\n{width&#x3D;”5.763888888888889in”height&#x3D;”1.1402777777777777in”}\n{width&#x3D;”5.764583333333333in”height&#x3D;”1.1694444444444445in”}\n流表变化 {#流表变化 .图名}实验结束后，回到genarator节点，输入并执行stop 0，停止发包。\nSimple_router实验实验准备若接着上述l2_switch实验继续，则需要先将环境清理。\n停止generator节点和receiver节点的发包程序，并退出。\nstop 0\nquit\n删除switch节点的ovsdb和ovs主进程。\nps -ef | grep ovs\nkill -9 xxxxx\nkill -9 xxxxx\n实验脚本文件和配置文件中的参数需根据服务器网口实际情况进行修改，实验路径如下图所示。不同节点需要修改的位置不同，以下分别描述。\n{width&#x3D;”5.759722222222222in”height&#x3D;”0.8493055555555555in”}\nsimple_router实验文件 {#simple_router实验文件 .图名}Switch节点：\nsimple_router.p4&#x2F;generator.pkt&#x2F;receiver.pkt：保持不变\nsimple_router.sh：将流表中的mac地址，更换为Generator和Receiver服务器分别连接Switch的网口的mac地址，如下标红位置所示。\n#! &#x2F;bin&#x2F;sh -ve\n# Please make sure that you update the path to the current OVSdirectory.\nDIR&#x3D;&#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;utilities\n# For this test we will pre-populate ARP caches at the end-hosts\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 del-flows br0\n# Verify Checksum (Table 0)\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;0,priority&#x3D;32768,ethernet__etherType&#x3D;0x800 \\\nactions&#x3D;calc_fields_verify(ipv4__hdrChecksum,csum16,fields:ipv4__version_ihl,ipv4__diffserv,ipv4__totalLen,ipv4__identification,ipv4__flags_fragOffset,ipv4__ttl,ipv4__protocol,ipv4__srcAddr,ipv4__dstAddr),\\\nresubmit(,1)&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;0,priority&#x3D;0 actions&#x3D;&quot;\n# IPv4 LPM (Table 1)\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;1,priority&#x3D;32768,ipv4__dstAddr&#x3D;0x0A00000F&#x2F;0xFFFFFF00 \\\nactions&#x3D;set_field:0x0B00000F-&gt;routing_metadata_nhop_ipv4, \\\nset_field:2-&gt;reg0, \\\nset_field:63-&gt;ipv4__ttl, \\\nresubmit(,2)&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;1,priority&#x3D;0 actions&#x3D;&quot;\n# Forward (Table 2)\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;32768,routing_metadata_nhop_ipv4&#x3D;0x0B00000F \\\nactions&#x3D;set_field:0x74a4b500eee4-&gt;ethernet__dstAddr, \\\nresubmit(,3)&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;2,priority&#x3D;0 actions&#x3D;&quot;\n# Send Frame (Table 3)\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;3,priority&#x3D;32768,reg0&#x3D;2 \\\nactions&#x3D;set_field:0x74a4b500ef02-&gt;ethernet__srcAddr, \\\ncalc_fields_update(ipv4__hdrChecksum,csum16,fields:ipv4__version_ihl,ipv4__diffserv,ipv4__totalLen,ipv4__identification,ipv4__flags_fragOffset,ipv4__ttl,ipv4__protocol,ipv4__srcAddr,ipv4__dstAddr),\\\ndeparse, \\\noutput:NXM_NX_REG0[]&quot;\n$DIR&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 add-flow br0&quot;table&#x3D;3,priority&#x3D;0 actions&#x3D;&quot;\ngenerator节点：\n只修改generator.pkt文件，将generator与switch连接的网口mac地址填入，如下所示。\nset mac 0 74:a4:b5:00:ee:e4\nset ip src 0 10.0.0.14&#x2F;24\nset ip dst 0 10.0.0.15\nreceiver节点：\n只修改receiver.pkt文件，将receiver与switch连接的网口mac地址填入，如下所示。\nset mac 0 74:a4:b5:00:ef:02\nset ip src 0 10.0.0.15&#x2F;24\nset ip dst 0 10.0.0.14\n实验操作Switch节点使用root用户，登录switch节点。\n编译simple_router.p4cd &#x2F;home&#x2F;vagrant&#x2F;ovs\n.&#x2F;configure --with-dpdk&#x3D;$DPDK_BUILD CFLAGS&#x3D;&quot;-g -O2 -Wno-cast-align&quot;p4inputfile&#x3D;&#x2F;home&#x2F;vagrant&#x2F;examples&#x2F;simple_router&#x2F;simple_router.p4p4outputdir&#x3D;.&#x2F;include&#x2F;p4&#x2F;src\nmake clean\nmake -j 2\n启动ovsdb-server(保持后台运行)cd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;ovsdb\nnohup .&#x2F;ovsdb-server--remote&#x3D;punix:&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;openvswitch&#x2F;db.sock \\\n--remote&#x3D;db:Open_vSwitch,Open_vSwitch,manager_options --pidfile &amp;\n启动ovs-vswitchd(保持后台运行)cd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;vswitchd\nnohup .&#x2F;ovs-vswitchd --dpdk -c 0x1 -n 4 --unix:&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;openvswitch&#x2F;db.sock --pidfile &amp;\n创建OVS网桥cd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;utilities\n.&#x2F;ovs-vsctl --no-wait init\n.&#x2F;ovs-vsctl add-br br0 -- set bridge br0 datapath_type&#x3D;netdev\n.&#x2F;ovs-vsctl set bridge br0 protocols&#x3D;OpenFlow15\n.&#x2F;ovs-vsctl add-port br0 dpdk0 -- set Interface dpdk0 type&#x3D;dpdk\n.&#x2F;ovs-vsctl add-port br0 dpdk1 -- set Interface dpdk1 type&#x3D;dpdk\n如果需要删除，则执行.&#x2F;ovs-vsctl del-br br0\n查看网桥执行.&#x2F;ovs-vsctl show\n{width&#x3D;”5.7659722222222225in”height&#x3D;”2.2305555555555556in”}\novs网桥情况 {#ovs网桥情况-1 .图名}加载流表cd &#x2F;home&#x2F;vagrant&#x2F;examples&#x2F;simple_router&#x2F;\n.&#x2F;simple_router.sh\n加载完成后，可执行如下命令查看。\ncd &#x2F;home&#x2F;vagrant&#x2F;ovs&#x2F;utilities\n.&#x2F;ovs-ofctl --protocols&#x3D;OpenFlow15 dump-flows br0\n{width&#x3D;”5.767361111111111in”height&#x3D;”1.229861111111111in”}\nsimple_router实验流表 {#simple_router实验流表 .图名}Generator节点 &amp; Receiver节点使用root用户，分别从不同终端窗口登录generator节点和receiver节点。\n启动发包程序Generator节点：\ncd &#x2F;home&#x2F;vagrant&#x2F;pktgen\n.&#x2F;app&#x2F;app&#x2F;x86_64-native-linuxapp-gcc&#x2F;app&#x2F;pktgen -c 0x3 -n 4 -- -P -m&quot;1.0&quot; -f &#x2F;home&#x2F;vagrant&#x2F;examples&#x2F;simple_router&#x2F;generator.pkt\nReceiver节点：\ncd &#x2F;home&#x2F;vagrant&#x2F;pktgen\n.&#x2F;app&#x2F;app&#x2F;x86_64-native-linuxapp-gcc&#x2F;app&#x2F;pktgen -c 0x3 -n 4 -- -P -m&quot;1.0&quot; -f &#x2F;home&#x2F;vagrant&#x2F;examples&#x2F;simple_router&#x2F;receiver.pkt\n启动后出现回显与l2_switch实验一致。\n开始发包回到generator节点的界面，输入并执行start 0，开始发包。\n此时，在switch节点可查看流表，若数据包数量随时间出现增长，则说明发报成功，如下图所示。\n{width&#x3D;”5.763888888888889in”height&#x3D;”1.1472222222222221in”}\n{width&#x3D;”5.759722222222222in”height&#x3D;”1.1659722222222222in”}\n流表变化 {#流表变化-1 .图名}实验结束后，回到genarator节点，输入并执行stop 0，停止发包。\n","categories":["软件安装配置与运维管理"]},{"title":"Linux系统中网口消失问题排查","url":"/2026/02/27/%E7%BD%91%E5%8F%A3%E4%B8%8D%E8%A7%81%E6%8E%92%E6%9F%A5/","content":"在 Linux 运维中，“网口不见了”（如找不到 eth0）是高频问题，绝大多数情况并非硬件故障，而是命名规则变更或驱动&#x2F;配置问题。以下是系统性分析与排查指南：\n\n🔍 核心原因分类（按发生频率排序）1️⃣ 网络接口命名规则变更（最常见！）\n现象：系统实际存在网卡，但名称变为 enp0s3、ens192、eno1 等（systemd ≥ 197 的“可预测命名”）。\n原因：现代发行版（CentOS 7+&#x2F;RHEL 7+、Ubuntu 15.10+ 等）默认启用此规则，避免驱动加载顺序导致名称漂移。\n验证：ip link show          # 查看所有接口（含 DOWN 状态）ls /sys/class/net/    # 直接列出内核识别的接口\n若看到非 eth* 名称，即属此情况。\n\n2️⃣ 驱动未加载或加载失败\n驱动缺失&#x2F;未编译进内核、initramfs 未包含驱动（内核升级后常见）、驱动被黑名单禁用、硬件不兼容。\n排查：lspci -k | grep -A 3 -i ethernet  # 查看网卡及绑定驱动dmesg | grep -i &quot;eth\\|error\\|fail&quot; # 检查内核日志错误lsmod | grep &lt;驱动名&gt;              # 确认模块是否加载\n\n3️⃣ 硬件或虚拟化层问题\n物理：网卡松动、BIOS&#x2F;UEFI 中禁用板载网卡、硬件故障。\n虚拟化：VM 未添加虚拟网卡、快照恢复后 MAC 变化导致 udev 重命名、云平台（AWS&#x2F;Aliyun）ENI 未挂载。\n排查：lspci | grep -i ethernet  # 确认硬件是否被识别# 虚拟机：检查 Hypervisor 配置；云平台：控制台确认网络接口状态\n\n4️⃣ 配置或环境干扰\nudev 规则覆盖（/etc/udev/rules.d/ 中自定义命名规则）\n容器环境：未共享主机网络命名空间（如 Docker 默认桥接模式下容器内无 eth0）\n命令误区：ifconfig（已弃用）可能不显示 DOWN 接口；应使用 ip link\n安全策略：SELinux&#x2F;AppArmor 限制（罕见）\n\n\n🛠️ 高效排查流程（建议顺序执行）# 1. 确认接口是否存在（关键第一步！）ip -br link show        # 简洁列出所有接口状态ls /sys/class/net/# 2. 检查硬件识别lspci | grep -i ether   # 有线网卡lsusb | grep -i net     # USB网卡# 3. 检查驱动与内核日志dmesg | tail -100 | grep -i &quot;net\\|eth\\|fail&quot;journalctl -b -u systemd-udevd --no-pager | grep -i net# 4. 检查命名规则干扰cat /etc/udev/rules.d/*net*.rules 2&gt;/dev/nullcat /proc/cmdline | grep -E &quot;net.ifnames|biosdevname&quot;  # 查看启动参数# 5. 虚拟化/云环境专项# - VM：检查虚拟机设置、快照历史# - 云主机：控制台确认弹性网卡状态、实例元数据\n\n\n💡 常见解决方案\n\n\n场景\n解决方案\n\n\n\n仅命名变化\n接受新名称（推荐）；或启动参数加 net.ifnames=0 biosdevname=0 → update-grub → 重启\n\n\n驱动缺失\n安装驱动 → update-initramfs -u (Debian) &#x2F; dracut -f (RHEL) → 重启\n\n\nudev 规则干扰\n检查 /etc/udev/rules.d/，临时移除自定义规则测试\n\n\n虚拟机 MAC 变化\n清理 /etc/udev/rules.d/70-persistent-net.rules（旧系统）或重置 VM 网卡\n\n\n容器内无 eth0\n检查容器网络模式（--network host 可共享主机接口）\n\n\n\n✅ 重要提醒\n优先使用 ip 命令：ifconfig 已过时且行为不一致（如某些版本隐藏 DOWN 接口）。\n“看不见” ≠ “不存在”：90% 以上是命名规则变化，先执行 ip link 确认。\n修改前备份：调整 GRUB 参数或 udev 规则前务必备份。\n云环境特殊性：阿里云&#x2F;腾讯云等需结合控制台操作（如重启实例、重置网络）。\n\n通过以上步骤，可快速定位问题根源。如仍无法解决，提供 ip link、lspci -k、dmesg | grep -i eth 的输出可进一步精准分析。\n","categories":["故障处理与问题排查"]}]